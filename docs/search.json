[{"path":"/articles/calculating.html","id":"rep","dir":"Articles","previous_headings":"","what":"calculate_representation()","title":"calculating","text":"calculate_representation() function allows users check well represented existing sample networks within context stratification. Users provide sraster choosing existing samples provided tabular graphical (plot = TRUE) output comparing strata coverage frequency sampling frequency.  tabular output outlines frequency coverage strata (srasterFreq) sampling frequency within strata (sampleFreq). difference (diffFreq) determine whether values -represented (positive numbers) -represented (negative numbers). also reflected number samples needed added removed (need) reach considered sample representative strata provided sraster. Performing algorithm sample set derived using sample_strat() demonstrates proportional sampling strata coverage.  common small (negligible) differences srasterFreq sampleFreq. cases important user determine whetehr think samples really added removed.","code":"#--- calculate representation ---# calculate_representation(sraster = sraster,                           existing = existing,                           plot = TRUE) #> # A tibble: 4 x 6 #>   strata srasterFreq sampleFreq diffFreq nSamp  need #>    <dbl>       <dbl>      <dbl>    <dbl> <int> <dbl> #> 1      1        0.27       0.24  -0.0300    49     5 #> 2      2        0.29       0.32   0.0300    64    -6 #> 3      3        0.2        0.16  -0.04      33     7 #> 4      4        0.24       0.27   0.0300    54    -6 #--- stratified samples ---# strat <- sample_strat(sraster = sraster,                       nSamp = 200)  calculate_representation(sraster = sraster,                          existing = strat,                          plot = TRUE) #> # A tibble: 4 x 6 #>   strata srasterFreq sampleFreq diffFreq nSamp  need #>    <dbl>       <dbl>      <dbl>    <dbl> <int> <dbl> #> 1      1        0.27       0.27        0    55     0 #> 2      2        0.29       0.29        0    58     1 #> 3      3        0.2        0.2         0    41     0 #> 4      4        0.24       0.24        0    49     0"},{"path":"/articles/calculating.html","id":"dist","dir":"Articles","previous_headings":"","what":"calculate_distance","title":"calculating","text":"calculate_distance() function takes input raster access data outputs per pixel distance nearest access point. function particular value constraining sampling protocols sample_clhs() function output raster layer can used cost constraint.output raster input calculated distance layer (dist2access) appended.","code":"calculate_distance(raster = sraster, # input                    access = access, # define access road network                    plot = TRUE) # plot #> class       : SpatRaster  #> dimensions  : 277, 373, 2  (nrow, ncol, nlyr) #> resolution  : 20, 20  (x, y) #> extent      : 431100, 438560, 5337700, 5343240  (xmin, xmax, ymin, ymax) #> coord. ref. : UTM Zone 17, Northern Hemisphere  #> sources     : memory   #>               memory   #> names       :      strata, dist2access  #> min values  : 1.000000000, 0.006621213  #> max values  :        4.00,     1061.66"},{"path":"/articles/calculating.html","id":"calculate_pcomp","dir":"Articles","previous_headings":"","what":"calculate_pcomp","title":"calculating","text":"calculate_pcomp() function take mraster input performs principal component analysis. number components defined nComp parameter specify number components rasterized output.","code":"calculate_pcomp(mraster = mraster, # input                 nComp = 5, # number of components to output                 plot = TRUE, # plot                 details = TRUE) # details about the principal component analysis appended #> $pca #> Standard deviations (1, .., p=7): #> [1] 2.39419739 0.86118253 0.65363210 0.27245666 0.11010541 0.10829035 #> [7] 0.02942688 #>  #> Rotation (n x k) = (7 x 7): #>                PC1         PC2         PC3         PC4         PC5 #> zmean    0.4133340  0.09703826 -0.16916047  0.05442900 -0.21939815 #> pzabove2 0.3217898  0.28579795  0.89947473  0.04704228  0.05896495 #> zsd      0.3314085 -0.70018256  0.06658857 -0.06471159  0.60912694 #> zq20     0.3511227  0.56045175 -0.30858934 -0.47871051  0.46478505 #> zq50     0.4055046  0.12094513 -0.21087080  0.55459689 -0.06283654 #> zq70     0.4116799 -0.07298152 -0.13366415  0.36834483 -0.07728656 #> zq90     0.3982126 -0.29083896  0.01832844 -0.56410773 -0.59279438 #>                   PC6          PC7 #> zmean     0.054431518  0.858523411 #> pzabove2 -0.004537764  0.002374888 #> zsd      -0.102288428  0.098957671 #> zq20      0.029772877 -0.145958963 #> zq50     -0.629629712 -0.261748068 #> zq70      0.755801174 -0.307312042 #> zq90     -0.134157677 -0.262454817 #>  #> $raster #> class       : SpatRaster  #> dimensions  : 277, 373, 5  (nrow, ncol, nlyr) #> resolution  : 20, 20  (x, y) #> extent      : 431100, 438560, 5337700, 5343240  (xmin, xmax, ymin, ymax) #> coord. ref. : UTM Zone 17, Northern Hemisphere  #> sources     : memory   #>               memory   #>               memory   #>               ... and 2 more source(s) #> names       :        PC1,        PC2,        PC3,        PC4,        PC5  #> min values  : -5.8417779, -6.3681104, -4.0383034, -2.4944332, -0.6915542  #> max values  :   7.804354,   2.563877,   1.633331,   1.594847,   1.529565"},{"path":"/articles/calculating.html","id":"calculate_sampsize","dir":"Articles","previous_headings":"","what":"calculate_sampsize","title":"calculating","text":"calculate_sampsize() function allows users determine appropriate sample size using relative standard error input metric. mraster multiple layers provided, sample sizes determined layers. plot = TRUE rse defined, sequence rse values visualized indicators value matching sample size.","code":"#--- determine sample size based on relative standard error (rse) of 1% ---# calculate_sampsize(mraster = mraster,                    rse = 0.01) #>   nSamp  rse      var #> 1  2030 0.01    zmean #> 2  1341 0.01 pzabove2 #> 3  1859 0.01      zsd #> 4  3647 0.01     zq20 #> 5  2581 0.01     zq50 #> 6  2110 0.01     zq70 #> 7  1394 0.01     zq90 #--- change default threshold sequence values ---#  #--- if increment and rse are not divisible the closest value will be taken ---# p <- calculate_sampsize(mraster = mraster,                    rse = 0.025,                    start = 0.01,                    end = 0.08,                    increment = 0.01,                    plot = TRUE) #> 'rse' not perfectly divisible by 'incremenent.  #> Selecting closest sample size (rse = 0.03) based on values.  p #> $nSamp #> # A tibble: 7 x 3 #> # Groups:   var [7] #>   nSamp   rse var      #>   <dbl> <dbl> <chr>    #> 1   230  0.03 zmean    #> 2   151  0.03 pzabove2 #> 3   211  0.03 zsd      #> 4   421  0.03 zq20     #> 5   295  0.03 zq50     #> 6   240  0.03 zq70     #> 7   157  0.03 zq90     #>  #> $plot"},{"path":"/articles/calculating.html","id":"calculate_allocation","dir":"Articles","previous_headings":"","what":"calculate_allocation","title":"calculating","text":"calculate_allocation() function calculates total number samples allocated sampling based total sample value (nSamp) input sraster. function utilized number functions including sample_strat. Three methods allocation currently included: proportional (prop; default), optimal (optim) allocation, equal (equal) allocation. Proportional - Samples allocated based area coverage strata. default method. Optimal - Samples allocated based within strata variation. Equal - number samples (nSamp) allocated strata.","code":""},{"path":"/articles/calculating.html","id":"proportional","dir":"Articles","previous_headings":"calculate_allocation","what":"Proportional allocation","title":"calculating","text":"Notice results total negative. indicates existing samples represent strata samples removed avoid representation. number added/removed details $total.","code":"#--- perform grid sampling ---# calculate_allocation(sraster = sraster,                       nSamp = 200) #>   strata total #> 1      1    55 #> 2      2    58 #> 3      3    41 #> 4      4    49 #--- calculate existing samples to include ---# e.sr <- extract_strata(sraster = sraster,                         existing = existing)  calculate_allocation(sraster = sraster,                       nSamp = 200,                       existing = e.sr) #>   strata total need #> 1      1     6   55 #> 2      2    -6   58 #> 3      3     8   41 #> 4      4    -5   49"},{"path":"/articles/calculating.html","id":"optimal","dir":"Articles","previous_headings":"calculate_allocation","what":"Optimal Allocation","title":"calculating","text":"Optimal allocation utilizes within strata metric variation allocate samples. means addition providing sraster, specific metric (mraster) must provided calculate variation optimally allocate samples.","code":"calculate_allocation(sraster = sraster, # stratified raster                      nSamp = 200, # desired sample number                      existing = e.sr, #existing samples                      allocation = \"optim\", # optimal allocation                      mraster = mraster$zq90, # metric raster                      force = TRUE) # force nSamp number #>   strata total need #> 1      1     2   51 #> 2      2   -16   48 #> 3      3     7   42 #> 4      4     7   61"},{"path":"/articles/calculating.html","id":"equal","dir":"Articles","previous_headings":"calculate_allocation","what":"Equal allocation","title":"calculating","text":"may instance user wants number samples allocated strata. case using allocation = equal ideal. instance, nSamp relates total number samples per strata rather total number samples overall. yields total 80 samples (20 nSamp 4 strata sraster.)","code":"calculate_allocation(sraster = sraster, # stratified raster                      nSamp = 20, # desired sample number                      allocation = \"equal\") # optimal allocation #> # A tibble: 4 x 2 #>   strata total #>    <dbl> <dbl> #> 1      1    20 #> 2      2    20 #> 3      3    20 #> 4      4    20"},{"path":"/articles/calculating.html","id":"sampeval","dir":"Articles","previous_headings":"","what":"Sample evaluation algorithms","title":"calculating","text":"following algorithms initially developed Dr. Brendan Malone University Sydney. work graciously provided depth description functionality algorithms originally developed improve soil sampling strategies. functions modified implemented can used structurally guided sampling approaches. Many thanks Dr. Malone excellent collaborator proponent open source algorithms. Please consult original reference ideas scripts extremely valuable helpful understanding sampling rationale. Malone BP, Minansy B, Brungard C. 2019. methods improve utility conditioned Latin hypercube sampling. PeerJ 7:e6451 DOI 10.7717/peerj.6451","code":""},{"path":"/articles/calculating.html","id":"coobs","dir":"Articles","previous_headings":"Sample evaluation algorithms","what":"calculate_coobs","title":"calculating","text":"calculate_coobs() function perform COunt OBServations (coobs) algorithm using existing sample data mraster covariates. algorithm aids user understanding existing sample data set distributed among landscape relation mraster covariates. output coobs raster used constrain clhs sampling using sample_clhs() areas reprented. coobs raster determines many observations similar terms covariate space every pixel.fucntion takes advantage parallel processing routines.","code":"calculate_coobs(mraster = mraster, # input                 existing = existing, # existing samples                 cores = 4, # parallel cores to use                 details = TRUE, # provide details from algorithm output                 plot = TRUE, # plot                 filename = tempfile(fileext = \".tif\")) # write output raster to tif"},{"path":"/articles/calculating.html","id":"lhseval","dir":"Articles","previous_headings":"","what":"Latin hypercube sampling evaluation algorithms","title":"calculating","text":"following 2 algorithms provide means maximize effectiveness latin hypercube sampling protocols.","code":""},{"path":"/articles/calculating.html","id":"lhspop","dir":"Articles","previous_headings":"Latin hypercube sampling evaluation algorithms","what":"calculate_lhsPop","title":"calculating","text":"calculate_lhsPop() function calculates population level statistics mraster covariates used including calculating principal components, quantile & covariate distributions, Kullback–Leibler divergence testing. outputs function mandatory use calculate_lhsOpt() function described next section. output details following: $values - Pixel values mraster $pcaLoad - PCA loadings $matQ - Quantile matrix $matCov - Covariate matrix","code":"#--- by default all statistical data are calculated ---# calculate_lhsPop(mraster = mraster) # input #--- statistical analyses can be chosen by setting their parameter to `FALSE` ---# calculate_lhsPop(mraster = mraster, # input                   nQuant = 10, # desired number of quantiles                  PCA = FALSE) # choose not to calculate PCA's"},{"path":"/articles/calculating.html","id":"lhsopt","dir":"Articles","previous_headings":"Latin hypercube sampling evaluation algorithms","what":"calculate_lhsOpt","title":"calculating","text":"calculate_lhsOpt() function performs bootsrapped latin hypercube sampling approach population level analysis mraster data performed determine optimal Latin hypercube sample size. Using statistical data calculated using calculate_lhsPop() varying sample sizes defined minSamp, maxSamp, step rep. Sampling protocols conducted statistical effectiveness sampling outcomes evaluated determine sample size minimized statistical representation maximized.","code":"#--- calculate lhsPop details ---# poplhs <- calculate_lhsPop(mraster = mr)  calculate_lhsOpt(popLHS = poplhs) calculate_lhsOpt(popLHS = poplhs,                   PCA = FALSE,                   iter = 200)"},{"path":"/articles/sampling.html","id":"access","dir":"Articles","previous_headings":"","what":"Access","title":"sampling","text":"feature sample_* functions ability define access corridors. Users can supply road access network (must sf line objects) define buffers around access samples excluded included. Important additional parameters access provided : buff_inner - inner buffer defines distance access samples taken (.e. don’t want samples within 50 m access layer set buff_inner = 50). buff_outer - Maximum distance samples can located access (.e. don’t want samples 200 meters access layer set buff_inner = 200)","code":""},{"path":"/articles/sampling.html","id":"srs","dir":"Articles","previous_headings":"","what":"sample_srs","title":"sampling","text":"provided simple example using sample_srs() function vignette(\"sgsR\"). provide additional examples . Notice input sample_srs() raster. means either sraster mraster supported.","code":"#--- perform simple random sampling ---# sample_srs(raster = sraster, # input sraster            nSamp = 200, # number of desired samples            plot = TRUE) # plot #> Simple feature collection with 200 features and 0 fields #> Geometry type: POINT #> Dimension:     XY #> Bounding box:  xmin: 431250 ymin: 5337750 xmax: 438550 ymax: 5343190 #> CRS:           +proj=utm +zone=17 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs #> First 10 features: #>                  geometry #> 1  POINT (436830 5341150) #> 2  POINT (436830 5341150) #> 3  POINT (436570 5342730) #> 4  POINT (437730 5338210) #> 5  POINT (434490 5339890) #> 6  POINT (431850 5337810) #> 7  POINT (432090 5340270) #> 8  POINT (432970 5337850) #> 9  POINT (431330 5341510) #> 10 POINT (433770 5340590) sample_srs(raster = mraster, # input mraster            nSamp = 200, # number of desired samples            access = access, # define access road network            mindist = 200, # minimum distance samples must be apart from one another            buff_inner = 50, # inner buffer - no samples within this distance from road            buff_outer = 200, # outer buffer - no samples further than this distance from road            plot = TRUE) # plot #> Simple feature collection with 200 features and 0 fields #> Geometry type: POINT #> Dimension:     XY #> Bounding box:  xmin: 431410 ymin: 5337790 xmax: 438550 ymax: 5343230 #> CRS:           +proj=utm +zone=17 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs #> First 10 features: #>                  geometry #> 1  POINT (438050 5340610) #> 2  POINT (432770 5339130) #> 3  POINT (434970 5340650) #> 4  POINT (438070 5340830) #> 5  POINT (437370 5342730) #> 6  POINT (432510 5338830) #> 7  POINT (432470 5341370) #> 8  POINT (435170 5339310) #> 9  POINT (432810 5340750) #> 10 POINT (432670 5339550) sample_srs(raster = sraster, # input            nSamp = 200, # number of desired samples            access = access, # define access road network            buff_inner = 50, # inner buffer - no samples within this distance from road            buff_outer = 200, # outer buffer - no samples further than this distance from road            plot = TRUE, # plot            filename = tempfile(fileext = \".shp\")) # write output samples to file #> Writing layer `file5c7077074089' to data source  #>   `C:\\Users\\tgood.stu\\AppData\\Local\\Temp\\RtmpwXR6av\\file5c7077074089.shp' using driver `ESRI Shapefile' #> Writing 200 features with 0 fields and geometry type Point. #> Simple feature collection with 200 features and 0 fields #> Geometry type: POINT #> Dimension:     XY #> Bounding box:  xmin: 431270 ymin: 5337730 xmax: 438550 ymax: 5343210 #> CRS:           +proj=utm +zone=17 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs #> First 10 features: #>                  geometry #> 1  POINT (434910 5340590) #> 2  POINT (434910 5340590) #> 3  POINT (433970 5341290) #> 4  POINT (437990 5340070) #> 5  POINT (435390 5338570) #> 6  POINT (433650 5341670) #> 7  POINT (435930 5342370) #> 8  POINT (435090 5338790) #> 9  POINT (431850 5342750) #> 10 POINT (436190 5339650)"},{"path":"/articles/sampling.html","id":"systematic","dir":"Articles","previous_headings":"","what":"sample_systematic","title":"sampling","text":"sample_systematic() function applies systematic sampling across area cellsize parameter defines resolution tessellation. Tesselation shape options defined square parameter, regular grid TRUE (default) hexagonal FALSE. location samples can also adjusted using locations parameter, centers takes center, corners takes corners, random takes random location within tessellation.","code":"#--- perform grid sampling ---# sample_systematic(raster = sraster, # input sraster                   cellsize = 1000, # grid distance                   plot = TRUE) # plot #> Simple feature collection with 40 features and 0 fields #> Geometry type: POINT #> Dimension:     XY #> Bounding box:  xmin: 431600 ymin: 5338200 xmax: 437600 ymax: 5343200 #> CRS:           +proj=utm +zone=17 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs #> First 10 features: #>                  geometry #> 1  POINT (431600 5338200) #> 2  POINT (432600 5338200) #> 3  POINT (433600 5338200) #> 4  POINT (434600 5338200) #> 5  POINT (435600 5338200) #> 6  POINT (436600 5338200) #> 7  POINT (437600 5338200) #> 8  POINT (432600 5339200) #> 9  POINT (433600 5339200) #> 10 POINT (434600 5339200) #--- perform grid sampling ---# sample_systematic(raster = sraster, # input sraster                   cellsize = 500, # grid distance                   square = FALSE, # hexagonal tessellation                   location = \"random\", # random sample within tessellation                   plot = TRUE) # plot #> Simple feature collection with 170 features and 0 fields #> Geometry type: POINT #> Dimension:     XY #> Bounding box:  xmin: 431108.8 ymin: 5337710 xmax: 438544.8 ymax: 5343206 #> CRS:           +proj=utm +zone=17 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs #> First 10 features: #>                    geometry #> 1  POINT (431108.8 5338509) #> 2    POINT (431227 5339575) #> 3  POINT (431205.1 5341042) #> 4  POINT (431401.4 5337937) #> 5    POINT (431378 5338832) #> 6  POINT (431446.2 5339877) #> 7    POINT (431275 5340777) #> 8  POINT (431369.5 5341441) #> 9  POINT (431348.2 5342633) #> 10 POINT (431692.1 5337855) sample_systematic(raster = sraster, # input sraster             cellsize = 500, # grid distance             access = access, # define access road network             buff_inner = 50, # inner buffer - no samples within this distance from road             buff_outer = 200, # outer buffer - no samples further than this distance from road             square = FALSE, # hexagonal tessellation             location = \"corners\", # take corners instead of centers             plot = TRUE) #> Simple feature collection with 470 features and 0 fields #> Geometry type: POINT #> Dimension:     XY #> Bounding box:  xmin: 431100 ymin: 5337844 xmax: 438350 ymax: 5343185 #> CRS:           +proj=utm +zone=17 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs #> First 10 features: #>                  geometry #> 1  POINT (431100 5340875) #> 2  POINT (431100 5340587) #> 3  POINT (431100 5340587) #> 4  POINT (431350 5340442) #> 5  POINT (431100 5340875) #> 6  POINT (431100 5340875) #> 7  POINT (431350 5342752) #> 8  POINT (431350 5340442) #> 9  POINT (431100 5340587) #> 10 POINT (431100 5340875)"},{"path":"/articles/sampling.html","id":"sstrat","dir":"Articles","previous_headings":"","what":"sample_strat","title":"sampling","text":"sample_strat() function contains hierarchical sampling algorithm originally developed Martin Queinnec. Queinnec, M., White, J. C., & Coops, N. C. (2021). Comparing airborne spaceborne photon-counting LiDAR canopy structural estimates across different boreal forest types. Remote Sensing Environment, 262(August 2020), 112510. algorithm uses moving window (wrow wcol parameters) filter input sraster locations stratum pixels spatially grouped rather dispersed individually across landscape. sampling performed 2 stages: Rule 1 - Sample within spatially grouped stratum pixels. Moving window defined wrow wcol. Rule 2 - samples exist satisfy desired sampling count, individual stratum pixels sampled. rule applied select particular sample defined rule attribute output samples. give examples :  cases, user may wish include existing sample data set within algorithm. order adjust total number samples needed per stratum reflect already present existing, can use utility function extract_strata(). function takes input sraster existing sample data set extracts stratum sample. samples can input sample_strat() function adjusts total required sample per class based representation existing. Notice e.sr now attribute named strata. parameter , sample_strat() give error.  mindist parameter defined example specifies minimum euclidian distance samples must apat one another. Notice sample outputs type rule attributes outline whether samples existing new whether rule1 rule2 used select individual samples.  include parameter determines whether existing samples included total count samples defined nSamp. defaults include = FALSE.","code":"#--- perform stratified sampling random sampling ---# sample_strat(sraster = sraster, # input sraster              nSamp = 200, # desired sample number              plot = TRUE) # plot #> Simple feature collection with 199 features and 3 fields #> Geometry type: POINT #> Dimension:     XY #> Bounding box:  xmin: 431150 ymin: 5337730 xmax: 438530 ymax: 5343210 #> CRS:           +proj=utm +zone=17 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs #> First 10 features: #>    strata type  rule               geometry #> x       1  new rule1 POINT (434510 5341590) #> x1      1  new rule1 POINT (437550 5343210) #> x2      1  new rule1 POINT (437610 5339170) #> x3      1  new rule1 POINT (438010 5338130) #> x4      1  new rule1 POINT (434210 5341710) #> x5      1  new rule1 POINT (434950 5342870) #> x6      1  new rule1 POINT (437650 5342590) #> x7      1  new rule1 POINT (436750 5337730) #> x8      1  new rule1 POINT (437850 5338990) #> x9      1  new rule1 POINT (435930 5342330) #--- extract strata values to existing samples ---#               e.sr <- extract_strata(sraster = sraster, # input sraster                        existing = existing) # existing samples to add strata value to  e.sr #> Simple feature collection with 200 features and 1 field #> Geometry type: POINT #> Dimension:     XY #> Bounding box:  xmin: 431110 ymin: 5337730 xmax: 438550 ymax: 5343230 #> Projected CRS: UTM Zone 17, Northern Hemisphere #> First 10 features: #>    strata               geometry #> 1       1 POINT (434610 5338890) #> 2       3 POINT (437190 5342830) #> 3       4 POINT (434950 5338430) #> 4       4 POINT (436090 5339590) #> 5       1 POINT (438190 5337850) #> 6       1 POINT (434770 5339830) #> 7       2 POINT (434090 5341690) #> 8       3 POINT (432050 5341670) #> 9       1 POINT (434110 5343130) #> 10      4 POINT (432490 5342030) sample_strat(sraster = sraster, # input sraster              nSamp = 200, # desired sample number              access = access, # define access road network              existing = e.sr, # existing samples with strata values              mindist = 200, # minimum distance samples must be apart from one another              buff_inner = 50, # inner buffer - no samples within this distance from road              buff_outer = 200, # outer buffer - no samples further than this distance from road              plot = TRUE) # plot #> Simple feature collection with 399 features and 3 fields #> Geometry type: POINT #> Dimension:     XY #> Bounding box:  xmin: 431110 ymin: 5337730 xmax: 438550 ymax: 5343230 #> CRS:           +proj=utm +zone=17 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs #> First 10 features: #>    strata     type     rule               geometry #> 1       1 existing existing POINT (434610 5338890) #> 5       1 existing existing POINT (438190 5337850) #> 6       1 existing existing POINT (434770 5339830) #> 9       1 existing existing POINT (434110 5343130) #> 15      1 existing existing POINT (434950 5342270) #> 23      1 existing existing POINT (434110 5339470) #> 25      1 existing existing POINT (435570 5342750) #> 32      1 existing existing POINT (434870 5342530) #> 34      1 existing existing POINT (438210 5338310) #> 40      1 existing existing POINT (434290 5340830) sample_strat(sraster = sraster, # input              nSamp = 200, # desired sample number              access = access, # define access road network              existing = e.sr, # existing samples with strata values              include = TRUE, # include existing plots in nSamp total              buff_inner = 50, # inner buffer - no samples within this distance from road              buff_outer = 200, # outer buffer - no samples further than this distance from road              filename = tempfile(fileext = \".shp\"), # write output samples to file              plot = TRUE) # plot #> Writing layer `file5c7024661b59' to data source  #>   `C:\\Users\\tgood.stu\\AppData\\Local\\Temp\\RtmpwXR6av\\file5c7024661b59.shp' using driver `ESRI Shapefile' #> Writing 199 features with 3 fields and geometry type Point. #> Simple feature collection with 199 features and 3 fields #> Geometry type: POINT #> Dimension:     XY #> Bounding box:  xmin: 431110 ymin: 5337730 xmax: 438550 ymax: 5343230 #> CRS:           +proj=utm +zone=17 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs #> First 10 features: #>     strata     type     rule               geometry #> 40       1 existing existing POINT (434290 5340830) #> 41       1 existing existing POINT (435130 5342390) #> 83       1 existing existing POINT (434330 5341610) #> 58       1 existing existing POINT (438510 5338990) #> 119      1 existing existing POINT (434530 5341290) #> 126      1 existing existing POINT (433930 5342650) #> 194      1 existing existing POINT (437850 5343030) #> 59       1 existing existing POINT (437370 5338530) #> 34       1 existing existing POINT (438210 5338310) #> 96       1 existing existing POINT (433890 5342950)"},{"path":"/articles/sampling.html","id":"clhs","dir":"Articles","previous_headings":"","what":"sample_clhs","title":"sampling","text":"sample_clhs() function implements conditioned latin hypercube (clhs) sampling functionality. number functions sgsR package help provide guidance clhs sampling including calculate_lhsPop() calculate_lhsOpt(). sure check functions better understanding optimize sample numbers. Syntax function similar others shown , though parameters like iter, define number iterations within Metropolis-Hastings process important consider. examples use low iter value takes less time run. Default values iter within clhs package 10,000.    cost parameter defines mraster covariate used constrain clhs sampling. number variables. example distance pixel road access (see example ), terrain slope, output calculate_coobs(), many others.","code":"sample_clhs(mraster = mraster, # input             nSamp = 200, # desired sample number             plot = TRUE, # plot              iter = 100) # number of iterations sample_clhs(mraster = mraster, # input             nSamp = 300, # desired sample number             existing = existing, # existing samples             iter = 100, # number of iterations             details = TRUE, # output details             plot = TRUE) # clhs details sample_clhs(mraster = mraster, # input             nSamp = 300, # desired sample number             iter = 100, # number of iterations             existing = existing, # existing samples             access = access, # define access road network             buff_inner = 100, # inner buffer - no samples within this distance from road             buff_outer = 300, # outer buffer - no samples further than this distance from road             plot = TRUE) # plot #--- cost constrained examples ---# #--- calculate distance to access layer for each pixel in mr ---# mr.c <- calculate_distance(raster = mraster, # input                            access = access,                            plot = TRUE) # define access road network sample_clhs(mraster = mr.c, # input             nSamp = 250, # desired sample number             iter = 100, # number of iterations             cost = \"dist2access\", # cost parameter - name defined in calculate_distance()             plot = TRUE) # plot sample_clhs(mraster = mr.c, # input             nSamp = 250, # desired sample number             existing = existing, # existing samples             iter = 100, # number of iterations             cost = \"dist2access\", # cost parameter - name defined in calculate_distance()             plot = TRUE) # plot"},{"path":"/articles/sampling.html","id":"balanced","dir":"Articles","previous_headings":"","what":"sample_balanced","title":"sampling","text":"sample_balanced() algorithm performs balanced sampling methodology stratifyR / SamplingBigData packages.","code":"sample_balanced(mraster = mraster, # input                 nSamp = 200, # desired sample number                 plot = TRUE) # plot #> Simple feature collection with 200 features and 0 fields #> Geometry type: POINT #> Dimension:     XY #> Bounding box:  xmin: 431230 ymin: 5337710 xmax: 438530 ymax: 5343190 #> CRS:           +proj=utm +zone=17 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs #> First 10 features: #>                  geometry #> 1  POINT (432810 5343190) #> 2  POINT (434050 5343190) #> 3  POINT (433370 5343010) #> 4  POINT (437250 5343010) #> 5  POINT (437890 5343010) #> 6  POINT (433190 5342990) #> 7  POINT (435370 5342950) #> 8  POINT (432050 5342930) #> 9  POINT (433830 5342870) #> 10 POINT (433030 5342850) sample_balanced(mraster = mraster, # input                 nSamp = 100, # desired sample number                 algorithm = \"lcube\", # algorithm type                 access = access, # define access road network                 buff_inner = 50, # inner buffer - no samples within this distance from road                 buff_outer = 200) # outer buffer - no samples further than this distance from road #> Simple feature collection with 100 features and 0 fields #> Geometry type: POINT #> Dimension:     XY #> Bounding box:  xmin: 431410 ymin: 5337770 xmax: 438470 ymax: 5343190 #> CRS:           +proj=utm +zone=17 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs #> First 10 features: #>                  geometry #> 1  POINT (434090 5342890) #> 2  POINT (438170 5342030) #> 3  POINT (435090 5342410) #> 4  POINT (435810 5340190) #> 5  POINT (436530 5338190) #> 6  POINT (437170 5343170) #> 7  POINT (436210 5339350) #> 8  POINT (438170 5342010) #> 9  POINT (432670 5338910) #> 10 POINT (438390 5339110)"},{"path":"/articles/sampling.html","id":"ahels","dir":"Articles","previous_headings":"","what":"sample_ahels","title":"sampling","text":"sample_ahels() function performs adapted Hypercube Evaluation Legacy Sample (ahels) algorithm using existing sample data mraster. New samples allocated based quantile ratios existing sample mraster covariate dataset. algorithm: Determines quantile distributions existing samples mraster covariates. Determines quantiles disparity samples covariates. Prioritizes sampling within quantile improve representation. use function, user first specify number quantiles (nQuant) followed either nSamp (total number desired samples added) threshold (proportional representation sample covariate quantiles - default 0.9) parameters. recommended use threshold values 0.9 higher values can currently cause algorithm add samples repeatedly.  Notice threshold, nSamp, nQuant defined. Thats defaults threshold = 0.9 nQuant = 10. first matrix output shows quantile ratios sample covariates. value 1.0 means samples covariates equally represented. Values 1.0 represented sample, less 1 represented sample.  Note total number samples 500. total existing samples (200) number defined nSamp = 300.","code":"sample_ahels(mraster = mraster[[1:3]], # input mraster - first 3 layers only              existing = existing, # existing samples              plot = TRUE) # plot #> Simple feature collection with 246 features and 4 fields #> Geometry type: POINT #> Dimension:     XY #> Bounding box:  xmin: 431110 ymin: 5337730 xmax: 438550 ymax: 5343230 #> CRS:           +proj=utm +zone=17 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs #> First 10 features: #>        type zmean pzabove2  zsd               geometry #> 1  existing  5.02      8.3 6.18 POINT (434610 5338890) #> 2  existing  5.85     75.1 3.02 POINT (437190 5342830) #> 3  existing 14.78     96.7 6.79 POINT (434950 5338430) #> 4  existing 16.62     76.6 7.58 POINT (436090 5339590) #> 5  existing  4.59     34.3 2.53 POINT (438190 5337850) #> 6  existing  4.07     29.0 2.32 POINT (434770 5339830) #> 7  existing 11.05     97.6 4.04 POINT (434090 5341690) #> 8  existing  6.10     70.5 2.56 POINT (432050 5341670) #> 9  existing  4.50     90.6 2.44 POINT (434110 5343130) #> 10 existing 13.75     77.1 4.37 POINT (432490 5342030) sample_ahels(mraster = mraster[[1:3]], # input mraster - first 3 layers only              existing = existing, # existing samples              nQuant = 20, # define 20 quantiles              nSamp = 300, # total samples desired              filename = tempfile(fileext = \".shp\")) # write samples to disc #> Simple feature collection with 500 features and 4 fields #> Geometry type: POINT #> Dimension:     XY #> Bounding box:  xmin: 431110 ymin: 5337730 xmax: 438550 ymax: 5343230 #> CRS:           +proj=utm +zone=17 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs #> First 10 features: #>        type zmean pzabove2  zsd               geometry #> 1  existing  5.02      8.3 6.18 POINT (434610 5338890) #> 2  existing  5.85     75.1 3.02 POINT (437190 5342830) #> 3  existing 14.78     96.7 6.79 POINT (434950 5338430) #> 4  existing 16.62     76.6 7.58 POINT (436090 5339590) #> 5  existing  4.59     34.3 2.53 POINT (438190 5337850) #> 6  existing  4.07     29.0 2.32 POINT (434770 5339830) #> 7  existing 11.05     97.6 4.04 POINT (434090 5341690) #> 8  existing  6.10     70.5 2.56 POINT (432050 5341670) #> 9  existing  4.50     90.6 2.44 POINT (434110 5343130) #> 10 existing 13.75     77.1 4.37 POINT (432490 5342030)"},{"path":"/articles/sgsR.html","id":"str","dir":"Articles","previous_headings":"","what":"Algorithm structure","title":"sgsR","text":"sgsR scripted primarily using terra package raster processing sf package vector manipulation. 3 primary function verbs package currently uses: strat_* - stratify verb implies functions applying stratification algorithms input metrics raster mraster output stratified raster sraster. sample_* - sample verb implies functions extracting samples srasters produced strat_* functions. algorithms (e.g. sample_srs(), sample_balanced(), sample_systematic()) able take mrasters inputs dependent stratified inputs sampling. calculate_* - calculate verb implies functions performing calculations used consequent processing. use predefined sample analysis algorithms calculate_representation(), calculate_coobs() also included.","code":""},{"path":"/articles/sgsR.html","id":"example-data","dir":"Articles","previous_headings":"","what":"Example data","title":"sgsR","text":"Worked examples functions provided using data internal package. load internal mraster road access data use following code. Follow along machine see outputs get better sense package functions.","code":""},{"path":"/articles/sgsR.html","id":"mrast","dir":"Articles","previous_headings":"Example data","what":"Metrics rasters - mraster","title":"sgsR","text":"","code":"library(sgsR) library(terra) library(sf)  #--- Load mraster and access files ---# r <- system.file(\"extdata\", \"wall_metrics.tif\", package = \"sgsR\")  #--- load the mraster using the terra package ---# mraster <- terra::rast(r)"},{"path":"/articles/sgsR.html","id":"vect","dir":"Articles","previous_headings":"Example data","what":"Road access data","title":"sgsR","text":"plot see first band (zmax) mraster access vector overlaid.","code":"a <- system.file(\"extdata\", \"roads.shp\", package = \"sgsR\")  #--- load the access vector using the sf package ---# access <- sf::st_read(a) #> Reading layer `roads' from data source  #>   `C:\\Users\\tgood.stu\\Documents\\R\\win-library\\4.1\\sgsR\\extdata\\roads.shp'  #>   using driver `ESRI Shapefile' #> Simple feature collection with 167 features and 2 fields #> Geometry type: MULTILINESTRING #> Dimension:     XY #> Bounding box:  xmin: 431100 ymin: 5337700 xmax: 438560 ymax: 5343240 #> Projected CRS: UTM_Zone_17_Northern_Hemisphere terra::plot(mraster[[1]]) terra::plot(access, add = TRUE, col = \"black\")"},{"path":"/articles/sgsR.html","id":"srast","dir":"Articles","previous_headings":"","what":"Stratified rasters - sraster","title":"sgsR","text":"purposes tutorial also going show produce basic sraster existing sample data used examples . make sraster use strat_kmeans() function input mraster stratified using kmeans algorithm.  sraster produced apply sample_srs() algorithm randomly samples points within sraster produce existing sample dataset.  now mraster, access, sraster existing data sets generated. Expect see data used examples document.","code":"#--- apply kmeans algorithm to metrics raster ---# sraster <- strat_kmeans(mraster = mraster, # use mraster as input for sampling                         nStrata = 4, # algorithm will produce 4 strata                         plot = TRUE) # algorithm will plot output #--- set seed ---# set.seed(2021)  #--- apply kmeans algorithm to metrics raster ---# existing <- sample_srs(raster = mraster, # use mraster as input for sampling                        nSamp = 200, # request 200 samples be taken                        mindist = 100, # define that samples must be 100 m apart                        plot = TRUE) # algorithm will plot output"},{"path":"/articles/sgsR.html","id":"pipe","dir":"Articles","previous_headings":"","what":"%>%","title":"sgsR","text":"sgsR package leverages %>% operator magrittr package. allows us “pipe” operations together save amount code needed achieve outcome. simple example .","code":"#--- non piped ---# sraster <- strat_kmeans(mraster = mraster, # use mraster as input for sampling                         nStrata = 4, # algorithm will produce 4 strata                         plot = TRUE) # algorithm will plot output  existing <- sample_srs(raster = sraster, # use mraster as input for sampling                        nSamp = 200, # request 200 samples be taken                        mindist = 100, # define that samples must be 100 m apart                        plot = TRUE) # algorithm will plot output  extract_metrics(mraster = mraster,                 existing = existing)   #--- piped ---# strat_kmeans(mraster = mraster, nStrata = 4) %>%   sample_srs(., nSamp = 200, mindist = 100) %>%   extract_metrics(mraster = mraster, existing = .)"},{"path":"/articles/stratification.html","id":"kmeans","dir":"Articles","previous_headings":"","what":"strat_kmeans","title":"stratification","text":"provide preliminary example strat_kmeans() algorithm prepare sraster input data . Notice nothing plotted… ’s plot = FALSE default functions sgsR. See examples plot = TRUE.","code":"#--- perform stratification using k-means ---# strat_kmeans(mraster = mraster, # input              nStrata = 5) # algorithm will produce 4 strata #> class       : SpatRaster  #> dimensions  : 277, 373, 1  (nrow, ncol, nlyr) #> resolution  : 20, 20  (x, y) #> extent      : 431100, 438560, 5337700, 5343240  (xmin, xmax, ymin, ymax) #> coord. ref. : UTM Zone 17, Northern Hemisphere  #> source      : memory  #> name        : strata  #> min value   :      1  #> max value   :      5 strat_kmeans(mraster = mraster, # input              nStrata = 10, # algorithm will produce 10 strata              iter = 1000, # set minimum number of iterations to determine kmeans centers              algorithm = \"MacQueen\", # use MacQueen algorithm              plot = TRUE) # plot output #> class       : SpatRaster  #> dimensions  : 277, 373, 1  (nrow, ncol, nlyr) #> resolution  : 20, 20  (x, y) #> extent      : 431100, 438560, 5337700, 5343240  (xmin, xmax, ymin, ymax) #> coord. ref. : UTM Zone 17, Northern Hemisphere  #> source      : memory  #> name        : strata  #> min value   :      1  #> max value   :     10 strat_kmeans(mraster = mraster, # input              nStrata = 5, # algorithm will produce 4 strata              center = FALSE, # do not center data              scale = FALSE, # do not scale data              plot = TRUE, # plot output              filename = tempfile(fileext = \".tif\"), # write output sraster to file              overwrite = TRUE) # overwrite file on disc if it exists #> class       : SpatRaster  #> dimensions  : 277, 373, 1  (nrow, ncol, nlyr) #> resolution  : 20, 20  (x, y) #> extent      : 431100, 438560, 5337700, 5343240  (xmin, xmax, ymin, ymax) #> coord. ref. : UTM Zone 17, Northern Hemisphere  #> source      : memory  #> name        : strata  #> min value   :      1  #> max value   :      5"},{"path":"/articles/stratification.html","id":"strat_quantiles","dir":"Articles","previous_headings":"","what":"strat_quantiles","title":"stratification","text":"strat_quantiles() algorithm divides data equally sized strata (nStrata). Similar strat_breaks(), algorithm allows stratification single mraster, user can supply secondary mraster (mraster2) specify associated number desired strata (nStrata2). dual stratification output always result product \\(nStrata * nStrata2\\).","code":"#--- perform quantiles stratification ---# strat_quantiles(mraster = mraster$zq90,                 nStrata = 6,                 plot = TRUE) #> class       : SpatRaster  #> dimensions  : 277, 373, 1  (nrow, ncol, nlyr) #> resolution  : 20, 20  (x, y) #> extent      : 431100, 438560, 5337700, 5343240  (xmin, xmax, ymin, ymax) #> coord. ref. : UTM Zone 17, Northern Hemisphere  #> source      : memory  #> name        : strata  #> min value   :      1  #> max value   :      6  #--- dual stratification - will produce 12 output strata ---# strat_quantiles(mraster = mraster$zq90,                  mraster2 = mraster$zsd,                 nStrata = 3,                  nStrata2 = 4) #> class       : SpatRaster  #> dimensions  : 277, 373, 1  (nrow, ncol, nlyr) #> resolution  : 20, 20  (x, y) #> extent      : 431100, 438560, 5337700, 5343240  (xmin, xmax, ymin, ymax) #> coord. ref. : UTM Zone 17, Northern Hemisphere  #> source      : memory  #> name        : strata  #> min value   :      1  #> max value   :     12"},{"path":"/articles/stratification.html","id":"strat_breaks","dir":"Articles","previous_headings":"","what":"strat_breaks","title":"stratification","text":"strat_breaks() function stratifies data based user-defined breaks covariates. single metric can defined additional metric2 can supplied. breaks breaks2 correspond user-defined breaks metric metric2 respectively. breaks created can input function using breaks breaks2 parameters.","code":"#--- perform stratification using user-defined breaks ---#  #--- define breaks for metric ---# breaks <- c(seq(0,100,20))  breaks #> [1]   0  20  40  60  80 100  #--- perform stratification using user-defined breaks ---#  values <- terra::values(mraster$zq90)  #--- define breaks for metric ---# breaks2 <- c(5,10,15,20,25)  breaks2 #> [1]  5 10 15 20 25 #--- stratify on 1 metric only ---#  strat_breaks(mraster = mraster$pzabove2,              breaks = breaks,              plot = TRUE) #> class       : SpatRaster  #> dimensions  : 277, 373, 1  (nrow, ncol, nlyr) #> resolution  : 20, 20  (x, y) #> extent      : 431100, 438560, 5337700, 5343240  (xmin, xmax, ymin, ymax) #> coord. ref. : UTM Zone 17, Northern Hemisphere  #> source      : memory  #> name        : strata  #> min value   :      1  #> max value   :      6 #--- stratify on 1 metric only ---#  strat_breaks(mraster = mraster$zq90,              breaks = breaks2,              plot = TRUE) #> class       : SpatRaster  #> dimensions  : 277, 373, 1  (nrow, ncol, nlyr) #> resolution  : 20, 20  (x, y) #> extent      : 431100, 438560, 5337700, 5343240  (xmin, xmax, ymin, ymax) #> coord. ref. : UTM Zone 17, Northern Hemisphere  #> source      : memory  #> name        : strata  #> min value   :      1  #> max value   :      6"},{"path":"/articles/stratification.html","id":"strat_poly","dir":"Articles","previous_headings":"","what":"strat_poly","title":"stratification","text":"strat_poly() algorithm stratifies based spatial polygon attributes features. user may wish stratify based categorical empirical variables given ALS data (e.g. species forest inventory polygons). method allows user define attribute interest well features within attributes grouped stratification. user defines input poly associated attribute. raster layer must provided guide spatial extent resolution output stratification polygon. Based vector list features, stratification applied, polygon rasterized appropriate strata. attribute column must defined, features within must specified define number composition output strata. case attribute = \"NUTRIENTS\" features within NUTRIENTS (poor, rich, medium) define 3 desired output classes.  features can also made amalgamate classes. example rich medium features combined low left alone. 2 vectors added list, outputs 2 classes (low & rich/medium).  notice details parameter present . returns output outRaster, $lookUp table associated strata, polygon ($poly) created drive stratification based attribute features provided users.","code":"#--- load in polygon coverage ---# poly <- system.file(\"extdata\", \"inventory_polygons.shp\", package = \"sgsR\")  fri <- sf::st_read(poly) #> Reading layer `inventory_polygons' from data source  #>   `C:\\Users\\tgood.stu\\Documents\\R\\win-library\\4.1\\sgsR\\extdata\\inventory_polygons.shp'  #>   using driver `ESRI Shapefile' #> Simple feature collection with 632 features and 3 fields #> Geometry type: MULTIPOLYGON #> Dimension:     XY #> Bounding box:  xmin: 431100 ymin: 5337700 xmax: 438560 ymax: 5343240 #> Projected CRS: UTM_Zone_17_Northern_Hemisphere #--- stratify polygon coverage ---# #--- specify polygon attribute to stratify ---#  attribute <- \"NUTRIENTS\"  #--- specify features within attribute & how they should be grouped ---# #--- as a single vector ---#  features <- c(\"poor\", \"rich\", \"medium\")  srasterpoly <- strat_poly(poly = fri, # input polygon                           attribute = attribute, # attribute to stratify by                           features = features, # features within attribute                           raster = sraster, # raster to define extent and resolution for output                           plot = TRUE) # plot output #--- or as multiple lists ---# g1 <- \"poor\" g2 <- c(\"rich\", \"medium\")  features <- list(g1, g2)  strat_poly(poly = fri,            attribute = attribute,            features = features,            raster = sraster,            plot = TRUE,            details = TRUE) #> $outRaster #> class       : SpatRaster  #> dimensions  : 277, 373, 1  (nrow, ncol, nlyr) #> resolution  : 20, 20  (x, y) #> extent      : 431100, 438560, 5337700, 5343240  (xmin, xmax, ymin, ymax) #> coord. ref. : UTM Zone 17, Northern Hemisphere  #> source      : memory  #> name        : strata  #> min value   :      1  #> max value   :      2  #>  #> $lookUp #>   strata features #> 1      1     poor #> 2      2     rich #> 3      2   medium #>  #> $poly #>  class       : SpatVector  #>  geometry    : polygons  #>  dimensions  : 524, 2  (geometries, attributes) #>  extent      : 431100, 438560, 5337700, 5343240  (xmin, xmax, ymin, ymax) #>  coord. ref. : UTM_Zone_17_Northern_Hemisphere  #>  names       : NUTRIENTS strata #>  type        :     <chr>  <num> #>  values      :      poor      1 #>                     poor      1 #>                     poor      1"},{"path":"/articles/stratification.html","id":"strat_map","dir":"Articles","previous_headings":"","what":"strat_map","title":"stratification","text":"may instance multiple levels stratification desired. instance user may want combine output strat_poly() 3 classes, 4 class kmeans stratification kmeans. total number classes always multiplicative number strata. .e. sraster 3 strata sraster2 4 strata output strat_map() 12 strata total.  convention numeric value output strata concatenation (merging) sraster strata sraster2 strata. See $lookUp clear depiction .","code":"#--- map srasters ---# strat_map(sraster = srasterpoly, # strat_poly 3 class stratification           sraster2 = sraster, # strat_kmeans 4 class stratification           plot = TRUE) #> class       : SpatRaster  #> dimensions  : 277, 373, 1  (nrow, ncol, nlyr) #> resolution  : 20, 20  (x, y) #> extent      : 431100, 438560, 5337700, 5343240  (xmin, xmax, ymin, ymax) #> coord. ref. : UTM Zone 17, Northern Hemisphere  #> source      : memory  #> name        : strata  #> min value   :     11  #> max value   :     34 strat_map(sraster = srasterpoly, # strat_poly 3 class stratification           sraster2 = sraster, # strat_poly 3 class stratification           stack = TRUE, # stack input and oputput strata into multi layer ouput raster           details = TRUE, # provide additional details           plot = TRUE) # plot output #> Stacking sraster, sraster2, and their combination (stratamapped). #> $outRaster #> class       : SpatRaster  #> dimensions  : 277, 373, 3  (nrow, ncol, nlyr) #> resolution  : 20, 20  (x, y) #> extent      : 431100, 438560, 5337700, 5343240  (xmin, xmax, ymin, ymax) #> coord. ref. : UTM Zone 17, Northern Hemisphere  #> sources     : memory   #>               memory   #>               memory   #> names       : strata, strata2, stratamapped  #> min values  :      1,       1,           11  #> max values  :      3,       4,           34  #>  #> $lookUp #>    strata strata2 stratamapped #> 1       3       2           32 #> 2       3       1           31 #> 3       1       4           14 #> 4       1       3           13 #> 5       3       4           34 #> 6       3       3           33 #> 7       1       2           12 #> 8       1       1           11 #> 9       2       1           21 #> 10      2       2           22 #> 11      2       4           24 #> 12      2       3           23"},{"path":"/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Tristan RH Goodbody. Author, maintainer. Nicholas C Coops. Author. Martin Queinnec. Author.","code":""},{"path":"/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Tristan RH Goodbody, Nicholas C Coops Martin Queinnec (2022). Structurally Guided Sampling Approaches using ALS Data. R package version 1.0.1. https://github.com/tgoodbody/sgsR","code":"@Manual{,   title = {Structurally Guided Sampling Approaches using ALS Data},   author = {Tristan RH Goodbody and Nicholas C Coops and Martin Queinnec},   year = {2022},   note = {R package version 1.0.1},   url = {https://github.com/tgoodbody/sgsR}, }"},{"path":"/index.html","id":"sgsr---structurally-guided-sampling-","dir":"","previous_headings":"","what":"sgsR","title":"sgsR","text":"sgsR designed implement structurally guided sampling approaches enhanced forest inventories. package designed function using rasterized airborne laser scanning (ALS; Lidar) metrics allow stratification forested areas based structure.","code":""},{"path":"/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"sgsR","text":"can install released version sgsR Github :","code":"install.packages(\"devtools\") devtools::install_github(\"https://github.com/tgoodbody/sgsR\") library(sgsR)"},{"path":"/index.html","id":"implementation","dir":"","previous_headings":"","what":"Implementation","title":"sgsR","text":"Describe package fundamentals - vignette(\"sgsR\") Overview sampling algorithms - vignette(\"sampling\") Overview stratification algorithms - vignette(\"stratification\") Overview calculate algorithms - vignette(\"calculating\")","code":""},{"path":"/index.html","id":"collaborators","dir":"","previous_headings":"","what":"Collaborators","title":"sgsR","text":"thankful continued collaboration academic, private industry, government institutions help improve sgsR. Special thanks :","code":""},{"path":"/index.html","id":"funding","dir":"","previous_headings":"","what":"Funding","title":"sgsR","text":"Development sgsR made possible thanks financial support Canadian Wood Fibre Centre’s Forest Innovation Program.","code":""},{"path":"/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"GNU General Public License","title":"GNU General Public License","text":"Version 3, 29 June 2007Copyright © 2007 Free Software Foundation, Inc. <http://fsf.org/> Everyone permitted copy distribute verbatim copies license document, changing allowed.","code":""},{"path":"/LICENSE.html","id":"preamble","dir":"","previous_headings":"","what":"Preamble","title":"GNU General Public License","text":"GNU General Public License free, copyleft license software kinds works. licenses software practical works designed take away freedom share change works. contrast, GNU General Public License intended guarantee freedom share change versions program–make sure remains free software users. , Free Software Foundation, use GNU General Public License software; applies also work released way authors. can apply programs, . speak free software, referring freedom, price. General Public Licenses designed make sure freedom distribute copies free software (charge wish), receive source code can get want , can change software use pieces new free programs, know can things. protect rights, need prevent others denying rights asking surrender rights. Therefore, certain responsibilities distribute copies software, modify : responsibilities respect freedom others. example, distribute copies program, whether gratis fee, must pass recipients freedoms received. must make sure , , receive can get source code. must show terms know rights. Developers use GNU GPL protect rights two steps: (1) assert copyright software, (2) offer License giving legal permission copy, distribute /modify . developers’ authors’ protection, GPL clearly explains warranty free software. users’ authors’ sake, GPL requires modified versions marked changed, problems attributed erroneously authors previous versions. devices designed deny users access install run modified versions software inside , although manufacturer can . fundamentally incompatible aim protecting users’ freedom change software. systematic pattern abuse occurs area products individuals use, precisely unacceptable. Therefore, designed version GPL prohibit practice products. problems arise substantially domains, stand ready extend provision domains future versions GPL, needed protect freedom users. Finally, every program threatened constantly software patents. States allow patents restrict development use software general-purpose computers, , wish avoid special danger patents applied free program make effectively proprietary. prevent , GPL assures patents used render program non-free. precise terms conditions copying, distribution modification follow.","code":""},{"path":[]},{"path":"/LICENSE.html","id":"0-definitions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"0. Definitions","title":"GNU General Public License","text":"“License” refers version 3 GNU General Public License. “Copyright” also means copyright-like laws apply kinds works, semiconductor masks. “Program” refers copyrightable work licensed License. licensee addressed “”. “Licensees” “recipients” may individuals organizations. “modify” work means copy adapt part work fashion requiring copyright permission, making exact copy. resulting work called “modified version” earlier work work “based ” earlier work. “covered work” means either unmodified Program work based Program. “propagate” work means anything , without permission, make directly secondarily liable infringement applicable copyright law, except executing computer modifying private copy. Propagation includes copying, distribution (without modification), making available public, countries activities well. “convey” work means kind propagation enables parties make receive copies. Mere interaction user computer network, transfer copy, conveying. interactive user interface displays “Appropriate Legal Notices” extent includes convenient prominently visible feature (1) displays appropriate copyright notice, (2) tells user warranty work (except extent warranties provided), licensees may convey work License, view copy License. interface presents list user commands options, menu, prominent item list meets criterion.","code":""},{"path":"/LICENSE.html","id":"1-source-code","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"1. Source Code","title":"GNU General Public License","text":"“source code” work means preferred form work making modifications . “Object code” means non-source form work. “Standard Interface” means interface either official standard defined recognized standards body, , case interfaces specified particular programming language, one widely used among developers working language. “System Libraries” executable work include anything, work whole, () included normal form packaging Major Component, part Major Component, (b) serves enable use work Major Component, implement Standard Interface implementation available public source code form. “Major Component”, context, means major essential component (kernel, window system, ) specific operating system () executable work runs, compiler used produce work, object code interpreter used run . “Corresponding Source” work object code form means source code needed generate, install, (executable work) run object code modify work, including scripts control activities. However, include work’s System Libraries, general-purpose tools generally available free programs used unmodified performing activities part work. example, Corresponding Source includes interface definition files associated source files work, source code shared libraries dynamically linked subprograms work specifically designed require, intimate data communication control flow subprograms parts work. Corresponding Source need include anything users can regenerate automatically parts Corresponding Source. Corresponding Source work source code form work.","code":""},{"path":"/LICENSE.html","id":"2-basic-permissions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"2. Basic Permissions","title":"GNU General Public License","text":"rights granted License granted term copyright Program, irrevocable provided stated conditions met. License explicitly affirms unlimited permission run unmodified Program. output running covered work covered License output, given content, constitutes covered work. License acknowledges rights fair use equivalent, provided copyright law. may make, run propagate covered works convey, without conditions long license otherwise remains force. may convey covered works others sole purpose make modifications exclusively , provide facilities running works, provided comply terms License conveying material control copyright. thus making running covered works must exclusively behalf, direction control, terms prohibit making copies copyrighted material outside relationship . Conveying circumstances permitted solely conditions stated . Sublicensing allowed; section 10 makes unnecessary.","code":""},{"path":"/LICENSE.html","id":"3-protecting-users-legal-rights-from-anti-circumvention-law","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"3. Protecting Users’ Legal Rights From Anti-Circumvention Law","title":"GNU General Public License","text":"covered work shall deemed part effective technological measure applicable law fulfilling obligations article 11 WIPO copyright treaty adopted 20 December 1996, similar laws prohibiting restricting circumvention measures. convey covered work, waive legal power forbid circumvention technological measures extent circumvention effected exercising rights License respect covered work, disclaim intention limit operation modification work means enforcing, work’s users, third parties’ legal rights forbid circumvention technological measures.","code":""},{"path":"/LICENSE.html","id":"4-conveying-verbatim-copies","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"4. Conveying Verbatim Copies","title":"GNU General Public License","text":"may convey verbatim copies Program’s source code receive , medium, provided conspicuously appropriately publish copy appropriate copyright notice; keep intact notices stating License non-permissive terms added accord section 7 apply code; keep intact notices absence warranty; give recipients copy License along Program. may charge price price copy convey, may offer support warranty protection fee.","code":""},{"path":"/LICENSE.html","id":"5-conveying-modified-source-versions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"5. Conveying Modified Source Versions","title":"GNU General Public License","text":"may convey work based Program, modifications produce Program, form source code terms section 4, provided also meet conditions: ) work must carry prominent notices stating modified , giving relevant date. b) work must carry prominent notices stating released License conditions added section 7. requirement modifies requirement section 4 “keep intact notices”. c) must license entire work, whole, License anyone comes possession copy. License therefore apply, along applicable section 7 additional terms, whole work, parts, regardless packaged. License gives permission license work way, invalidate permission separately received . d) work interactive user interfaces, must display Appropriate Legal Notices; however, Program interactive interfaces display Appropriate Legal Notices, work need make . compilation covered work separate independent works, nature extensions covered work, combined form larger program, volume storage distribution medium, called “aggregate” compilation resulting copyright used limit access legal rights compilation’s users beyond individual works permit. Inclusion covered work aggregate cause License apply parts aggregate.","code":""},{"path":"/LICENSE.html","id":"6-conveying-non-source-forms","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"6. Conveying Non-Source Forms","title":"GNU General Public License","text":"may convey covered work object code form terms sections 4 5, provided also convey machine-readable Corresponding Source terms License, one ways: ) Convey object code , embodied , physical product (including physical distribution medium), accompanied Corresponding Source fixed durable physical medium customarily used software interchange. b) Convey object code , embodied , physical product (including physical distribution medium), accompanied written offer, valid least three years valid long offer spare parts customer support product model, give anyone possesses object code either (1) copy Corresponding Source software product covered License, durable physical medium customarily used software interchange, price reasonable cost physically performing conveying source, (2) access copy Corresponding Source network server charge. c) Convey individual copies object code copy written offer provide Corresponding Source. alternative allowed occasionally noncommercially, received object code offer, accord subsection 6b. d) Convey object code offering access designated place (gratis charge), offer equivalent access Corresponding Source way place charge. need require recipients copy Corresponding Source along object code. place copy object code network server, Corresponding Source may different server (operated third party) supports equivalent copying facilities, provided maintain clear directions next object code saying find Corresponding Source. Regardless server hosts Corresponding Source, remain obligated ensure available long needed satisfy requirements. e) Convey object code using peer--peer transmission, provided inform peers object code Corresponding Source work offered general public charge subsection 6d. separable portion object code, whose source code excluded Corresponding Source System Library, need included conveying object code work. “User Product” either (1) “consumer product”, means tangible personal property normally used personal, family, household purposes, (2) anything designed sold incorporation dwelling. determining whether product consumer product, doubtful cases shall resolved favor coverage. particular product received particular user, “normally used” refers typical common use class product, regardless status particular user way particular user actually uses, expects expected use, product. product consumer product regardless whether product substantial commercial, industrial non-consumer uses, unless uses represent significant mode use product. “Installation Information” User Product means methods, procedures, authorization keys, information required install execute modified versions covered work User Product modified version Corresponding Source. information must suffice ensure continued functioning modified object code case prevented interfered solely modification made. convey object code work section , , specifically use , User Product, conveying occurs part transaction right possession use User Product transferred recipient perpetuity fixed term (regardless transaction characterized), Corresponding Source conveyed section must accompanied Installation Information. requirement apply neither third party retains ability install modified object code User Product (example, work installed ROM). requirement provide Installation Information include requirement continue provide support service, warranty, updates work modified installed recipient, User Product modified installed. Access network may denied modification materially adversely affects operation network violates rules protocols communication across network. Corresponding Source conveyed, Installation Information provided, accord section must format publicly documented (implementation available public source code form), must require special password key unpacking, reading copying.","code":""},{"path":"/LICENSE.html","id":"7-additional-terms","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"7. Additional Terms","title":"GNU General Public License","text":"“Additional permissions” terms supplement terms License making exceptions one conditions. Additional permissions applicable entire Program shall treated though included License, extent valid applicable law. additional permissions apply part Program, part may used separately permissions, entire Program remains governed License without regard additional permissions. convey copy covered work, may option remove additional permissions copy, part . (Additional permissions may written require removal certain cases modify work.) may place additional permissions material, added covered work, can give appropriate copyright permission. Notwithstanding provision License, material add covered work, may (authorized copyright holders material) supplement terms License terms: ) Disclaiming warranty limiting liability differently terms sections 15 16 License; b) Requiring preservation specified reasonable legal notices author attributions material Appropriate Legal Notices displayed works containing ; c) Prohibiting misrepresentation origin material, requiring modified versions material marked reasonable ways different original version; d) Limiting use publicity purposes names licensors authors material; e) Declining grant rights trademark law use trade names, trademarks, service marks; f) Requiring indemnification licensors authors material anyone conveys material (modified versions ) contractual assumptions liability recipient, liability contractual assumptions directly impose licensors authors. non-permissive additional terms considered “restrictions” within meaning section 10. Program received , part , contains notice stating governed License along term restriction, may remove term. license document contains restriction permits relicensing conveying License, may add covered work material governed terms license document, provided restriction survive relicensing conveying. add terms covered work accord section, must place, relevant source files, statement additional terms apply files, notice indicating find applicable terms. Additional terms, permissive non-permissive, may stated form separately written license, stated exceptions; requirements apply either way.","code":""},{"path":"/LICENSE.html","id":"8-termination","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"8. Termination","title":"GNU General Public License","text":"may propagate modify covered work except expressly provided License. attempt otherwise propagate modify void, automatically terminate rights License (including patent licenses granted third paragraph section 11). However, cease violation License, license particular copyright holder reinstated () provisionally, unless copyright holder explicitly finally terminates license, (b) permanently, copyright holder fails notify violation reasonable means prior 60 days cessation. Moreover, license particular copyright holder reinstated permanently copyright holder notifies violation reasonable means, first time received notice violation License (work) copyright holder, cure violation prior 30 days receipt notice. Termination rights section terminate licenses parties received copies rights License. rights terminated permanently reinstated, qualify receive new licenses material section 10.","code":""},{"path":"/LICENSE.html","id":"9-acceptance-not-required-for-having-copies","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"9. Acceptance Not Required for Having Copies","title":"GNU General Public License","text":"required accept License order receive run copy Program. Ancillary propagation covered work occurring solely consequence using peer--peer transmission receive copy likewise require acceptance. However, nothing License grants permission propagate modify covered work. actions infringe copyright accept License. Therefore, modifying propagating covered work, indicate acceptance License .","code":""},{"path":"/LICENSE.html","id":"10-automatic-licensing-of-downstream-recipients","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"10. Automatic Licensing of Downstream Recipients","title":"GNU General Public License","text":"time convey covered work, recipient automatically receives license original licensors, run, modify propagate work, subject License. responsible enforcing compliance third parties License. “entity transaction” transaction transferring control organization, substantially assets one, subdividing organization, merging organizations. propagation covered work results entity transaction, party transaction receives copy work also receives whatever licenses work party’s predecessor interest give previous paragraph, plus right possession Corresponding Source work predecessor interest, predecessor can get reasonable efforts. may impose restrictions exercise rights granted affirmed License. example, may impose license fee, royalty, charge exercise rights granted License, may initiate litigation (including cross-claim counterclaim lawsuit) alleging patent claim infringed making, using, selling, offering sale, importing Program portion .","code":""},{"path":"/LICENSE.html","id":"11-patents","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"11. Patents","title":"GNU General Public License","text":"“contributor” copyright holder authorizes use License Program work Program based. work thus licensed called contributor’s “contributor version”. contributor’s “essential patent claims” patent claims owned controlled contributor, whether already acquired hereafter acquired, infringed manner, permitted License, making, using, selling contributor version, include claims infringed consequence modification contributor version. purposes definition, “control” includes right grant patent sublicenses manner consistent requirements License. contributor grants non-exclusive, worldwide, royalty-free patent license contributor’s essential patent claims, make, use, sell, offer sale, import otherwise run, modify propagate contents contributor version. following three paragraphs, “patent license” express agreement commitment, however denominated, enforce patent (express permission practice patent covenant sue patent infringement). “grant” patent license party means make agreement commitment enforce patent party. convey covered work, knowingly relying patent license, Corresponding Source work available anyone copy, free charge terms License, publicly available network server readily accessible means, must either (1) cause Corresponding Source available, (2) arrange deprive benefit patent license particular work, (3) arrange, manner consistent requirements License, extend patent license downstream recipients. “Knowingly relying” means actual knowledge , patent license, conveying covered work country, recipient’s use covered work country, infringe one identifiable patents country reason believe valid. , pursuant connection single transaction arrangement, convey, propagate procuring conveyance , covered work, grant patent license parties receiving covered work authorizing use, propagate, modify convey specific copy covered work, patent license grant automatically extended recipients covered work works based . patent license “discriminatory” include within scope coverage, prohibits exercise , conditioned non-exercise one rights specifically granted License. may convey covered work party arrangement third party business distributing software, make payment third party based extent activity conveying work, third party grants, parties receive covered work , discriminatory patent license () connection copies covered work conveyed (copies made copies), (b) primarily connection specific products compilations contain covered work, unless entered arrangement, patent license granted, prior 28 March 2007. Nothing License shall construed excluding limiting implied license defenses infringement may otherwise available applicable patent law.","code":""},{"path":"/LICENSE.html","id":"12-no-surrender-of-others-freedom","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"12. No Surrender of Others’ Freedom","title":"GNU General Public License","text":"conditions imposed (whether court order, agreement otherwise) contradict conditions License, excuse conditions License. convey covered work satisfy simultaneously obligations License pertinent obligations, consequence may convey . example, agree terms obligate collect royalty conveying convey Program, way satisfy terms License refrain entirely conveying Program.","code":""},{"path":"/LICENSE.html","id":"13-use-with-the-gnu-affero-general-public-license","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"13. Use with the GNU Affero General Public License","title":"GNU General Public License","text":"Notwithstanding provision License, permission link combine covered work work licensed version 3 GNU Affero General Public License single combined work, convey resulting work. terms License continue apply part covered work, special requirements GNU Affero General Public License, section 13, concerning interaction network apply combination .","code":""},{"path":"/LICENSE.html","id":"14-revised-versions-of-this-license","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"14. Revised Versions of this License","title":"GNU General Public License","text":"Free Software Foundation may publish revised /new versions GNU General Public License time time. new versions similar spirit present version, may differ detail address new problems concerns. version given distinguishing version number. Program specifies certain numbered version GNU General Public License “later version” applies , option following terms conditions either numbered version later version published Free Software Foundation. Program specify version number GNU General Public License, may choose version ever published Free Software Foundation. Program specifies proxy can decide future versions GNU General Public License can used, proxy’s public statement acceptance version permanently authorizes choose version Program. Later license versions may give additional different permissions. However, additional obligations imposed author copyright holder result choosing follow later version.","code":""},{"path":"/LICENSE.html","id":"15-disclaimer-of-warranty","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"15. Disclaimer of Warranty","title":"GNU General Public License","text":"WARRANTY PROGRAM, EXTENT PERMITTED APPLICABLE LAW. EXCEPT OTHERWISE STATED WRITING COPYRIGHT HOLDERS /PARTIES PROVIDE PROGRAM “” WITHOUT WARRANTY KIND, EITHER EXPRESSED IMPLIED, INCLUDING, LIMITED , IMPLIED WARRANTIES MERCHANTABILITY FITNESS PARTICULAR PURPOSE. ENTIRE RISK QUALITY PERFORMANCE PROGRAM . PROGRAM PROVE DEFECTIVE, ASSUME COST NECESSARY SERVICING, REPAIR CORRECTION.","code":""},{"path":"/LICENSE.html","id":"16-limitation-of-liability","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"16. Limitation of Liability","title":"GNU General Public License","text":"EVENT UNLESS REQUIRED APPLICABLE LAW AGREED WRITING COPYRIGHT HOLDER, PARTY MODIFIES /CONVEYS PROGRAM PERMITTED , LIABLE DAMAGES, INCLUDING GENERAL, SPECIAL, INCIDENTAL CONSEQUENTIAL DAMAGES ARISING USE INABILITY USE PROGRAM (INCLUDING LIMITED LOSS DATA DATA RENDERED INACCURATE LOSSES SUSTAINED THIRD PARTIES FAILURE PROGRAM OPERATE PROGRAMS), EVEN HOLDER PARTY ADVISED POSSIBILITY DAMAGES.","code":""},{"path":"/LICENSE.html","id":"17-interpretation-of-sections-15-and-16","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"17. Interpretation of Sections 15 and 16","title":"GNU General Public License","text":"disclaimer warranty limitation liability provided given local legal effect according terms, reviewing courts shall apply local law closely approximates absolute waiver civil liability connection Program, unless warranty assumption liability accompanies copy Program return fee. END TERMS CONDITIONS","code":""},{"path":"/LICENSE.html","id":"how-to-apply-these-terms-to-your-new-programs","dir":"","previous_headings":"","what":"How to Apply These Terms to Your New Programs","title":"GNU General Public License","text":"develop new program, want greatest possible use public, best way achieve make free software everyone can redistribute change terms. , attach following notices program. safest attach start source file effectively state exclusion warranty; file least “copyright” line pointer full notice found. Also add information contact electronic paper mail. program terminal interaction, make output short notice like starts interactive mode: hypothetical commands show w show c show appropriate parts General Public License. course, program’s commands might different; GUI interface, use “box”. also get employer (work programmer) school, , sign “copyright disclaimer” program, necessary. information , apply follow GNU GPL, see <http://www.gnu.org/licenses/>. GNU General Public License permit incorporating program proprietary programs. program subroutine library, may consider useful permit linking proprietary applications library. want , use GNU Lesser General Public License instead License. first, please read <http://www.gnu.org/philosophy/--lgpl.html>.","code":"<one line to give the program's name and a brief idea of what it does.> Copyright (C) <year>  <name of author>  This program is free software: you can redistribute it and/or modify it under the terms of the GNU General Public License as published by the Free Software Foundation, either version 3 of the License, or (at your option) any later version.  This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for more details.  You should have received a copy of the GNU General Public License along with this program.  If not, see <http://www.gnu.org/licenses/>. <program>  Copyright (C) <year>  <name of author> This program comes with ABSOLUTELY NO WARRANTY; for details type 'show w'. This is free software, and you are welcome to redistribute it under certain conditions; type 'show c' for details."},{"path":"/reference/calculate_ahels.html","id":null,"dir":"Reference","previous_headings":"","what":"Adapted Hypercube Evaluation of a Legacy Sample (ahels) — calculate_ahels","title":"Adapted Hypercube Evaluation of a Legacy Sample (ahels) — calculate_ahels","text":"Perform adapted Hypercube Evaluation Legacy Sample (ahels) algorithm using existing site data raster metrics. New samples allocated based quantile ratios existing sample covariate dataset.","code":""},{"path":"/reference/calculate_ahels.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Adapted Hypercube Evaluation of a Legacy Sample (ahels) — calculate_ahels","text":"","code":"calculate_ahels(   mraster,   existing,   nQuant = 10,   nSamp = NULL,   threshold = 0.9,   plot = FALSE,   details = FALSE,   filename = NULL,   overwrite = FALSE )"},{"path":"/reference/calculate_ahels.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Adapted Hypercube Evaluation of a Legacy Sample (ahels) — calculate_ahels","text":"mraster spatRaster. ALS metrics raster. existing sf. Samples resulting sample_* functions. nQuant Numeric. Number quantiles divide covariates samples . Quantiles cover least 1 percent area interest excluded returned NA. nSamp Numeric. Maximum number new samples allocate. provided, algorithm default allocating number samples provided. threshold Numeric. sample quantile ratio threshold establishing whether additional samples added. default = 0.9. Values close 1 can cause algorithm continually loop used sparingly. plot Logial. Plots existing (circles) new (crosses) samples first band mraster. details Logical. FALSE (default) output  stratification raster. TRUE return list $details additional stratification information  $raster output stratification spatRaster.  @param ... Additional arguments passed kmeans function. filename Character. Path write stratified raster disc. overwrite Logical. Specify whether filename overwritten disc.","code":""},{"path":"/reference/calculate_ahels.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Adapted Hypercube Evaluation of a Legacy Sample (ahels) — calculate_ahels","text":"Returns sf point object existing samples supplemental samples added ahels algorithm.","code":""},{"path":"/reference/calculate_ahels.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Adapted Hypercube Evaluation of a Legacy Sample (ahels) — calculate_ahels","text":"Special thanks Dr. Brendan Malone original implementation algorithm.","code":""},{"path":"/reference/calculate_ahels.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Adapted Hypercube Evaluation of a Legacy Sample (ahels) — calculate_ahels","text":"Malone BP, Minansy B, Brungard C. 2019. methods improve utility conditioned Latin hypercube sampling. PeerJ 7:e6451 DOI 10.7717/peerj.6451","code":""},{"path":[]},{"path":"/reference/calculate_ahels.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Adapted Hypercube Evaluation of a Legacy Sample (ahels) — calculate_ahels","text":"Tristan R.H. Goodbody","code":""},{"path":"/reference/calculate_ahels.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Adapted Hypercube Evaluation of a Legacy Sample (ahels) — calculate_ahels","text":"","code":"#--- Load raster and existing plots---# r <- system.file(\"extdata\", \"wall_metrics.tif\", package = \"sgsR\") mr <- terra::rast(r)  e <- system.file(\"extdata\", \"existing.shp\", package = \"sgsR\") e <- sf::st_read(e) #> Reading layer `existing' from data source  #>   `C:\\Users\\tgood.stu\\Documents\\R\\win-library\\4.1\\sgsR\\extdata\\existing.shp'  #>   using driver `ESRI Shapefile' #> Simple feature collection with 100 features and 1 field #> Geometry type: POINT #> Dimension:     XY #> Bounding box:  xmin: 431110 ymin: 5337750 xmax: 438550 ymax: 5343230 #> CRS:           unknown  calculate_ahels(   mraster = mr[[1:3]],   existing = e,   plot = TRUE ) #> Creating covariance matrix. #>    |                                                                       |                                                              |   0%   |                                                                       |                                                              |   1%   |                                                                       |=                                                             |   1%   |                                                                       |=                                                             |   2%   |                                                                       |==                                                            |   2%   |                                                                       |==                                                            |   3%   |                                                                       |==                                                            |   4%   |                                                                       |===                                                           |   4%   |                                                                       |===                                                           |   5%   |                                                                       |===                                                           |   6%   |                                                                       |====                                                          |   6%   |                                                                       |====                                                          |   7%   |                                                                       |=====                                                         |   7%   |                                                                       |=====                                                         |   8%   |                                                                       |=====                                                         |   9%   |                                                                       |======                                                        |   9%   |                                                                       |======                                                        |  10%   |                                                                       |=======                                                       |  10%   |                                                                       |=======                                                       |  11%   |                                                                       |=======                                                       |  12%   |                                                                       |========                                                      |  12%   |                                                                       |========                                                      |  13%   |                                                                       |========                                                      |  14%   |                                                                       |=========                                                     |  14%   |                                                                       |=========                                                     |  15%   |                                                                       |==========                                                    |  15%   |                                                                       |==========                                                    |  16%   |                                                                       |==========                                                    |  17%   |                                                                       |===========                                                   |  17%   |                                                                       |===========                                                   |  18%   |                                                                       |===========                                                   |  19%   |                                                                       |============                                                  |  19%   |                                                                       |============                                                  |  20%   |                                                                       |=============                                                 |  20%   |                                                                       |=============                                                 |  21%   |                                                                       |=============                                                 |  22%   |                                                                       |==============                                                |  22%   |                                                                       |==============                                                |  23%   |                                                                       |===============                                               |  23%   |                                                                       |===============                                               |  24%   |                                                                       |===============                                               |  25%   |                                                                       |================                                              |  25%   |                                                                       |================                                              |  26%   |                                                                       |================                                              |  27%   |                                                                       |=================                                             |  27%   |                                                                       |=================                                             |  28%   |                                                                       |==================                                            |  28%   |                                                                       |==================                                            |  29%   |                                                                       |==================                                            |  30%   |                                                                       |===================                                           |  30%   |                                                                       |===================                                           |  31%   |                                                                       |====================                                          |  31%   |                                                                       |====================                                          |  32%   |                                                                       |====================                                          |  33%   |                                                                       |=====================                                         |  33%   |                                                                       |=====================                                         |  34%   |                                                                       |=====================                                         |  35%   |                                                                       |======================                                        |  35%   |                                                                       |======================                                        |  36%   |                                                                       |=======================                                       |  36%   |                                                                       |=======================                                       |  37%   |                                                                       |=======================                                       |  38%   |                                                                       |========================                                      |  38%   |                                                                       |========================                                      |  39%   |                                                                       |========================                                      |  40%   |                                                                       |=========================                                     |  40%   |                                                                       |=========================                                     |  41%   |                                                                       |==========================                                    |  41%   |                                                                       |==========================                                    |  42%   |                                                                       |==========================                                    |  43%   |                                                                       |===========================                                   |  43%   |                                                                       |===========================                                   |  44%   |                                                                       |============================                                  |  44%   |                                                                       |============================                                  |  45%   |                                                                       |============================                                  |  46%   |                                                                       |=============================                                 |  46%   |                                                                       |=============================                                 |  47%   |                                                                       |=============================                                 |  48%   |                                                                       |==============================                                |  48%   |                                                                       |==============================                                |  49%   |                                                                       |===============================                               |  49%   |                                                                       |===============================                               |  50%   |                                                                       |===============================                               |  51%   |                                                                       |================================                              |  51%   |                                                                       |================================                              |  52%   |                                                                       |=================================                             |  52%   |                                                                       |=================================                             |  53%   |                                                                       |=================================                             |  54%   |                                                                       |==================================                            |  54%   |                                                                       |==================================                            |  55%   |                                                                       |==================================                            |  56%   |                                                                       |===================================                           |  56%   |                                                                       |===================================                           |  57%   |                                                                       |====================================                          |  57%   |                                                                       |====================================                          |  58%   |                                                                       |====================================                          |  59%   |                                                                       |=====================================                         |  59%   |                                                                       |=====================================                         |  60%   |                                                                       |======================================                        |  60%   |                                                                       |======================================                        |  61%   |                                                                       |======================================                        |  62%   |                                                                       |=======================================                       |  62%   |                                                                       |=======================================                       |  63%   |                                                                       |=======================================                       |  64%   |                                                                       |========================================                      |  64%   |                                                                       |========================================                      |  65%   |                                                                       |=========================================                     |  65%   |                                                                       |=========================================                     |  66%   |                                                                       |=========================================                     |  67%   |                                                                       |==========================================                    |  67%   |                                                                       |==========================================                    |  68%   |                                                                       |==========================================                    |  69%   |                                                                       |===========================================                   |  69%   |                                                                       |===========================================                   |  70%   |                                                                       |============================================                  |  70%   |                                                                       |============================================                  |  71%   |                                                                       |============================================                  |  72%   |                                                                       |=============================================                 |  72%   |                                                                       |=============================================                 |  73%   |                                                                       |==============================================                |  73%   |                                                                       |==============================================                |  74%   |                                                                       |==============================================                |  75%   |                                                                       |===============================================               |  75%   |                                                                       |===============================================               |  76%   |                                                                       |===============================================               |  77%   |                                                                       |================================================              |  77%   |                                                                       |================================================              |  78%   |                                                                       |=================================================             |  78%   |                                                                       |=================================================             |  79%   |                                                                       |=================================================             |  80%   |                                                                       |==================================================            |  80%   |                                                                       |==================================================            |  81%   |                                                                       |===================================================           |  81%   |                                                                       |===================================================           |  82%   |                                                                       |===================================================           |  83%   |                                                                       |====================================================          |  83%   |                                                                       |====================================================          |  84%   |                                                                       |====================================================          |  85%   |                                                                       |=====================================================         |  85%   |                                                                       |=====================================================         |  86%   |                                                                       |======================================================        |  86%   |                                                                       |======================================================        |  87%   |                                                                       |======================================================        |  88%   |                                                                       |=======================================================       |  88%   |                                                                       |=======================================================       |  89%   |                                                                       |=======================================================       |  90%   |                                                                       |========================================================      |  90%   |                                                                       |========================================================      |  91%   |                                                                       |=========================================================     |  91%   |                                                                       |=========================================================     |  92%   |                                                                       |=========================================================     |  93%   |                                                                       |==========================================================    |  93%   |                                                                       |==========================================================    |  94%   |                                                                       |===========================================================   |  94%   |                                                                       |===========================================================   |  95%   |                                                                       |===========================================================   |  96%   |                                                                       |============================================================  |  96%   |                                                                       |============================================================  |  97%   |                                                                       |============================================================  |  98%   |                                                                       |============================================================= |  98%   |                                                                       |============================================================= |  99%   |                                                                       |==============================================================|  99%   |                                                                       |==============================================================| 100% #> threshold of 0.9 has been provided. Samples will be added until quantile ratio is reached #> Underrepresented Quantile 1 - A total of 11 samples have been allocated. #> Underrepresented Quantile 2 - A total of 2 samples have been allocated. #> Underrepresented Quantile 3 - A total of 2 samples have been allocated. #> Underrepresented Quantile 4 - A total of 4 samples have been allocated. #> Underrepresented Quantile 5 - A total of 3 samples have been allocated. #> Underrepresented Quantile 6 - A total of 4 samples have been allocated. #> Underrepresented Quantile 7 - A total of 5 samples have been allocated. #> Underrepresented Quantile 8 - A total of 5 samples have been allocated. #> Underrepresented Quantile 9 - A total of 2 samples have been allocated. #> Underrepresented Quantile 10 - A total of 3 samples have been allocated. #> Underrepresented Quantile 11 - A total of 3 samples have been allocated. #> Underrepresented Quantile 12 - A total of 3 samples have been allocated. #> Underrepresented Quantile 13 - A total of 1 samples have been allocated. #> Underrepresented Quantile 14 - A total of 4 samples have been allocated. #> A total of 52 new samples added  #> Simple feature collection with 152 features and 4 fields #> Geometry type: POINT #> Dimension:     XY #> Bounding box:  xmin: 431110 ymin: 5337750 xmax: 438550 ymax: 5343230 #> CRS:           +proj=utm +zone=17 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs #> First 10 features: #>        type     zmean pzabove2  zsd               geometry #> 1  existing 11.490000     79.7 4.96 POINT (434970 5343030) #> 2  existing 10.679999     91.9 3.90 POINT (435590 5340510) #> 3  existing  5.640000     24.8 4.23 POINT (434290 5338670) #> 4  existing  7.490000     38.5 3.61 POINT (435170 5340410) #> 5  existing  9.170000     69.4 4.20 POINT (437550 5340650) #> 6  existing 11.059999     79.8 5.30 POINT (435850 5340130) #> 7  existing  9.240000     74.8 5.34 POINT (431630 5343230) #> 8  existing  9.420000     89.6 3.63 POINT (436510 5340870) #> 9  existing  9.059999     65.1 4.80 POINT (435990 5339950) #> 10 existing  8.170000     93.5 3.38 POINT (438250 5337770)  calculate_ahels(   mraster = mr[[1:3]],   existing = e,   nQuant = 20,   nSamp = 300,   filename = tempfile(fileext = \".shp\") ) #> Creating covariance matrix. #>    |                                                                       |                                                              |   0%   |                                                                       |                                                              |   1%   |                                                                       |=                                                             |   1%   |                                                                       |=                                                             |   2%   |                                                                       |==                                                            |   2%   |                                                                       |==                                                            |   3%   |                                                                       |==                                                            |   4%   |                                                                       |===                                                           |   4%   |                                                                       |===                                                           |   5%   |                                                                       |===                                                           |   6%   |                                                                       |====                                                          |   6%   |                                                                       |====                                                          |   7%   |                                                                       |=====                                                         |   7%   |                                                                       |=====                                                         |   8%   |                                                                       |=====                                                         |   9%   |                                                                       |======                                                        |   9%   |                                                                       |======                                                        |  10%   |                                                                       |=======                                                       |  10%   |                                                                       |=======                                                       |  11%   |                                                                       |=======                                                       |  12%   |                                                                       |========                                                      |  12%   |                                                                       |========                                                      |  13%   |                                                                       |========                                                      |  14%   |                                                                       |=========                                                     |  14%   |                                                                       |=========                                                     |  15%   |                                                                       |==========                                                    |  15%   |                                                                       |==========                                                    |  16%   |                                                                       |==========                                                    |  17%   |                                                                       |===========                                                   |  17%   |                                                                       |===========                                                   |  18%   |                                                                       |===========                                                   |  19%   |                                                                       |============                                                  |  19%   |                                                                       |============                                                  |  20%   |                                                                       |=============                                                 |  20%   |                                                                       |=============                                                 |  21%   |                                                                       |=============                                                 |  22%   |                                                                       |==============                                                |  22%   |                                                                       |==============                                                |  23%   |                                                                       |===============                                               |  23%   |                                                                       |===============                                               |  24%   |                                                                       |===============                                               |  25%   |                                                                       |================                                              |  25%   |                                                                       |================                                              |  26%   |                                                                       |================                                              |  27%   |                                                                       |=================                                             |  27%   |                                                                       |=================                                             |  28%   |                                                                       |==================                                            |  28%   |                                                                       |==================                                            |  29%   |                                                                       |==================                                            |  30%   |                                                                       |===================                                           |  30%   |                                                                       |===================                                           |  31%   |                                                                       |====================                                          |  31%   |                                                                       |====================                                          |  32%   |                                                                       |====================                                          |  33%   |                                                                       |=====================                                         |  33%   |                                                                       |=====================                                         |  34%   |                                                                       |=====================                                         |  35%   |                                                                       |======================                                        |  35%   |                                                                       |======================                                        |  36%   |                                                                       |=======================                                       |  36%   |                                                                       |=======================                                       |  37%   |                                                                       |=======================                                       |  38%   |                                                                       |========================                                      |  38%   |                                                                       |========================                                      |  39%   |                                                                       |========================                                      |  40%   |                                                                       |=========================                                     |  40%   |                                                                       |=========================                                     |  41%   |                                                                       |==========================                                    |  41%   |                                                                       |==========================                                    |  42%   |                                                                       |==========================                                    |  43%   |                                                                       |===========================                                   |  43%   |                                                                       |===========================                                   |  44%   |                                                                       |============================                                  |  44%   |                                                                       |============================                                  |  45%   |                                                                       |============================                                  |  46%   |                                                                       |=============================                                 |  46%   |                                                                       |=============================                                 |  47%   |                                                                       |=============================                                 |  48%   |                                                                       |==============================                                |  48%   |                                                                       |==============================                                |  49%   |                                                                       |===============================                               |  49%   |                                                                       |===============================                               |  50%   |                                                                       |===============================                               |  51%   |                                                                       |================================                              |  51%   |                                                                       |================================                              |  52%   |                                                                       |=================================                             |  52%   |                                                                       |=================================                             |  53%   |                                                                       |=================================                             |  54%   |                                                                       |==================================                            |  54%   |                                                                       |==================================                            |  55%   |                                                                       |==================================                            |  56%   |                                                                       |===================================                           |  56%   |                                                                       |===================================                           |  57%   |                                                                       |====================================                          |  57%   |                                                                       |====================================                          |  58%   |                                                                       |====================================                          |  59%   |                                                                       |=====================================                         |  59%   |                                                                       |=====================================                         |  60%   |                                                                       |======================================                        |  60%   |                                                                       |======================================                        |  61%   |                                                                       |======================================                        |  62%   |                                                                       |=======================================                       |  62%   |                                                                       |=======================================                       |  63%   |                                                                       |=======================================                       |  64%   |                                                                       |========================================                      |  64%   |                                                                       |========================================                      |  65%   |                                                                       |=========================================                     |  65%   |                                                                       |=========================================                     |  66%   |                                                                       |=========================================                     |  67%   |                                                                       |==========================================                    |  67%   |                                                                       |==========================================                    |  68%   |                                                                       |==========================================                    |  69%   |                                                                       |===========================================                   |  69%   |                                                                       |===========================================                   |  70%   |                                                                       |============================================                  |  70%   |                                                                       |============================================                  |  71%   |                                                                       |============================================                  |  72%   |                                                                       |=============================================                 |  72%   |                                                                       |=============================================                 |  73%   |                                                                       |==============================================                |  73%   |                                                                       |==============================================                |  74%   |                                                                       |==============================================                |  75%   |                                                                       |===============================================               |  75%   |                                                                       |===============================================               |  76%   |                                                                       |===============================================               |  77%   |                                                                       |================================================              |  77%   |                                                                       |================================================              |  78%   |                                                                       |=================================================             |  78%   |                                                                       |=================================================             |  79%   |                                                                       |=================================================             |  80%   |                                                                       |==================================================            |  80%   |                                                                       |==================================================            |  81%   |                                                                       |===================================================           |  81%   |                                                                       |===================================================           |  82%   |                                                                       |===================================================           |  83%   |                                                                       |====================================================          |  83%   |                                                                       |====================================================          |  84%   |                                                                       |====================================================          |  85%   |                                                                       |=====================================================         |  85%   |                                                                       |=====================================================         |  86%   |                                                                       |======================================================        |  86%   |                                                                       |======================================================        |  87%   |                                                                       |======================================================        |  88%   |                                                                       |=======================================================       |  88%   |                                                                       |=======================================================       |  89%   |                                                                       |=======================================================       |  90%   |                                                                       |========================================================      |  90%   |                                                                       |========================================================      |  91%   |                                                                       |=========================================================     |  91%   |                                                                       |=========================================================     |  92%   |                                                                       |=========================================================     |  93%   |                                                                       |==========================================================    |  93%   |                                                                       |==========================================================    |  94%   |                                                                       |===========================================================   |  94%   |                                                                       |===========================================================   |  95%   |                                                                       |===========================================================   |  96%   |                                                                       |============================================================  |  96%   |                                                                       |============================================================  |  97%   |                                                                       |============================================================  |  98%   |                                                                       |============================================================= |  98%   |                                                                       |============================================================= |  99%   |                                                                       |==============================================================|  99%   |                                                                       |==============================================================| 100% #> nSamp of 300 has been provided. Samples will be added until this number is reached #> Underrepresented Quantile 1 - A total of 8 samples have been allocated. #> Underrepresented Quantile 2 - A total of 3 samples have been allocated. #> Underrepresented Quantile 3 - A total of 4 samples have been allocated. #> Underrepresented Quantile 4 - A total of 2 samples have been allocated. #> Underrepresented Quantile 5 - A total of 2 samples have been allocated. #> Underrepresented Quantile 6 - A total of 2 samples have been allocated. #> Underrepresented Quantile 7 - A total of 2 samples have been allocated. #> Underrepresented Quantile 8 - A total of 2 samples have been allocated. #> Underrepresented Quantile 9 - A total of 2 samples have been allocated. #> Underrepresented Quantile 10 - A total of 3 samples have been allocated. #> Underrepresented Quantile 11 - A total of 6 samples have been allocated. #> Underrepresented Quantile 12 - A total of 5 samples have been allocated. #> Underrepresented Quantile 13 - A total of 4 samples have been allocated. #> Underrepresented Quantile 14 - A total of 2 samples have been allocated. #> Underrepresented Quantile 15 - A total of 1 samples have been allocated. #> Underrepresented Quantile 16 - A total of 3 samples have been allocated. #> Underrepresented Quantile 17 - A total of 10 samples have been allocated. #> Underrepresented Quantile 18 - A total of 4 samples have been allocated. #> Underrepresented Quantile 19 - A total of 1 samples have been allocated. #> Underrepresented Quantile 20 - A total of 2 samples have been allocated. #> Underrepresented Quantile 21 - A total of 3 samples have been allocated. #> Underrepresented Quantile 22 - A total of 2 samples have been allocated. #> Underrepresented Quantile 23 - A total of 3 samples have been allocated. #> Underrepresented Quantile 24 - A total of 1 samples have been allocated. #> Underrepresented Quantile 25 - A total of 2 samples have been allocated. #> Underrepresented Quantile 26 - A total of 4 samples have been allocated. #> Underrepresented Quantile 27 - A total of 1 samples have been allocated. #> Underrepresented Quantile 28 - A total of 2 samples have been allocated. #> Underrepresented Quantile 29 - A total of 3 samples have been allocated. #> Underrepresented Quantile 30 - A total of 1 samples have been allocated. #> Underrepresented Quantile 31 - A total of 6 samples have been allocated. #> Underrepresented Quantile 32 - A total of 1 samples have been allocated. #> Underrepresented Quantile 33 - A total of 6 samples have been allocated. #> Underrepresented Quantile 34 - A total of 8 samples have been allocated. #> Underrepresented Quantile 35 - A total of 1 samples have been allocated. #> Underrepresented Quantile 36 - A total of 1 samples have been allocated. #> Underrepresented Quantile 37 - A total of 1 samples have been allocated. #> Underrepresented Quantile 38 - A total of 3 samples have been allocated. #> Underrepresented Quantile 39 - A total of 4 samples have been allocated. #> Underrepresented Quantile 40 - A total of 1 samples have been allocated. #> Underrepresented Quantile 41 - A total of 1 samples have been allocated. #> Underrepresented Quantile 42 - A total of 4 samples have been allocated. #> Underrepresented Quantile 43 - A total of 4 samples have been allocated. #> Underrepresented Quantile 44 - A total of 2 samples have been allocated. #> Underrepresented Quantile 45 - A total of 3 samples have been allocated. #> Underrepresented Quantile 46 - A total of 2 samples have been allocated. #> Underrepresented Quantile 47 - A total of 2 samples have been allocated. #> Underrepresented Quantile 48 - A total of 4 samples have been allocated. #> Underrepresented Quantile 49 - A total of 2 samples have been allocated. #> Underrepresented Quantile 50 - A total of 1 samples have been allocated. #> Underrepresented Quantile 51 - A total of 5 samples have been allocated. #> Underrepresented Quantile 52 - A total of 4 samples have been allocated. #> Underrepresented Quantile 53 - A total of 1 samples have been allocated. #> Underrepresented Quantile 54 - A total of 2 samples have been allocated. #> Underrepresented Quantile 55 - A total of 8 samples have been allocated. #> Underrepresented Quantile 56 - A total of 1 samples have been allocated. #> Underrepresented Quantile 57 - A total of 2 samples have been allocated. #> Underrepresented Quantile 58 - A total of 3 samples have been allocated. #> Underrepresented Quantile 59 - A total of 1 samples have been allocated. #> Underrepresented Quantile 60 - A total of 3 samples have been allocated. #> Underrepresented Quantile 61 - A total of 4 samples have been allocated. #> Underrepresented Quantile 62 - A total of 2 samples have been allocated. #> Underrepresented Quantile 63 - A total of 7 samples have been allocated. #> Underrepresented Quantile 64 - A total of 1 samples have been allocated. #> Underrepresented Quantile 65 - A total of 4 samples have been allocated. #> Underrepresented Quantile 66 - A total of 3 samples have been allocated. #> Underrepresented Quantile 67 - A total of 5 samples have been allocated. #> Underrepresented Quantile 68 - A total of 2 samples have been allocated. #> Underrepresented Quantile 69 - A total of 2 samples have been allocated. #> Underrepresented Quantile 70 - A total of 4 samples have been allocated. #> Underrepresented Quantile 71 - A total of 2 samples have been allocated. #> Underrepresented Quantile 72 - A total of 1 samples have been allocated. #> Underrepresented Quantile 73 - A total of 3 samples have been allocated. #> Underrepresented Quantile 74 - A total of 6 samples have been allocated. #> Underrepresented Quantile 75 - A total of 1 samples have been allocated. #> Underrepresented Quantile 76 - A total of 1 samples have been allocated. #> Underrepresented Quantile 77 - A total of 4 samples have been allocated. #> Underrepresented Quantile 78 - A total of 1 samples have been allocated. #> Underrepresented Quantile 79 - A total of 3 samples have been allocated. #> Underrepresented Quantile 80 - A total of 1 samples have been allocated. #> Underrepresented Quantile 81 - A total of 6 samples have been allocated. #> Underrepresented Quantile 82 - A total of 1 samples have been allocated. #> Underrepresented Quantile 83 - A total of 5 samples have been allocated. #> Underrepresented Quantile 84 - A total of 2 samples have been allocated. #> Underrepresented Quantile 85 - A total of 2 samples have been allocated. #> Underrepresented Quantile 86 - A total of 3 samples have been allocated. #> Underrepresented Quantile 87 - A total of 1 samples have been allocated. #> Underrepresented Quantile 88 - A total of 2 samples have been allocated. #> Underrepresented Quantile 89 - A total of 3 samples have been allocated. #> Underrepresented Quantile 90 - A total of 2 samples have been allocated. #> Underrepresented Quantile 91 - A total of 5 samples have been allocated. #> Underrepresented Quantile 92 - A total of 1 samples have been allocated. #> Underrepresented Quantile 93 - A total of 2 samples have been allocated. #> Underrepresented Quantile 94 - A total of 1 samples have been allocated. #> Underrepresented Quantile 95 - A total of 1 samples have been allocated. #> Underrepresented Quantile 96 - A total of 4 samples have been allocated. #> Underrepresented Quantile 97 - A total of 1 samples have been allocated. #> Underrepresented Quantile 98 - A total of 2 samples have been allocated. #> Underrepresented Quantile 99 - A total of 2 samples have been allocated. #> Underrepresented Quantile 100 - A total of 2 samples have been allocated. #> Underrepresented Quantile 101 - A total of 2 samples have been allocated. #> Underrepresented Quantile 102 - A total of 3 samples have been allocated. #> Underrepresented Quantile 103 - A total of 2 samples have been allocated. #> Underrepresented Quantile 104 - A total of 1 samples have been allocated. #> Underrepresented Quantile 105 - A total of 6 samples have been allocated. #> Underrepresented Quantile 106 - A total of 4 samples have been allocated. #> A total of 300 new samples added #> Writing layer `file54b069622846' to data source  #>   `C:\\Users\\tgood.stu\\AppData\\Local\\Temp\\Rtmp0Uciba\\file54b069622846.shp' using driver `ESRI Shapefile' #> Writing 400 features with 4 fields and geometry type Point. #> Simple feature collection with 400 features and 4 fields #> Geometry type: POINT #> Dimension:     XY #> Bounding box:  xmin: 431110 ymin: 5337710 xmax: 438550 ymax: 5343230 #> CRS:           +proj=utm +zone=17 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs #> First 10 features: #>        type     zmean pzabove2  zsd               geometry #> 1  existing 11.490000     79.7 4.96 POINT (434970 5343030) #> 2  existing 10.679999     91.9 3.90 POINT (435590 5340510) #> 3  existing  5.640000     24.8 4.23 POINT (434290 5338670) #> 4  existing  7.490000     38.5 3.61 POINT (435170 5340410) #> 5  existing  9.170000     69.4 4.20 POINT (437550 5340650) #> 6  existing 11.059999     79.8 5.30 POINT (435850 5340130) #> 7  existing  9.240000     74.8 5.34 POINT (431630 5343230) #> 8  existing  9.420000     89.6 3.63 POINT (436510 5340870) #> 9  existing  9.059999     65.1 4.80 POINT (435990 5339950) #> 10 existing  8.170000     93.5 3.38 POINT (438250 5337770)"},{"path":"/reference/calculate_allocation.html","id":null,"dir":"Reference","previous_headings":"","what":"Determine required samples in strata — calculate_allocation","title":"Determine required samples in strata — calculate_allocation","text":"Determine required samples strata","code":""},{"path":"/reference/calculate_allocation.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Determine required samples in strata — calculate_allocation","text":"","code":"calculate_allocation(   sraster,   nSamp,   allocation = \"prop\",   mraster = NULL,   existing = NULL,   force = FALSE )"},{"path":"/reference/calculate_allocation.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Determine required samples in strata — calculate_allocation","text":"sraster spatRaster. Stratification raster used sampling. nSamp Numeric. Number desired samples. allocation Character. Allocation algorithm used. Either prop (default) proportional allocation optim optimal allocation (equal sampling cost) equal equal number samples (defined nSamp)  strata. mraster spatRaster. ALS metric raster. Required allocation = optim. existing sf data.frame.  Existing plot network. force Logical. Default = FALSE - force nSamp exactly user defined value cases nSamp sraster strata count equally divisible. Additional samples often need allocated removed based rounding differences resulting proportional differences nSamp strata coverages sraster. instances samples either added strata lowest number samples removed strata highest number samples. effect existing provided.","code":""},{"path":"/reference/calculate_allocation.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Determine required samples in strata — calculate_allocation","text":"Returns data.frame : strata - Strata ID. total - Total samples allocated based representation (positive) representation (negative) removed users discretion. need - Total required samples per strata. Rounded.","code":""},{"path":"/reference/calculate_allocation.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Determine required samples in strata — calculate_allocation","text":"Determine many samples allocate within strata","code":""},{"path":"/reference/calculate_allocation.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Determine required samples in strata — calculate_allocation","text":"Gregoire, T.G., & Valentine, H.T. (2007). Sampling Strategies Natural Resources Environment (1st ed.).  Chapman Hall/CRC. https://doi.org/10.1201/9780203498880","code":""},{"path":[]},{"path":"/reference/calculate_allocation.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Determine required samples in strata — calculate_allocation","text":"Tristan R.H. Goodbody","code":""},{"path":"/reference/calculate_allocation.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Determine required samples in strata — calculate_allocation","text":"","code":"#--- Load strata raster and existing samples---# r <- system.file(\"extdata\", \"kmeans.tif\", package = \"sgsR\") sr <- terra::rast(r)  e <- system.file(\"extdata\", \"existing.shp\", package = \"sgsR\") e <- sf::st_read(e) #> Reading layer `existing' from data source  #>   `C:\\Users\\tgood.stu\\Documents\\R\\win-library\\4.1\\sgsR\\extdata\\existing.shp'  #>   using driver `ESRI Shapefile' #> Simple feature collection with 100 features and 1 field #> Geometry type: POINT #> Dimension:     XY #> Bounding box:  xmin: 431110 ymin: 5337750 xmax: 438550 ymax: 5343230 #> CRS:           unknown  #--- perform grid sampling ---# calculate_allocation(   sraster = sr,   nSamp = 200 ) #> Implementing porportional allocation of samples #> nSamp of 200 is not perfectly divisible based on strata distribution. nSamp of 205 will be returned. Use \"force = TRUE\" to brute force to 200. #>    strata total #> 1       1    14 #> 2       2    29 #> 3       3    15 #> 4       4    21 #> 5       5    26 #> 6       6    25 #> 7       7    24 #> 8       8    17 #> 9       9    23 #> 10     10    11  calculate_allocation(   sraster = sr,   nSamp = 200,   force = TRUE ) #> Implementing porportional allocation of samples #> Forcing 200 total samples. #>    strata total #> 1       1    14 #> 2       2    25 #> 3       3    15 #> 4       4    21 #> 5       5    25 #> 6       6    25 #> 7       7    24 #> 8       8    17 #> 9       9    23 #> 10     10    11  #--- extract strata from existing samples ---# e.sr <- extract_strata(   sraster = sr,   existing = e )  calculate_allocation(   sraster = sr,   nSamp = 200,   existing = e.sr ) #> Implementing porportional allocation of samples #> nSamp of 200 is not perfectly divisible based on strata distribution. nSamp of 205 will be returned. Use \"force = TRUE\" to brute force to 200. #>    strata total need #> 1       1    12   14 #> 2       2    15   29 #> 3       3     3   15 #> 4       4    10   21 #> 5       5    11   26 #> 6       6    11   25 #> 7       7    12   24 #> 8       8     4   17 #> 9       9    18   23 #> 10     10     9   11  #--- Load mraster for optimal allocation ---# mr <- system.file(\"extdata\", \"wall_metrics.tif\", package = \"sgsR\") mr <- terra::rast(mr)  calculate_allocation(   sraster = sr,   nSamp = 200,   existing = e.sr,   allocation = \"optim\",   mraster = mr$zq90,   force = TRUE ) #> Implementing optimal allocation of samples based on variability of 'zq90' #> Forcing 200 total samples. #>    strata total need #> 1       1    14   17 #> 2       2    15   32 #> 3       3     3   15 #> 4       4     7   18 #> 5       5     5   20 #> 6       6     7   21 #> 7       7    12   24 #> 8       8    11   24 #> 9       9    15   22 #> 10     10    11   13"},{"path":"/reference/calculate_coobs.html","id":null,"dir":"Reference","previous_headings":"","what":"coobs algorithm sampling — calculate_coobs","title":"coobs algorithm sampling — calculate_coobs","text":"Perform COunt OBServations (coobs) algorithm using existing site data raster metrics. algorithm aids user determining additional samples located comparing existing samples pixel associated covariates. output coobs raster used constrain clhs sampling areas underreprented.","code":""},{"path":"/reference/calculate_coobs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"coobs algorithm sampling — calculate_coobs","text":"","code":"calculate_coobs(   mraster,   existing,   cores = 1,   threshold = 0.95,   plot = FALSE,   details = FALSE,   filename = NULL,   overwrite = FALSE )"},{"path":"/reference/calculate_coobs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"coobs algorithm sampling — calculate_coobs","text":"mraster spatRaster. ALS metrics raster. Requires least 2 layers calculate covariance matrix existing sf.  Existing plot network. cores Numeric. Number cores use parallel processing. default = 1 threshold Numeric. Proxy maximum pixel quantile avoid outliers. default = 0.95 plot Logical. Plots output strata raster visualized strata boundary dividers. details Logical. FALSE (default) output  stratification raster. TRUE return list $details additional stratification information  $raster output stratification spatRaster.  @param ... Additional arguments passed kmeans function. filename Character. Path write stratified raster disc. overwrite Logical. Specify whether filename overwritten disc.","code":""},{"path":"/reference/calculate_coobs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"coobs algorithm sampling — calculate_coobs","text":"output raster coobs classified coobs layers.","code":""},{"path":"/reference/calculate_coobs.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"coobs algorithm sampling — calculate_coobs","text":"Special thanks Dr. Brendan Malone original implementation algorithm.","code":""},{"path":"/reference/calculate_coobs.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"coobs algorithm sampling — calculate_coobs","text":"Malone BP, Minansy B, Brungard C. 2019. methods improve utility conditioned Latin hypercube sampling. PeerJ 7:e6451 DOI 10.7717/peerj.6451","code":""},{"path":[]},{"path":"/reference/calculate_coobs.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"coobs algorithm sampling — calculate_coobs","text":"Tristan R.H. Goodbody","code":""},{"path":"/reference/calculate_coobs.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"coobs algorithm sampling — calculate_coobs","text":"","code":"if (FALSE) { #--- Load raster and existing plots---# r <- system.file(\"extdata\", \"wall_metrics.tif\", package = \"sgsR\") mr <- terra::rast(r)  e <- system.file(\"extdata\", \"existing.shp\", package = \"sgsR\") e <- sf::st_read(e)  calculate_coobs(   mraster = mr,   existing = e,   cores = 4,   details = TRUE,   filename = tempfile(fileext = \".tif\") ) }"},{"path":"/reference/calculate_distance.html","id":null,"dir":"Reference","previous_headings":"","what":"Distance to access layer — calculate_distance","title":"Distance to access layer — calculate_distance","text":"Per pixel distance nearest access vector. Intended used `cost` constraint within sample_clhs function","code":""},{"path":"/reference/calculate_distance.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Distance to access layer — calculate_distance","text":"","code":"calculate_distance(   raster,   access,   plot = FALSE,   filename = NULL,   overwrite = FALSE )"},{"path":"/reference/calculate_distance.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Distance to access layer — calculate_distance","text":"raster spatRaster. Raster used calculate pixel level distance access layer. access sf. Road access network - must lines. plot Logical. Plots output strata raster samples. filename Character. Path write output samples. overwrite Logical. Choice overwrite existing filename exists.","code":""},{"path":"/reference/calculate_distance.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Distance to access layer — calculate_distance","text":"Input raster dist2access layer appended.","code":""},{"path":[]},{"path":"/reference/calculate_distance.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Distance to access layer — calculate_distance","text":"Tristan R.H. Goodbody","code":""},{"path":"/reference/calculate_distance.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Distance to access layer — calculate_distance","text":"","code":"#--- Load raster and access files ---# r <- system.file(\"extdata\", \"kmeans.tif\", package = \"sgsR\") sr <- terra::rast(r)  a <- system.file(\"extdata\", \"roads.shp\", package = \"sgsR\") ac <- sf::st_read(a) #> Reading layer `roads' from data source  #>   `C:\\Users\\tgood.stu\\Documents\\R\\win-library\\4.1\\sgsR\\extdata\\roads.shp'  #>   using driver `ESRI Shapefile' #> Simple feature collection with 167 features and 2 fields #> Geometry type: MULTILINESTRING #> Dimension:     XY #> Bounding box:  xmin: 431100 ymin: 5337700 xmax: 438560 ymax: 5343240 #> Projected CRS: UTM_Zone_17_Northern_Hemisphere  calculate_distance(   raster = sr,   access = ac,   plot = TRUE ) #> calculating per pixel distance to provided access layer #> class       : SpatRaster  #> dimensions  : 277, 373, 2  (nrow, ncol, nlyr) #> resolution  : 20, 20  (x, y) #> extent      : 431100, 438560, 5337700, 5343240  (xmin, xmax, ymin, ymax) #> coord. ref. : UTM Zone 17, Northern Hemisphere  #> sources     : kmeans.tif   #>               memory   #> names       :      strata, dist2access  #> min values  : 1.000000000, 0.006621213  #> max values  :       10.00,     1061.66   calculate_distance(   raster = sr,   access = ac,   plot = TRUE,   filename = tempfile(fileext = \".tif\") ) #> calculating per pixel distance to provided access layer  #> class       : SpatRaster  #> dimensions  : 277, 373, 2  (nrow, ncol, nlyr) #> resolution  : 20, 20  (x, y) #> extent      : 431100, 438560, 5337700, 5343240  (xmin, xmax, ymin, ymax) #> coord. ref. : UTM Zone 17, Northern Hemisphere  #> sources     : kmeans.tif   #>               memory   #> names       :      strata, dist2access  #> min values  : 1.000000000, 0.006621213  #> max values  :       10.00,     1061.66"},{"path":"/reference/calculate_lhsOpt.html","id":null,"dir":"Reference","previous_headings":"","what":"Analyze optimal Latin hypercube sample number — calculate_lhsOpt","title":"Analyze optimal Latin hypercube sample number — calculate_lhsOpt","text":"Population level analysis metric raster data determine optimal Latin Hypercube sample size","code":""},{"path":"/reference/calculate_lhsOpt.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Analyze optimal Latin hypercube sample number — calculate_lhsOpt","text":"","code":"calculate_lhsOpt(   popLHS,   PCA = TRUE,   quant = TRUE,   KLdiv = TRUE,   minSamp = 10,   maxSamp = 100,   step = 10,   rep = 10,   iter = 10000 )"},{"path":"/reference/calculate_lhsOpt.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Analyze optimal Latin hypercube sample number — calculate_lhsOpt","text":"popLHS List. Output calculate_lhsPop function. PCA Logical. Calculates principal component loadings population PCA similarity factor testing. default = TRUE. quant Logical. Calculates quantile matrix population quantile comparison testing. default = TRUE. KLdiv Logical. Calculates covariate matrix population Kullback–Leibler divergence testing. default = TRUE. Relies quant = TRUE calculate. minSamp Numeric. Minimum sample size test. default = 10. maxSamp Numeric. Maximum sample size test. default = 100. step Numeric. Sample step size iteration. default = 10. rep Numeric. Internal repetitions sample size. default = 10. iter Numeric. Internal clhs - positive number, giving number iterations Metropolis-Hastings annealing process. Defaults 10000.","code":""},{"path":"/reference/calculate_lhsOpt.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Analyze optimal Latin hypercube sample number — calculate_lhsOpt","text":"data.frame summary statistics.","code":""},{"path":"/reference/calculate_lhsOpt.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Analyze optimal Latin hypercube sample number — calculate_lhsOpt","text":"Special thanks Dr. Brendan Malone original implementation algorithm.","code":""},{"path":"/reference/calculate_lhsOpt.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Analyze optimal Latin hypercube sample number — calculate_lhsOpt","text":"Malone BP, Minansy B, Brungard C. 2019. methods improve utility conditioned Latin hypercube sampling. PeerJ 7:e6451 DOI 10.7717/peerj.6451","code":""},{"path":"/reference/calculate_lhsOpt.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Analyze optimal Latin hypercube sample number — calculate_lhsOpt","text":"Tristan R.H. Goodbody","code":""},{"path":"/reference/calculate_lhsOpt.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Analyze optimal Latin hypercube sample number — calculate_lhsOpt","text":"","code":"if (FALSE) { #--- Load raster and access files ---# r <- system.file(\"extdata\", \"wall_metrics.tif\", package = \"sgsR\") mr <- terra::rast(r)  #--- calculate lhsPop details ---# poplhs <- calculate_lhsPop(mraster = mr)  calculate_lhsOpt(popLHS = poplhs)  calculate_lhsOpt(   popLHS = poplhs,   PCA = FALSE,   iter = 200 ) }"},{"path":"/reference/calculate_lhsPop.html","id":null,"dir":"Reference","previous_headings":"","what":"Analyze covariates for lhs — calculate_lhsPop","title":"Analyze covariates for lhs — calculate_lhsPop","text":"Population level analysis metric raster data Calculates population level statistics including principal components, quantile matrix, Kullback-leibler divergence neccesary calculate_lhsOpt.","code":""},{"path":"/reference/calculate_lhsPop.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Analyze covariates for lhs — calculate_lhsPop","text":"","code":"calculate_lhsPop(mraster, PCA = TRUE, quant = TRUE, nQuant = 10, KLdiv = TRUE)"},{"path":"/reference/calculate_lhsPop.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Analyze covariates for lhs — calculate_lhsPop","text":"mraster spatRaster. ALS metrics raster. PCA Logical. Calculates principal component loadings population PCA similarity factor testing. default = TRUE. quant Logical. Calculates quantile matrix population quantile comparison testing. default = TRUE. nQuant Numeric. Number quantiles divide population quant. default = 10. KLdiv Logical. Calculates covariate matrix population Kullback–Leibler divergence testing. default = TRUE. Relies quant = TRUE calculate.","code":""},{"path":"/reference/calculate_lhsPop.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Analyze covariates for lhs — calculate_lhsPop","text":"List matrices used input calculate_lhsOpt.","code":""},{"path":"/reference/calculate_lhsPop.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Analyze covariates for lhs — calculate_lhsPop","text":"Special thanks Dr. Brendan Malone original implementation algorithm.","code":""},{"path":"/reference/calculate_lhsPop.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Analyze covariates for lhs — calculate_lhsPop","text":"Malone BP, Minansy B, Brungard C. 2019. methods improve utility conditioned Latin hypercube sampling. PeerJ 7:e6451 DOI 10.7717/peerj.6451","code":""},{"path":[]},{"path":"/reference/calculate_lhsPop.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Analyze covariates for lhs — calculate_lhsPop","text":"Tristan R.H. Goodbody","code":""},{"path":"/reference/calculate_lhsPop.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Analyze covariates for lhs — calculate_lhsPop","text":"","code":"if (FALSE) { #--- Load raster and access files ---# r <- system.file(\"extdata\", \"wall_metrics.tif\", package = \"sgsR\") mr <- terra::rast(r)  calculate_lhsPop(mraster = mr)  calculate_lhsPop(   mraster = mr,   nQuant = 10,   PCA = FALSE ) }"},{"path":"/reference/calculate_pcomp.html","id":null,"dir":"Reference","previous_headings":"","what":"Raster principal components — calculate_pcomp","title":"Raster principal components — calculate_pcomp","text":"Calculate rasterize principal components metric raster","code":""},{"path":"/reference/calculate_pcomp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Raster principal components — calculate_pcomp","text":"","code":"calculate_pcomp(   mraster,   nComp,   center = TRUE,   scale = TRUE,   plot = FALSE,   details = FALSE,   filename = NULL,   overwrite = FALSE,   ... )"},{"path":"/reference/calculate_pcomp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Raster principal components — calculate_pcomp","text":"mraster spatRaster. ALS metrics raster. nComp Numeric. Value indicating number principal components rasterized. prior analysis. center Logical. Value indicating whether variables shifted zero centered. scale Logical. Value indicating whether variables scaled unit variance plot Logical. Plots output strata raster samples. details Logical. FALSE (default) output  stratification raster. TRUE return list $details additional stratification information  $raster output stratification spatRaster.  @param ... Additional arguments passed kmeans function. filename Character. Path write output samples. overwrite Logical. Choice overwrite existing filename exists. ... Additional arguments passed prcomp.","code":""},{"path":"/reference/calculate_pcomp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Raster principal components — calculate_pcomp","text":"Output raster specified number principal components layers.","code":""},{"path":[]},{"path":"/reference/calculate_pcomp.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Raster principal components — calculate_pcomp","text":"Tristan R.H. Goodbody","code":""},{"path":"/reference/calculate_pcomp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Raster principal components — calculate_pcomp","text":"","code":"#--- Load raster ---# r <- system.file(\"extdata\", \"wall_metrics.tif\", package = \"sgsR\") mr <- terra::rast(r)  calculate_pcomp(   mraster = mr,   nComp = 5,   plot = TRUE )  #> class       : SpatRaster  #> dimensions  : 277, 373, 5  (nrow, ncol, nlyr) #> resolution  : 20, 20  (x, y) #> extent      : 431100, 438560, 5337700, 5343240  (xmin, xmax, ymin, ymax) #> coord. ref. : UTM Zone 17, Northern Hemisphere  #> sources     : memory   #>               memory   #>               memory   #>               ... and 2 more source(s) #> names       :        PC1,        PC2,        PC3,        PC4,        PC5  #> min values  : -5.8417779, -6.3681104, -4.0383034, -2.4944332, -0.6915542  #> max values  :   7.804354,   2.563877,   1.633331,   1.594847,   1.529565   pcomp <- calculate_pcomp(   mraster = mr,   nComp = 3,   details = TRUE )  #--- Display principal component details ---# pcomp$pca #> Standard deviations (1, .., p=7): #> [1] 2.39419739 0.86118253 0.65363210 0.27245666 0.11010541 0.10829035 #> [7] 0.02942688 #>  #> Rotation (n x k) = (7 x 7): #>                PC1         PC2         PC3         PC4         PC5 #> zmean    0.4133340  0.09703826 -0.16916047  0.05442900 -0.21939815 #> pzabove2 0.3217898  0.28579795  0.89947473  0.04704228  0.05896495 #> zsd      0.3314085 -0.70018256  0.06658857 -0.06471159  0.60912694 #> zq20     0.3511227  0.56045175 -0.30858934 -0.47871051  0.46478505 #> zq50     0.4055046  0.12094513 -0.21087080  0.55459689 -0.06283654 #> zq70     0.4116799 -0.07298152 -0.13366415  0.36834483 -0.07728656 #> zq90     0.3982126 -0.29083896  0.01832844 -0.56410773 -0.59279438 #>                   PC6          PC7 #> zmean     0.054431518  0.858523411 #> pzabove2 -0.004537764  0.002374888 #> zsd      -0.102288428  0.098957671 #> zq20      0.029772877 -0.145958963 #> zq50     -0.629629712 -0.261748068 #> zq70      0.755801174 -0.307312042 #> zq90     -0.134157677 -0.262454817  #--- Display importance of components ---# summary(pcomp$pca) #> Importance of components: #>                           PC1    PC2     PC3    PC4     PC5     PC6 #> Standard deviation     2.3942 0.8612 0.65363 0.2725 0.11011 0.10829 #> Proportion of Variance 0.8189 0.1060 0.06103 0.0106 0.00173 0.00168 #> Cumulative Proportion  0.8189 0.9248 0.98586 0.9965 0.99820 0.99988 #>                            PC7 #> Standard deviation     0.02943 #> Proportion of Variance 0.00012 #> Cumulative Proportion  1.00000"},{"path":"/reference/calculate_representation.html","id":null,"dir":"Reference","previous_headings":"","what":"Compare representation of samples within sraster strata — calculate_representation","title":"Compare representation of samples within sraster strata — calculate_representation","text":"Compare representation samples within sraster strata","code":""},{"path":"/reference/calculate_representation.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compare representation of samples within sraster strata — calculate_representation","text":"","code":"calculate_representation(sraster, existing, plot = FALSE)"},{"path":"/reference/calculate_representation.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compare representation of samples within sraster strata — calculate_representation","text":"sraster spatRaster. Stratification raster used sampling. existing sf data.frame.  Existing plot network. plot Logical. Plots existing (circles) new (crosses) samples.","code":""},{"path":"/reference/calculate_representation.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compare representation of samples within sraster strata — calculate_representation","text":"Returns tibble : strata - sraster strata ID. srasterFreq - Coverage frequency percent sraster strata. sampleFreq - Sampling frequency percent within sraster strata. diffFreq - Difference srasterFreq & sampleFreq. Positive values indicate representation nSamp - Number samples within strata existing. need - srasterFreq * sum(nSamp). Total theoretical number required samples representative strata coverage. values rounded. important user consider diffFreq. small difference - e.g. 1 percent - sample vs. sraster frequency correspond algorithm allocating removing samples likely ignored.","code":""},{"path":"/reference/calculate_representation.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Compare representation of samples within sraster strata — calculate_representation","text":"Calculate well sraster strata represented existing samples","code":""},{"path":[]},{"path":"/reference/calculate_representation.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Compare representation of samples within sraster strata — calculate_representation","text":"Tristan R.H. Goodbody, Martin Queinnec","code":""},{"path":"/reference/calculate_representation.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compare representation of samples within sraster strata — calculate_representation","text":"","code":"### --- generate example stratification ---###  #--- load ALS metrics from sgsR internal data ---# r <- system.file(\"extdata\", \"wall_metrics.tif\", package = \"sgsR\")  #--- read ALS metrics using the terra package ---# mraster <- terra::rast(r)  #--- perform stratification ---# sraster <- strat_kmeans(   mraster = mraster$zq90,   nStrata = 6,   plot = TRUE ) #> K-means being performed on 1 layers with 6 centers.   ### --- create existing sample network ---###  #--- simple random sampling ---# existing <- sample_srs(   raster = mraster$zq90,   nSamp = 100 )  #--- calculate representation ---#  calculate_representation(   sraster = sraster,   existing = existing,   plot = TRUE )  #> # A tibble: 6 x 6 #>   strata srasterFreq sampleFreq diffFreq nSamp  need #>    <dbl>       <dbl>      <dbl>    <dbl> <int> <dbl> #> 1      1        0.18       0.16  -0.0200    16     2 #> 2      2        0.27       0.36   0.09      36    -9 #> 3      3        0.12       0.07  -0.05       7     5 #> 4      4        0.09       0.1    0.0100    10    -1 #> 5      5        0.09       0.05  -0.04       5     4 #> 6      6        0.24       0.26   0.0200    26    -2"},{"path":"/reference/calculate_sampsize.html","id":null,"dir":"Reference","previous_headings":"","what":"Sample size determination — calculate_sampsize","title":"Sample size determination — calculate_sampsize","text":"Determine samples size simple random sampling using relative standard error","code":""},{"path":"/reference/calculate_sampsize.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sample size determination — calculate_sampsize","text":"","code":"calculate_sampsize(   mraster,   rse = NULL,   start = 0.01,   end = 0.05,   increment = 0.001,   plot = FALSE )"},{"path":"/reference/calculate_sampsize.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sample size determination — calculate_sampsize","text":"mraster spatRaster. Metrics raster. values must numeric. rse Numeric. Desired relative standard error (coefficient variation mean) threshold determine sample size. start Numeric. First rse value begin rse sequence. default = 0.01. end Numeric. Final rse value end rse sequence. default = 0.05. increment Numeric. Value increment start & end. default = 0.001. plot Logical. TRUE output graphical representation estimated sample size vs. rse.","code":""},{"path":"/reference/calculate_sampsize.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sample size determination — calculate_sampsize","text":"data.frame sample size rse raster variable.","code":""},{"path":"/reference/calculate_sampsize.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Sample size determination — calculate_sampsize","text":"$$rse = (100 * SE) / mean)$$ : SE - Standard error mean s - Standard deviation observations n - Number observations","code":""},{"path":"/reference/calculate_sampsize.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Sample size determination — calculate_sampsize","text":"Benedetti, R., Piersimoni, F., & Postiglione, P. (2015). Sampling spatial units agricultural surveys. pp 202-203. Berlin: Springer.","code":""},{"path":[]},{"path":"/reference/calculate_sampsize.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Sample size determination — calculate_sampsize","text":"Tristan R.H. Goodbody","code":""},{"path":"/reference/calculate_sampsize.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Sample size determination — calculate_sampsize","text":"","code":"#--- Load raster ---# r <- system.file(\"extdata\", \"wall_metrics.tif\", package = \"sgsR\") mr <- terra::rast(r)  calculate_sampsize(   mraster = mr,   rse = 0.01,   plot = TRUE ) #> $nSamp #>   nSamp  rse      var #> 1  2030 0.01    zmean #> 2  1341 0.01 pzabove2 #> 3  1859 0.01      zsd #> 4  3647 0.01     zq20 #> 5  2581 0.01     zq50 #> 6  2110 0.01     zq70 #> 7  1394 0.01     zq90 #>  #> $plot  #>   calculate_sampsize(   mraster = mr,   plot = TRUE ) #> $nSamp #>     nSamp   rse      var #> 1    2030 0.010    zmean #> 2    1684 0.011    zmean #> 3    1419 0.012    zmean #> 4    1212 0.013    zmean #> 5    1047 0.014    zmean #> 6     914 0.015    zmean #> 7     804 0.016    zmean #> 8     713 0.017    zmean #> 9     637 0.018    zmean #> 10    572 0.019    zmean #> 11    516 0.020    zmean #> 12    469 0.021    zmean #> 13    427 0.022    zmean #> 14    391 0.023    zmean #> 15    359 0.024    zmean #> 16    331 0.025    zmean #> 17    306 0.026    zmean #> 18    284 0.027    zmean #> 19    264 0.028    zmean #> 20    247 0.029    zmean #> 21    230 0.030    zmean #> 22    216 0.031    zmean #> 23    203 0.032    zmean #> 24    191 0.033    zmean #> 25    180 0.034    zmean #> 26    170 0.035    zmean #> 27    160 0.036    zmean #> 28    152 0.037    zmean #> 29    144 0.038    zmean #> 30    137 0.039    zmean #> 31    130 0.040    zmean #> 32    124 0.041    zmean #> 33    118 0.042    zmean #> 34    113 0.043    zmean #> 35    108 0.044    zmean #> 36    103 0.045    zmean #> 37     98 0.046    zmean #> 38     94 0.047    zmean #> 39     90 0.048    zmean #> 40     87 0.049    zmean #> 41     83 0.050    zmean #> 42   1341 0.010 pzabove2 #> 43   1111 0.011 pzabove2 #> 44    935 0.012 pzabove2 #> 45    798 0.013 pzabove2 #> 46    689 0.014 pzabove2 #> 47    601 0.015 pzabove2 #> 48    529 0.016 pzabove2 #> 49    469 0.017 pzabove2 #> 50    418 0.018 pzabove2 #> 51    376 0.019 pzabove2 #> 52    339 0.020 pzabove2 #> 53    308 0.021 pzabove2 #> 54    281 0.022 pzabove2 #> 55    257 0.023 pzabove2 #> 56    236 0.024 pzabove2 #> 57    218 0.025 pzabove2 #> 58    201 0.026 pzabove2 #> 59    187 0.027 pzabove2 #> 60    174 0.028 pzabove2 #> 61    162 0.029 pzabove2 #> 62    151 0.030 pzabove2 #> 63    142 0.031 pzabove2 #> 64    133 0.032 pzabove2 #> 65    125 0.033 pzabove2 #> 66    118 0.034 pzabove2 #> 67    111 0.035 pzabove2 #> 68    105 0.036 pzabove2 #> 69    100 0.037 pzabove2 #> 70     95 0.038 pzabove2 #> 71     90 0.039 pzabove2 #> 72     85 0.040 pzabove2 #> 73     81 0.041 pzabove2 #> 74     78 0.042 pzabove2 #> 75     74 0.043 pzabove2 #> 76     71 0.044 pzabove2 #> 77     68 0.045 pzabove2 #> 78     65 0.046 pzabove2 #> 79     62 0.047 pzabove2 #> 80     59 0.048 pzabove2 #> 81     57 0.049 pzabove2 #> 82     55 0.050 pzabove2 #> 83   1859 0.010      zsd #> 84   1542 0.011      zsd #> 85   1299 0.012      zsd #> 86   1109 0.013      zsd #> 87    958 0.014      zsd #> 88    836 0.015      zsd #> 89    735 0.016      zsd #> 90    652 0.017      zsd #> 91    582 0.018      zsd #> 92    523 0.019      zsd #> 93    472 0.020      zsd #> 94    429 0.021      zsd #> 95    391 0.022      zsd #> 96    358 0.023      zsd #> 97    329 0.024      zsd #> 98    303 0.025      zsd #> 99    280 0.026      zsd #> 100   260 0.027      zsd #> 101   242 0.028      zsd #> 102   225 0.029      zsd #> 103   211 0.030      zsd #> 104   197 0.031      zsd #> 105   185 0.032      zsd #> 106   174 0.033      zsd #> 107   164 0.034      zsd #> 108   155 0.035      zsd #> 109   147 0.036      zsd #> 110   139 0.037      zsd #> 111   132 0.038      zsd #> 112   125 0.039      zsd #> 113   119 0.040      zsd #> 114   113 0.041      zsd #> 115   108 0.042      zsd #> 116   103 0.043      zsd #> 117    98 0.044      zsd #> 118    94 0.045      zsd #> 119    90 0.046      zsd #> 120    86 0.047      zsd #> 121    83 0.048      zsd #> 122    79 0.049      zsd #> 123    76 0.050      zsd #> 124  3647 0.010     zq20 #> 125  3035 0.011     zq20 #> 126  2564 0.012     zq20 #> 127  2194 0.013     zq20 #> 128  1898 0.014     zq20 #> 129  1658 0.015     zq20 #> 130  1460 0.016     zq20 #> 131  1296 0.017     zq20 #> 132  1158 0.018     zq20 #> 133  1041 0.019     zq20 #> 134   940 0.020     zq20 #> 135   854 0.021     zq20 #> 136   779 0.022     zq20 #> 137   713 0.023     zq20 #> 138   655 0.024     zq20 #> 139   604 0.025     zq20 #> 140   559 0.026     zq20 #> 141   519 0.027     zq20 #> 142   482 0.028     zq20 #> 143   450 0.029     zq20 #> 144   421 0.030     zq20 #> 145   394 0.031     zq20 #> 146   370 0.032     zq20 #> 147   348 0.033     zq20 #> 148   328 0.034     zq20 #> 149   310 0.035     zq20 #> 150   293 0.036     zq20 #> 151   277 0.037     zq20 #> 152   263 0.038     zq20 #> 153   250 0.039     zq20 #> 154   237 0.040     zq20 #> 155   226 0.041     zq20 #> 156   215 0.042     zq20 #> 157   205 0.043     zq20 #> 158   196 0.044     zq20 #> 159   188 0.045     zq20 #> 160   180 0.046     zq20 #> 161   172 0.047     zq20 #> 162   165 0.048     zq20 #> 163   158 0.049     zq20 #> 164   152 0.050     zq20 #> 165  2581 0.010     zq50 #> 166  2144 0.011     zq50 #> 167  1808 0.012     zq50 #> 168  1546 0.013     zq50 #> 169  1336 0.014     zq50 #> 170  1166 0.015     zq50 #> 171  1026 0.016     zq50 #> 172   910 0.017     zq50 #> 173   813 0.018     zq50 #> 174   730 0.019     zq50 #> 175   660 0.020     zq50 #> 176   599 0.021     zq50 #> 177   546 0.022     zq50 #> 178   500 0.023     zq50 #> 179   459 0.024     zq50 #> 180   424 0.025     zq50 #> 181   392 0.026     zq50 #> 182   363 0.027     zq50 #> 183   338 0.028     zq50 #> 184   315 0.029     zq50 #> 185   295 0.030     zq50 #> 186   276 0.031     zq50 #> 187   259 0.032     zq50 #> 188   244 0.033     zq50 #> 189   230 0.034     zq50 #> 190   217 0.035     zq50 #> 191   205 0.036     zq50 #> 192   194 0.037     zq50 #> 193   184 0.038     zq50 #> 194   175 0.039     zq50 #> 195   166 0.040     zq50 #> 196   158 0.041     zq50 #> 197   151 0.042     zq50 #> 198   144 0.043     zq50 #> 199   137 0.044     zq50 #> 200   131 0.045     zq50 #> 201   126 0.046     zq50 #> 202   121 0.047     zq50 #> 203   116 0.048     zq50 #> 204   111 0.049     zq50 #> 205   107 0.050     zq50 #> 206  2110 0.010     zq70 #> 207  1751 0.011     zq70 #> 208  1476 0.012     zq70 #> 209  1261 0.013     zq70 #> 210  1089 0.014     zq70 #> 211   950 0.015     zq70 #> 212   836 0.016     zq70 #> 213   742 0.017     zq70 #> 214   662 0.018     zq70 #> 215   595 0.019     zq70 #> 216   537 0.020     zq70 #> 217   488 0.021     zq70 #> 218   445 0.022     zq70 #> 219   407 0.023     zq70 #> 220   374 0.024     zq70 #> 221   345 0.025     zq70 #> 222   319 0.026     zq70 #> 223   296 0.027     zq70 #> 224   275 0.028     zq70 #> 225   257 0.029     zq70 #> 226   240 0.030     zq70 #> 227   225 0.031     zq70 #> 228   211 0.032     zq70 #> 229   198 0.033     zq70 #> 230   187 0.034     zq70 #> 231   176 0.035     zq70 #> 232   167 0.036     zq70 #> 233   158 0.037     zq70 #> 234   150 0.038     zq70 #> 235   142 0.039     zq70 #> 236   135 0.040     zq70 #> 237   129 0.041     zq70 #> 238   123 0.042     zq70 #> 239   117 0.043     zq70 #> 240   112 0.044     zq70 #> 241   107 0.045     zq70 #> 242   102 0.046     zq70 #> 243    98 0.047     zq70 #> 244    94 0.048     zq70 #> 245    90 0.049     zq70 #> 246    87 0.050     zq70 #> 247  1394 0.010     zq90 #> 248  1155 0.011     zq90 #> 249   973 0.012     zq90 #> 250   830 0.013     zq90 #> 251   717 0.014     zq90 #> 252   625 0.015     zq90 #> 253   550 0.016     zq90 #> 254   488 0.017     zq90 #> 255   435 0.018     zq90 #> 256   391 0.019     zq90 #> 257   353 0.020     zq90 #> 258   320 0.021     zq90 #> 259   292 0.022     zq90 #> 260   267 0.023     zq90 #> 261   246 0.024     zq90 #> 262   226 0.025     zq90 #> 263   209 0.026     zq90 #> 264   194 0.027     zq90 #> 265   181 0.028     zq90 #> 266   168 0.029     zq90 #> 267   157 0.030     zq90 #> 268   148 0.031     zq90 #> 269   138 0.032     zq90 #> 270   130 0.033     zq90 #> 271   123 0.034     zq90 #> 272   116 0.035     zq90 #> 273   110 0.036     zq90 #> 274   104 0.037     zq90 #> 275    98 0.038     zq90 #> 276    93 0.039     zq90 #> 277    89 0.040     zq90 #> 278    85 0.041     zq90 #> 279    81 0.042     zq90 #> 280    77 0.043     zq90 #> 281    74 0.044     zq90 #> 282    70 0.045     zq90 #> 283    67 0.046     zq90 #> 284    65 0.047     zq90 #> 285    62 0.048     zq90 #> 286    59 0.049     zq90 #> 287    57 0.050     zq90 #>  #> $plot  #>   calculate_sampsize(   mraster = mr,   rse = 0.025,   start = 0.01,   end = 0.08,   increment = 0.01,   plot = TRUE ) #> 'rse' not perfectly divisible by 'incremenent.  #> Selecting closest sample size (rse = 0.03) based on values. #> $nSamp #> # A tibble: 7 x 3 #> # Groups:   var [7] #>   nSamp   rse var      #>   <dbl> <dbl> <chr>    #> 1   230  0.03 zmean    #> 2   151  0.03 pzabove2 #> 3   211  0.03 zsd      #> 4   421  0.03 zq20     #> 5   295  0.03 zq50     #> 6   240  0.03 zq70     #> 7   157  0.03 zq90     #>  #> $plot  #>   #--- higher variance leads to need for more samples ---#"},{"path":"/reference/extract.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract — extract","title":"Extract — extract","text":"Extract raster values samples Extract metric raster attributes existing","code":""},{"path":"/reference/extract.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract — extract","text":"","code":"extract_strata(   sraster,   existing,   data.frame = FALSE,   filename = NULL,   overwrite = FALSE )  extract_metrics(   mraster,   existing,   data.frame = FALSE,   filename = NULL,   overwrite = FALSE )"},{"path":"/reference/extract.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract — extract","text":"sraster spatRaster. Stratification raster. existing sf. Samples resulting sample_* functions. data.frame Logical. true outputs data.frame filename Character. Path write stratified raster disc. overwrite Logical. Specify whether filename overwritten disc. mraster Spatraster. Primary covariate raster stratify.","code":""},{"path":"/reference/extract.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract — extract","text":"sf data.frame object samples strata attributes sf data.frame object samples associated raster cell attributes","code":""},{"path":"/reference/extract_metrics.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract metrics — extract_metrics","title":"Extract metrics — extract_metrics","text":"Extract metric values existing samples","code":""},{"path":"/reference/extract_metrics.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract metrics — extract_metrics","text":"","code":"extract_metrics(   mraster,   existing,   data.frame = FALSE,   filename = NULL,   overwrite = FALSE )"},{"path":"/reference/extract_metrics.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract metrics — extract_metrics","text":"mraster spatRaster. Metrics Raster. existing sf.  Existing plot network. data.frame Logical. Output data.frame TRUE filename Character. Path write output samples. overwrite Logical. Choice overwrite existing filename exists.","code":""},{"path":"/reference/extract_metrics.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract metrics — extract_metrics","text":"sf data.frame object samples metrics attributes","code":""},{"path":[]},{"path":"/reference/extract_metrics.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Extract metrics — extract_metrics","text":"Tristan R.H. Goodbody","code":""},{"path":"/reference/extract_metrics.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract metrics — extract_metrics","text":"","code":"#--- Load mraster ---# r <- system.file(\"extdata\", \"wall_metrics.tif\", package = \"sgsR\") mr <- terra::rast(r)  #' #--- load existing samples ---# e <- system.file(\"extdata\", \"existing.shp\", package = \"sgsR\") e <- sf::st_read(e) #> Reading layer `existing' from data source  #>   `C:\\Users\\tgood.stu\\Documents\\R\\win-library\\4.1\\sgsR\\extdata\\existing.shp'  #>   using driver `ESRI Shapefile' #> Simple feature collection with 100 features and 1 field #> Geometry type: POINT #> Dimension:     XY #> Bounding box:  xmin: 431110 ymin: 5337750 xmax: 438550 ymax: 5343230 #> CRS:           unknown  extract_metrics(mraster =  mr,                 existing = e) #> Simple feature collection with 100 features and 8 fields #> Geometry type: POINT #> Dimension:     XY #> Bounding box:  xmin: 431110 ymin: 5337750 xmax: 438550 ymax: 5343230 #> CRS:           +proj=utm +zone=17 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs #> First 10 features: #>    FID     zmean pzabove2  zsd zq20      zq50      zq70 zq90 #> 1    0 11.490000     79.7 4.96 6.15 11.429999 15.429999 18.6 #> 2    1 10.679999     91.9 3.90 7.93 10.349999 12.030000 18.2 #> 3    2  5.640000     24.8 4.23 1.61  4.300000  7.990000 13.5 #> 4    3  7.490000     38.5 3.61 3.99  7.620000  9.260000 13.8 #> 5    4  9.170000     69.4 4.20 5.03  9.630000 12.009999 15.5 #> 6    5 11.059999     79.8 5.30 5.59 12.250000 15.020000 18.2 #> 7    6  9.240000     74.8 5.34 2.76  9.250000 12.730000 17.9 #> 8    7  9.420000     89.6 3.63 6.22  9.469999 11.360000 15.4 #> 9    8  9.059999     65.1 4.80 4.33  8.770000 12.030000 17.2 #> 10   9  8.170000     93.5 3.38 5.39  7.970000  9.429999 14.4 #>                  geometry #> 1  POINT (434970 5343030) #> 2  POINT (435590 5340510) #> 3  POINT (434290 5338670) #> 4  POINT (435170 5340410) #> 5  POINT (437550 5340650) #> 6  POINT (435850 5340130) #> 7  POINT (431630 5343230) #> 8  POINT (436510 5340870) #> 9  POINT (435990 5339950) #> 10 POINT (438250 5337770)"},{"path":"/reference/extract_strata.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract strata — extract_strata","title":"Extract strata — extract_strata","text":"Extract stratum values existing samples","code":""},{"path":"/reference/extract_strata.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract strata — extract_strata","text":"","code":"extract_strata(   sraster,   existing,   data.frame = FALSE,   filename = NULL,   overwrite = FALSE )"},{"path":"/reference/extract_strata.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract strata — extract_strata","text":"sraster spatRaster. Stratification raster. existing sf.  Existing plot network. data.frame Logical. Output data.frame TRUE filename Character. Path write output samples. overwrite Logical. Choice overwrite existing filename exists.","code":""},{"path":"/reference/extract_strata.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract strata — extract_strata","text":"sf data.frame object samples strata attribute","code":""},{"path":[]},{"path":"/reference/extract_strata.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Extract strata — extract_strata","text":"Tristan R.H. Goodbody","code":""},{"path":"/reference/extract_strata.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract strata — extract_strata","text":"","code":"#--- Load sraster ---# r <- system.file(\"extdata\", \"kmeans.tif\", package = \"sgsR\") sr <- terra::rast(r)  #--- load existing samples ---# e <- system.file(\"extdata\", \"existing.shp\", package = \"sgsR\") e <- sf::st_read(e) #> Reading layer `existing' from data source  #>   `C:\\Users\\tgood.stu\\Documents\\R\\win-library\\4.1\\sgsR\\extdata\\existing.shp'  #>   using driver `ESRI Shapefile' #> Simple feature collection with 100 features and 1 field #> Geometry type: POINT #> Dimension:     XY #> Bounding box:  xmin: 431110 ymin: 5337750 xmax: 438550 ymax: 5343230 #> CRS:           unknown  extract_strata(sraster = sr,                existing = e) #> Simple feature collection with 100 features and 1 field #> Geometry type: POINT #> Dimension:     XY #> Bounding box:  xmin: 431110 ymin: 5337750 xmax: 438550 ymax: 5343230 #> Projected CRS: UTM Zone 17, Northern Hemisphere #> First 10 features: #>    strata               geometry #> 1       4 POINT (434970 5343030) #> 2       6 POINT (435590 5340510) #> 3       8 POINT (434290 5338670) #> 4       8 POINT (435170 5340410) #> 5       7 POINT (437550 5340650) #> 6       4 POINT (435850 5340130) #> 7       7 POINT (431630 5343230) #> 8       5 POINT (436510 5340870) #> 9       7 POINT (435990 5339950) #> 10      5 POINT (438250 5337770)"},{"path":"/reference/masking.html","id":null,"dir":"Reference","previous_headings":"","what":"Masking — masking","title":"Masking — masking","text":"Create covariate sample matrices","code":""},{"path":"/reference/masking.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Masking — masking","text":"","code":"mask_access(raster, access, buff_inner, buff_outer)"},{"path":"/reference/masking.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Masking — masking","text":"raster SpatRaster. Raster masked. access sf. Road access network - must lines. buff_inner Numeric. Inner buffer boundary specifying distance access plots sampled. buff_outer Numeric. Outer buffer boundary specifying distance access plots can sampled.","code":""},{"path":"/reference/matrices.html","id":null,"dir":"Reference","previous_headings":"","what":"Matrices — matrices","title":"Matrices — matrices","text":"Create covariate sample matrices","code":""},{"path":"/reference/matrices.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Matrices — matrices","text":"","code":"mat_quant(vals, nQuant, nb)  mat_cov(vals, nQuant, nb, matQ)  mat_covNB(vals, nQuant, nb, matQ)"},{"path":"/reference/matrices.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Matrices — matrices","text":"vals Covariate / sample data nQuant Number quantiles nb Number bands matQ Quantile matrix","code":""},{"path":"/reference/pipe.html","id":null,"dir":"Reference","previous_headings":"","what":"Pipe operator — %>%","title":"Pipe operator — %>%","text":"See magrittr::%>% details.","code":""},{"path":"/reference/pipe.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Pipe operator — %>%","text":"","code":"lhs %>% rhs"},{"path":"/reference/pipe.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Pipe operator — %>%","text":"lhs value magrittr placeholder. rhs function call using magrittr semantics.","code":""},{"path":"/reference/pipe.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Pipe operator — %>%","text":"result calling `rhs(lhs)`.","code":""},{"path":"/reference/plot.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot — plot","title":"Plot — plot","text":"Plot Class Plot","code":""},{"path":"/reference/plot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot — plot","text":"","code":"classPlot(dfc, coordsgrps, mraster, mraster2, samp)"},{"path":"/reference/plot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot — plot","text":"dfc data.frame. Values mraster mraster2 coordsgrps List. Cartesian coordinates strata mraster Spatraster. Primary covariate raster stratify. mraster2 Spatraster. Secondary covariate raster stratify. samp Numeric. Determines proportion cells plot","code":""},{"path":"/reference/sample_ahels.html","id":null,"dir":"Reference","previous_headings":"","what":"Adapted Hypercube Evaluation of a Legacy Sample (ahels) — sample_ahels","title":"Adapted Hypercube Evaluation of a Legacy Sample (ahels) — sample_ahels","text":"Perform adapted Hypercube Evaluation Legacy Sample (ahels) algorithm using existing site data raster metrics. New samples allocated based quantile ratios existing sample covariate dataset.","code":""},{"path":"/reference/sample_ahels.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Adapted Hypercube Evaluation of a Legacy Sample (ahels) — sample_ahels","text":"","code":"sample_ahels(   mraster,   existing,   nQuant = 10,   nSamp = NULL,   threshold = 0.9,   plot = FALSE,   details = FALSE,   filename = NULL,   overwrite = FALSE )"},{"path":"/reference/sample_ahels.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Adapted Hypercube Evaluation of a Legacy Sample (ahels) — sample_ahels","text":"mraster spatRaster. ALS metrics raster. existing sf.  Existing plot network. nQuant Numeric. Number quantiles divide covariates samples . Quantiles cover least 1 percent area interest excluded returned NA. nSamp Numeric. Maximum number new samples allocate. provided, algorithm default allocating number samples provided. threshold Numeric. sample quantile ratio threshold establishing whether additional samples added. default = 0.9. Values close 1 can cause algorithm continually loop used sparingly. plot Logial. Plots existing (circles) new (crosses) samples first band mraster. details Logical. FALSE (default) output  stratification raster. TRUE return list $details additional stratification information  $raster output stratification spatRaster.  @param ... Additional arguments passed kmeans function. filename Character. Path write stratified raster disc. overwrite Logical. Specify whether filename overwritten disc.","code":""},{"path":"/reference/sample_ahels.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Adapted Hypercube Evaluation of a Legacy Sample (ahels) — sample_ahels","text":"Returns sf point object existing samples supplemental samples added ahels algorithm.","code":""},{"path":"/reference/sample_ahels.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Adapted Hypercube Evaluation of a Legacy Sample (ahels) — sample_ahels","text":"Messages algorithm state samples added -represented quantiles. number square brackets follow represent matrix column row respectively can printed using details = TRUE. Special thanks Dr. Brendan Malone original implementation algorithm.","code":""},{"path":"/reference/sample_ahels.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Adapted Hypercube Evaluation of a Legacy Sample (ahels) — sample_ahels","text":"Malone BP, Minansy B, Brungard C. 2019. methods improve utility conditioned Latin hypercube sampling. PeerJ 7:e6451 DOI 10.7717/peerj.6451","code":""},{"path":[]},{"path":"/reference/sample_ahels.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Adapted Hypercube Evaluation of a Legacy Sample (ahels) — sample_ahels","text":"Tristan R.H. Goodbody","code":""},{"path":"/reference/sample_ahels.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Adapted Hypercube Evaluation of a Legacy Sample (ahels) — sample_ahels","text":"","code":"#--- Load raster and existing plots---# r <- system.file(\"extdata\", \"wall_metrics.tif\", package = \"sgsR\") mr <- terra::rast(r)  e <- system.file(\"extdata\", \"existing.shp\", package = \"sgsR\") e <- sf::st_read(e) #> Reading layer `existing' from data source  #>   `C:\\Users\\tgood.stu\\Documents\\R\\win-library\\4.1\\sgsR\\extdata\\existing.shp'  #>   using driver `ESRI Shapefile' #> Simple feature collection with 100 features and 1 field #> Geometry type: POINT #> Dimension:     XY #> Bounding box:  xmin: 431110 ymin: 5337750 xmax: 438550 ymax: 5343230 #> CRS:           unknown  sample_ahels(   mraster = mr[[1:3]],   existing = e,   plot = TRUE ) #> Creating covariance matrix. #>    |                                                                       |                                                              |   0%   |                                                                       |                                                              |   1%   |                                                                       |=                                                             |   1%   |                                                                       |=                                                             |   2%   |                                                                       |==                                                            |   2%   |                                                                       |==                                                            |   3%   |                                                                       |==                                                            |   4%   |                                                                       |===                                                           |   4%   |                                                                       |===                                                           |   5%   |                                                                       |===                                                           |   6%   |                                                                       |====                                                          |   6%   |                                                                       |====                                                          |   7%   |                                                                       |=====                                                         |   7%   |                                                                       |=====                                                         |   8%   |                                                                       |=====                                                         |   9%   |                                                                       |======                                                        |   9%   |                                                                       |======                                                        |  10%   |                                                                       |=======                                                       |  10%   |                                                                       |=======                                                       |  11%   |                                                                       |=======                                                       |  12%   |                                                                       |========                                                      |  12%   |                                                                       |========                                                      |  13%   |                                                                       |========                                                      |  14%   |                                                                       |=========                                                     |  14%   |                                                                       |=========                                                     |  15%   |                                                                       |==========                                                    |  15%   |                                                                       |==========                                                    |  16%   |                                                                       |==========                                                    |  17%   |                                                                       |===========                                                   |  17%   |                                                                       |===========                                                   |  18%   |                                                                       |===========                                                   |  19%   |                                                                       |============                                                  |  19%   |                                                                       |============                                                  |  20%   |                                                                       |=============                                                 |  20%   |                                                                       |=============                                                 |  21%   |                                                                       |=============                                                 |  22%   |                                                                       |==============                                                |  22%   |                                                                       |==============                                                |  23%   |                                                                       |===============                                               |  23%   |                                                                       |===============                                               |  24%   |                                                                       |===============                                               |  25%   |                                                                       |================                                              |  25%   |                                                                       |================                                              |  26%   |                                                                       |================                                              |  27%   |                                                                       |=================                                             |  27%   |                                                                       |=================                                             |  28%   |                                                                       |==================                                            |  28%   |                                                                       |==================                                            |  29%   |                                                                       |==================                                            |  30%   |                                                                       |===================                                           |  30%   |                                                                       |===================                                           |  31%   |                                                                       |====================                                          |  31%   |                                                                       |====================                                          |  32%   |                                                                       |====================                                          |  33%   |                                                                       |=====================                                         |  33%   |                                                                       |=====================                                         |  34%   |                                                                       |=====================                                         |  35%   |                                                                       |======================                                        |  35%   |                                                                       |======================                                        |  36%   |                                                                       |=======================                                       |  36%   |                                                                       |=======================                                       |  37%   |                                                                       |=======================                                       |  38%   |                                                                       |========================                                      |  38%   |                                                                       |========================                                      |  39%   |                                                                       |========================                                      |  40%   |                                                                       |=========================                                     |  40%   |                                                                       |=========================                                     |  41%   |                                                                       |==========================                                    |  41%   |                                                                       |==========================                                    |  42%   |                                                                       |==========================                                    |  43%   |                                                                       |===========================                                   |  43%   |                                                                       |===========================                                   |  44%   |                                                                       |============================                                  |  44%   |                                                                       |============================                                  |  45%   |                                                                       |============================                                  |  46%   |                                                                       |=============================                                 |  46%   |                                                                       |=============================                                 |  47%   |                                                                       |=============================                                 |  48%   |                                                                       |==============================                                |  48%   |                                                                       |==============================                                |  49%   |                                                                       |===============================                               |  49%   |                                                                       |===============================                               |  50%   |                                                                       |===============================                               |  51%   |                                                                       |================================                              |  51%   |                                                                       |================================                              |  52%   |                                                                       |=================================                             |  52%   |                                                                       |=================================                             |  53%   |                                                                       |=================================                             |  54%   |                                                                       |==================================                            |  54%   |                                                                       |==================================                            |  55%   |                                                                       |==================================                            |  56%   |                                                                       |===================================                           |  56%   |                                                                       |===================================                           |  57%   |                                                                       |====================================                          |  57%   |                                                                       |====================================                          |  58%   |                                                                       |====================================                          |  59%   |                                                                       |=====================================                         |  59%   |                                                                       |=====================================                         |  60%   |                                                                       |======================================                        |  60%   |                                                                       |======================================                        |  61%   |                                                                       |======================================                        |  62%   |                                                                       |=======================================                       |  62%   |                                                                       |=======================================                       |  63%   |                                                                       |=======================================                       |  64%   |                                                                       |========================================                      |  64%   |                                                                       |========================================                      |  65%   |                                                                       |=========================================                     |  65%   |                                                                       |=========================================                     |  66%   |                                                                       |=========================================                     |  67%   |                                                                       |==========================================                    |  67%   |                                                                       |==========================================                    |  68%   |                                                                       |==========================================                    |  69%   |                                                                       |===========================================                   |  69%   |                                                                       |===========================================                   |  70%   |                                                                       |============================================                  |  70%   |                                                                       |============================================                  |  71%   |                                                                       |============================================                  |  72%   |                                                                       |=============================================                 |  72%   |                                                                       |=============================================                 |  73%   |                                                                       |==============================================                |  73%   |                                                                       |==============================================                |  74%   |                                                                       |==============================================                |  75%   |                                                                       |===============================================               |  75%   |                                                                       |===============================================               |  76%   |                                                                       |===============================================               |  77%   |                                                                       |================================================              |  77%   |                                                                       |================================================              |  78%   |                                                                       |=================================================             |  78%   |                                                                       |=================================================             |  79%   |                                                                       |=================================================             |  80%   |                                                                       |==================================================            |  80%   |                                                                       |==================================================            |  81%   |                                                                       |===================================================           |  81%   |                                                                       |===================================================           |  82%   |                                                                       |===================================================           |  83%   |                                                                       |====================================================          |  83%   |                                                                       |====================================================          |  84%   |                                                                       |====================================================          |  85%   |                                                                       |=====================================================         |  85%   |                                                                       |=====================================================         |  86%   |                                                                       |======================================================        |  86%   |                                                                       |======================================================        |  87%   |                                                                       |======================================================        |  88%   |                                                                       |=======================================================       |  88%   |                                                                       |=======================================================       |  89%   |                                                                       |=======================================================       |  90%   |                                                                       |========================================================      |  90%   |                                                                       |========================================================      |  91%   |                                                                       |=========================================================     |  91%   |                                                                       |=========================================================     |  92%   |                                                                       |=========================================================     |  93%   |                                                                       |==========================================================    |  93%   |                                                                       |==========================================================    |  94%   |                                                                       |===========================================================   |  94%   |                                                                       |===========================================================   |  95%   |                                                                       |===========================================================   |  96%   |                                                                       |============================================================  |  96%   |                                                                       |============================================================  |  97%   |                                                                       |============================================================  |  98%   |                                                                       |============================================================= |  98%   |                                                                       |============================================================= |  99%   |                                                                       |==============================================================|  99%   |                                                                       |==============================================================| 100% #> threshold of 0.9 has been provided. Samples will be added until quantile ratio is reached #> Underrepresented Quantile 1 - A total of 5 samples have been allocated. #> Underrepresented Quantile 2 - A total of 2 samples have been allocated. #> Underrepresented Quantile 3 - A total of 5 samples have been allocated. #> Underrepresented Quantile 4 - A total of 2 samples have been allocated. #> Underrepresented Quantile 5 - A total of 5 samples have been allocated. #> Underrepresented Quantile 6 - A total of 2 samples have been allocated. #> Underrepresented Quantile 7 - A total of 5 samples have been allocated. #> Underrepresented Quantile 8 - A total of 2 samples have been allocated. #> Underrepresented Quantile 9 - A total of 5 samples have been allocated. #> Underrepresented Quantile 10 - A total of 3 samples have been allocated. #> Underrepresented Quantile 11 - A total of 5 samples have been allocated. #> Underrepresented Quantile 12 - A total of 3 samples have been allocated. #> Underrepresented Quantile 13 - A total of 4 samples have been allocated. #> Underrepresented Quantile 14 - A total of 1 samples have been allocated. #> Underrepresented Quantile 15 - A total of 1 samples have been allocated. #> Underrepresented Quantile 16 - A total of 7 samples have been allocated. #> Underrepresented Quantile 17 - A total of 1 samples have been allocated. #> A total of 58 new samples added  #> Simple feature collection with 158 features and 4 fields #> Geometry type: POINT #> Dimension:     XY #> Bounding box:  xmin: 431110 ymin: 5337750 xmax: 438550 ymax: 5343230 #> CRS:           +proj=utm +zone=17 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs #> First 10 features: #>        type     zmean pzabove2  zsd               geometry #> 1  existing 11.490000     79.7 4.96 POINT (434970 5343030) #> 2  existing 10.679999     91.9 3.90 POINT (435590 5340510) #> 3  existing  5.640000     24.8 4.23 POINT (434290 5338670) #> 4  existing  7.490000     38.5 3.61 POINT (435170 5340410) #> 5  existing  9.170000     69.4 4.20 POINT (437550 5340650) #> 6  existing 11.059999     79.8 5.30 POINT (435850 5340130) #> 7  existing  9.240000     74.8 5.34 POINT (431630 5343230) #> 8  existing  9.420000     89.6 3.63 POINT (436510 5340870) #> 9  existing  9.059999     65.1 4.80 POINT (435990 5339950) #> 10 existing  8.170000     93.5 3.38 POINT (438250 5337770)  sample_ahels(   mraster = mr[[1:3]],   existing = e,   nQuant = 20,   nSamp = 300,   filename = tempfile(fileext = \".shp\") ) #> Creating covariance matrix. #>    |                                                                       |                                                              |   0%   |                                                                       |                                                              |   1%   |                                                                       |=                                                             |   1%   |                                                                       |=                                                             |   2%   |                                                                       |==                                                            |   2%   |                                                                       |==                                                            |   3%   |                                                                       |==                                                            |   4%   |                                                                       |===                                                           |   4%   |                                                                       |===                                                           |   5%   |                                                                       |===                                                           |   6%   |                                                                       |====                                                          |   6%   |                                                                       |====                                                          |   7%   |                                                                       |=====                                                         |   7%   |                                                                       |=====                                                         |   8%   |                                                                       |=====                                                         |   9%   |                                                                       |======                                                        |   9%   |                                                                       |======                                                        |  10%   |                                                                       |=======                                                       |  10%   |                                                                       |=======                                                       |  11%   |                                                                       |=======                                                       |  12%   |                                                                       |========                                                      |  12%   |                                                                       |========                                                      |  13%   |                                                                       |========                                                      |  14%   |                                                                       |=========                                                     |  14%   |                                                                       |=========                                                     |  15%   |                                                                       |==========                                                    |  15%   |                                                                       |==========                                                    |  16%   |                                                                       |==========                                                    |  17%   |                                                                       |===========                                                   |  17%   |                                                                       |===========                                                   |  18%   |                                                                       |===========                                                   |  19%   |                                                                       |============                                                  |  19%   |                                                                       |============                                                  |  20%   |                                                                       |=============                                                 |  20%   |                                                                       |=============                                                 |  21%   |                                                                       |=============                                                 |  22%   |                                                                       |==============                                                |  22%   |                                                                       |==============                                                |  23%   |                                                                       |===============                                               |  23%   |                                                                       |===============                                               |  24%   |                                                                       |===============                                               |  25%   |                                                                       |================                                              |  25%   |                                                                       |================                                              |  26%   |                                                                       |================                                              |  27%   |                                                                       |=================                                             |  27%   |                                                                       |=================                                             |  28%   |                                                                       |==================                                            |  28%   |                                                                       |==================                                            |  29%   |                                                                       |==================                                            |  30%   |                                                                       |===================                                           |  30%   |                                                                       |===================                                           |  31%   |                                                                       |====================                                          |  31%   |                                                                       |====================                                          |  32%   |                                                                       |====================                                          |  33%   |                                                                       |=====================                                         |  33%   |                                                                       |=====================                                         |  34%   |                                                                       |=====================                                         |  35%   |                                                                       |======================                                        |  35%   |                                                                       |======================                                        |  36%   |                                                                       |=======================                                       |  36%   |                                                                       |=======================                                       |  37%   |                                                                       |=======================                                       |  38%   |                                                                       |========================                                      |  38%   |                                                                       |========================                                      |  39%   |                                                                       |========================                                      |  40%   |                                                                       |=========================                                     |  40%   |                                                                       |=========================                                     |  41%   |                                                                       |==========================                                    |  41%   |                                                                       |==========================                                    |  42%   |                                                                       |==========================                                    |  43%   |                                                                       |===========================                                   |  43%   |                                                                       |===========================                                   |  44%   |                                                                       |============================                                  |  44%   |                                                                       |============================                                  |  45%   |                                                                       |============================                                  |  46%   |                                                                       |=============================                                 |  46%   |                                                                       |=============================                                 |  47%   |                                                                       |=============================                                 |  48%   |                                                                       |==============================                                |  48%   |                                                                       |==============================                                |  49%   |                                                                       |===============================                               |  49%   |                                                                       |===============================                               |  50%   |                                                                       |===============================                               |  51%   |                                                                       |================================                              |  51%   |                                                                       |================================                              |  52%   |                                                                       |=================================                             |  52%   |                                                                       |=================================                             |  53%   |                                                                       |=================================                             |  54%   |                                                                       |==================================                            |  54%   |                                                                       |==================================                            |  55%   |                                                                       |==================================                            |  56%   |                                                                       |===================================                           |  56%   |                                                                       |===================================                           |  57%   |                                                                       |====================================                          |  57%   |                                                                       |====================================                          |  58%   |                                                                       |====================================                          |  59%   |                                                                       |=====================================                         |  59%   |                                                                       |=====================================                         |  60%   |                                                                       |======================================                        |  60%   |                                                                       |======================================                        |  61%   |                                                                       |======================================                        |  62%   |                                                                       |=======================================                       |  62%   |                                                                       |=======================================                       |  63%   |                                                                       |=======================================                       |  64%   |                                                                       |========================================                      |  64%   |                                                                       |========================================                      |  65%   |                                                                       |=========================================                     |  65%   |                                                                       |=========================================                     |  66%   |                                                                       |=========================================                     |  67%   |                                                                       |==========================================                    |  67%   |                                                                       |==========================================                    |  68%   |                                                                       |==========================================                    |  69%   |                                                                       |===========================================                   |  69%   |                                                                       |===========================================                   |  70%   |                                                                       |============================================                  |  70%   |                                                                       |============================================                  |  71%   |                                                                       |============================================                  |  72%   |                                                                       |=============================================                 |  72%   |                                                                       |=============================================                 |  73%   |                                                                       |==============================================                |  73%   |                                                                       |==============================================                |  74%   |                                                                       |==============================================                |  75%   |                                                                       |===============================================               |  75%   |                                                                       |===============================================               |  76%   |                                                                       |===============================================               |  77%   |                                                                       |================================================              |  77%   |                                                                       |================================================              |  78%   |                                                                       |=================================================             |  78%   |                                                                       |=================================================             |  79%   |                                                                       |=================================================             |  80%   |                                                                       |==================================================            |  80%   |                                                                       |==================================================            |  81%   |                                                                       |===================================================           |  81%   |                                                                       |===================================================           |  82%   |                                                                       |===================================================           |  83%   |                                                                       |====================================================          |  83%   |                                                                       |====================================================          |  84%   |                                                                       |====================================================          |  85%   |                                                                       |=====================================================         |  85%   |                                                                       |=====================================================         |  86%   |                                                                       |======================================================        |  86%   |                                                                       |======================================================        |  87%   |                                                                       |======================================================        |  88%   |                                                                       |=======================================================       |  88%   |                                                                       |=======================================================       |  89%   |                                                                       |=======================================================       |  90%   |                                                                       |========================================================      |  90%   |                                                                       |========================================================      |  91%   |                                                                       |=========================================================     |  91%   |                                                                       |=========================================================     |  92%   |                                                                       |=========================================================     |  93%   |                                                                       |==========================================================    |  93%   |                                                                       |==========================================================    |  94%   |                                                                       |===========================================================   |  94%   |                                                                       |===========================================================   |  95%   |                                                                       |===========================================================   |  96%   |                                                                       |============================================================  |  96%   |                                                                       |============================================================  |  97%   |                                                                       |============================================================  |  98%   |                                                                       |============================================================= |  98%   |                                                                       |============================================================= |  99%   |                                                                       |==============================================================|  99%   |                                                                       |==============================================================| 100% #> nSamp of 300 has been provided. Samples will be added until this number is reached #> Under-represented Quantile [3,1] - A total of 3 samples have been allocated. #> Under-represented Quantile [2,1] - A total of 3 samples have been allocated. #> Under-represented Quantile [1,15] - A total of 2 samples have been allocated. #> Under-represented Quantile [3,10] - A total of 4 samples have been allocated. #> Under-represented Quantile [2,12] - A total of 2 samples have been allocated. #> Under-represented Quantile [3,11] - A total of 2 samples have been allocated. #> Under-represented Quantile [2,2] - A total of 2 samples have been allocated. #> Under-represented Quantile [2,9] - A total of 2 samples have been allocated. #> Under-represented Quantile [1,9] - A total of 6 samples have been allocated. #> Under-represented Quantile [2,7] - A total of 1 samples have been allocated. #> Under-represented Quantile [2,17] - A total of 6 samples have been allocated. #> Under-represented Quantile [3,12] - A total of 1 samples have been allocated. #> Under-represented Quantile [1,3] - A total of 4 samples have been allocated. #> Under-represented Quantile [1,12] - A total of 4 samples have been allocated. #> Under-represented Quantile [2,13] - A total of 2 samples have been allocated. #> Under-represented Quantile [2,14] - A total of 3 samples have been allocated. #> Under-represented Quantile [2,3] - A total of 1 samples have been allocated. #> Under-represented Quantile [2,10] - A total of 1 samples have been allocated. #> Under-represented Quantile [1,8] - A total of 5 samples have been allocated. #> Under-represented Quantile [2,1] - A total of 2 samples have been allocated. #> Under-represented Quantile [2,19] - A total of 10 samples have been allocated. #> Under-represented Quantile [3,10] - A total of 3 samples have been allocated. #> Under-represented Quantile [2,12] - A total of 2 samples have been allocated. #> Under-represented Quantile [3,3] - A total of 4 samples have been allocated. #> Under-represented Quantile [2,6] - A total of 1 samples have been allocated. #> Under-represented Quantile [3,9] - A total of 4 samples have been allocated. #> Under-represented Quantile [2,16] - A total of 4 samples have been allocated. #> Under-represented Quantile [1,9] - A total of 6 samples have been allocated. #> Under-represented Quantile [2,2] - A total of 2 samples have been allocated. #> Under-represented Quantile [2,3] - A total of 1 samples have been allocated. #> Under-represented Quantile [2,10] - A total of 1 samples have been allocated. #> Under-represented Quantile [3,5] - A total of 6 samples have been allocated. #> Under-represented Quantile [1,10] - A total of 4 samples have been allocated. #> Under-represented Quantile [1,13] - A total of 2 samples have been allocated. #> Under-represented Quantile [2,11] - A total of 2 samples have been allocated. #> Under-represented Quantile [2,17] - A total of 4 samples have been allocated. #> Under-represented Quantile [3,6] - A total of 6 samples have been allocated. #> Under-represented Quantile [2,14] - A total of 2 samples have been allocated. #> Under-represented Quantile [2,1] - A total of 2 samples have been allocated. #> Under-represented Quantile [2,5] - A total of 1 samples have been allocated. #> Under-represented Quantile [2,6] - A total of 1 samples have been allocated. #> Under-represented Quantile [1,15] - A total of 1 samples have been allocated. #> Under-represented Quantile [1,11] - A total of 4 samples have been allocated. #> Under-represented Quantile [2,10] - A total of 1 samples have been allocated. #> Under-represented Quantile [1,4] - A total of 3 samples have been allocated. #> Under-represented Quantile [3,3] - A total of 2 samples have been allocated. #> Under-represented Quantile [1,13] - A total of 2 samples have been allocated. #> Under-represented Quantile [2,19] - A total of 7 samples have been allocated. #> Under-represented Quantile [2,17] - A total of 4 samples have been allocated. #> Under-represented Quantile [1,12] - A total of 3 samples have been allocated. #> Under-represented Quantile [3,5] - A total of 6 samples have been allocated. #> Under-represented Quantile [3,11] - A total of 1 samples have been allocated. #> Under-represented Quantile [2,16] - A total of 3 samples have been allocated. #> Under-represented Quantile [2,2] - A total of 1 samples have been allocated. #> Under-represented Quantile [1,9] - A total of 4 samples have been allocated. #> Under-represented Quantile [2,15] - A total of 2 samples have been allocated. #> Under-represented Quantile [2,8] - A total of 1 samples have been allocated. #> Under-represented Quantile [1,6] - A total of 3 samples have been allocated. #> Under-represented Quantile [2,18] - A total of 5 samples have been allocated. #> Under-represented Quantile [2,19] - A total of 7 samples have been allocated. #> Under-represented Quantile [2,3] - A total of 1 samples have been allocated. #> Under-represented Quantile [2,10] - A total of 1 samples have been allocated. #> Under-represented Quantile [3,12] - A total of 1 samples have been allocated. #> Under-represented Quantile [3,3] - A total of 2 samples have been allocated. #> Under-represented Quantile [2,1] - A total of 1 samples have been allocated. #> Under-represented Quantile [3,6] - A total of 6 samples have been allocated. #> Under-represented Quantile [3,11] - A total of 1 samples have been allocated. #> Under-represented Quantile [2,17] - A total of 4 samples have been allocated. #> Under-represented Quantile [2,12] - A total of 1 samples have been allocated. #> Under-represented Quantile [1,10] - A total of 4 samples have been allocated. #> Under-represented Quantile [2,13] - A total of 2 samples have been allocated. #> Under-represented Quantile [2,2] - A total of 1 samples have been allocated. #> Under-represented Quantile [3,8] - A total of 4 samples have been allocated. #> Under-represented Quantile [1,8] - A total of 4 samples have been allocated. #> Under-represented Quantile [2,16] - A total of 3 samples have been allocated. #> Under-represented Quantile [3,3] - A total of 2 samples have been allocated. #> Under-represented Quantile [3,5] - A total of 6 samples have been allocated. #> Under-represented Quantile [2,1] - A total of 1 samples have been allocated. #> Under-represented Quantile [2,3] - A total of 1 samples have been allocated. #> Under-represented Quantile [2,19] - A total of 8 samples have been allocated. #> Under-represented Quantile [2,8] - A total of 1 samples have been allocated. #> Under-represented Quantile [1,6] - A total of 3 samples have been allocated. #> Under-represented Quantile [3,11] - A total of 1 samples have been allocated. #> Under-represented Quantile [2,12] - A total of 2 samples have been allocated. #> Under-represented Quantile [2,15] - A total of 3 samples have been allocated. #> Under-represented Quantile [2,18] - A total of 6 samples have been allocated. #> Under-represented Quantile [2,14] - A total of 2 samples have been allocated. #> Under-represented Quantile [2,2] - A total of 1 samples have been allocated. #> Under-represented Quantile [2,9] - A total of 1 samples have been allocated. #> Under-represented Quantile [2,16] - A total of 3 samples have been allocated. #> Under-represented Quantile [2,7] - A total of 1 samples have been allocated. #> Under-represented Quantile [1,4] - A total of 3 samples have been allocated. #> Under-represented Quantile [2,1] - A total of 1 samples have been allocated. #> Under-represented Quantile [1,11] - A total of 4 samples have been allocated. #> Under-represented Quantile [3,4] - A total of 3 samples have been allocated. #> Under-represented Quantile [1,7] - A total of 3 samples have been allocated. #> Under-represented Quantile [1,12] - A total of 3 samples have been allocated. #> Under-represented Quantile [2,20] - A total of 4 samples have been allocated. #> Under-represented Quantile [2,10] - A total of 1 samples have been allocated. #> Under-represented Quantile [3,11] - A total of 1 samples have been allocated. #> Under-represented Quantile [2,11] - A total of 1 samples have been allocated. #> Under-represented Quantile [1,13] - A total of 2 samples have been allocated. #> Under-represented Quantile [2,13] - A total of 1 samples have been allocated. #> Under-represented Quantile [1,3] - A total of 2 samples have been allocated. #> Under-represented Quantile [2,19] - A total of 6 samples have been allocated. #> Under-represented Quantile [2,1] - A total of 1 samples have been allocated. #> Under-represented Quantile [1,8] - A total of 2 samples have been allocated. #> A total of 300 new samples added #> Writing layer `file5f005d6743f1' to data source  #>   `C:\\Users\\tgood.stu\\AppData\\Local\\Temp\\Rtmp2hCvHc\\file5f005d6743f1.shp' using driver `ESRI Shapefile' #> Writing 400 features with 4 fields and geometry type Point. #> Simple feature collection with 400 features and 4 fields #> Geometry type: POINT #> Dimension:     XY #> Bounding box:  xmin: 431110 ymin: 5337710 xmax: 438550 ymax: 5343230 #> CRS:           +proj=utm +zone=17 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs #> First 10 features: #>        type     zmean pzabove2  zsd               geometry #> 1  existing 11.490000     79.7 4.96 POINT (434970 5343030) #> 2  existing 10.679999     91.9 3.90 POINT (435590 5340510) #> 3  existing  5.640000     24.8 4.23 POINT (434290 5338670) #> 4  existing  7.490000     38.5 3.61 POINT (435170 5340410) #> 5  existing  9.170000     69.4 4.20 POINT (437550 5340650) #> 6  existing 11.059999     79.8 5.30 POINT (435850 5340130) #> 7  existing  9.240000     74.8 5.34 POINT (431630 5343230) #> 8  existing  9.420000     89.6 3.63 POINT (436510 5340870) #> 9  existing  9.059999     65.1 4.80 POINT (435990 5339950) #> 10 existing  8.170000     93.5 3.38 POINT (438250 5337770)"},{"path":"/reference/sample_balanced.html","id":null,"dir":"Reference","previous_headings":"","what":"Balanced sampling — sample_balanced","title":"Balanced sampling — sample_balanced","text":"Balanced raster sampling using lcube lpm2_kdtree methods","code":""},{"path":"/reference/sample_balanced.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Balanced sampling — sample_balanced","text":"","code":"sample_balanced(   mraster,   nSamp,   algorithm = \"lpm2_kdtree\",   p = NULL,   access = NULL,   buff_inner = NULL,   buff_outer = NULL,   plot = FALSE,   filename = NULL,   overwrite = FALSE )"},{"path":"/reference/sample_balanced.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Balanced sampling — sample_balanced","text":"mraster spatRaster. ALS metrics raster. nSamp Numeric. Number desired samples. algorithm Character. One lpm2_kdtree, lcube, lcubestratified p Numeric. Vector length equal number cells mraster representing inclusion probability candidate sample. Default = nSamp / N, N number cells. access sf. Road access network - must lines. buff_inner Numeric. Inner buffer boundary specifying distance access plots sampled. buff_outer Numeric. Outer buffer boundary specifying distance access plots can sampled. plot Logical. Plots output strata raster visualized strata boundary dividers. filename Character. Path write stratified raster disc. overwrite Logical. Specify whether filename overwritten disc.","code":""},{"path":"/reference/sample_balanced.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Balanced sampling — sample_balanced","text":"sf object nSamp randomly sampled points.","code":""},{"path":"/reference/sample_balanced.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Balanced sampling — sample_balanced","text":"Anton Grafstrom Jonathan Lisic (2019). BalancedSampling: Balanced Spatially Balanced Sampling. R package version 1.5.5. https://CRAN.R-project.org/package=BalancedSampling Jonathan Lisic Anton Grafstrom (2018). SamplingBigData: Sampling Methods Big Data. R package version 1.0.0. https://CRAN.R-project.org/package=SamplingBigData Grafström, . Lisic, J (2018). BalancedSampling: Balanced Spatially Balanced Sampling.  R package version 1.5.4. http://www.antongrafstrom.se/balancedsampling","code":""},{"path":[]},{"path":"/reference/sample_balanced.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Balanced sampling — sample_balanced","text":"Tristan R.H. Goodbody","code":""},{"path":"/reference/sample_balanced.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Balanced sampling — sample_balanced","text":"","code":"if (FALSE) { #--- Load raster and existing plots---# r <- system.file(\"extdata\", \"wall_metrics.tif\", package = \"sgsR\") mr <- terra::rast(r)  a <- system.file(\"extdata\", \"roads.shp\", package = \"sgsR\") ac <- sf::st_read(a)  sample_balanced(   mraster = mr,   nSamp = 200,   plot = TRUE )  sample_balanced(   mraster = mr,   nSamp = 100,   algorithm = \"lcube\",   access = ac,   buff_inner = 50,   buff_outer = 200 ) }"},{"path":"/reference/sample_clhs.html","id":null,"dir":"Reference","previous_headings":"","what":"Conditioned Latin Hypercube Sampling — sample_clhs","title":"Conditioned Latin Hypercube Sampling — sample_clhs","text":"Conditioned Latin Hypercube Sampling using clhs functionality.","code":""},{"path":"/reference/sample_clhs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Conditioned Latin Hypercube Sampling — sample_clhs","text":"","code":"sample_clhs(   mraster,   nSamp,   iter = 10000,   cost = NULL,   existing = NULL,   access = NULL,   buff_inner = NULL,   buff_outer = NULL,   plot = FALSE,   details = FALSE,   filename = NULL,   overwrite = FALSE,   ... )"},{"path":"/reference/sample_clhs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Conditioned Latin Hypercube Sampling — sample_clhs","text":"mraster spatRaster. ALS metrics raster. nSamp Numeric. Number desired samples. iter Numeric. Value giving number iterations within Metropolis-Hastings process. cost Numeric/Character. Index name covariate within mraster used constrain cLHS sampling. default - NULL cost constraint used. existing sf.  Existing plot network. access sf. Road access network - must lines. buff_inner Numeric. Inner buffer boundary specifying distance access plots sampled. buff_outer Numeric. Outer buffer boundary specifying distance access plots can sampled. plot Logical. Plots output strata raster samples. details Logical. FALSE (default) output  stratification raster. TRUE return list $details additional stratification information  $raster output stratification spatRaster.  @param ... Additional arguments passed kmeans function. filename Character. Path write output samples. overwrite Logical. Choice overwrite existing filename exists. ... Additional arguments clhs sampling. See clhs.","code":""},{"path":"/reference/sample_clhs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Conditioned Latin Hypercube Sampling — sample_clhs","text":"sf object nSamp stratified samples.","code":""},{"path":"/reference/sample_clhs.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Conditioned Latin Hypercube Sampling — sample_clhs","text":"Minasny, B. McBratney, .B. 2006. conditioned Latin hypercube method sampling presence ancillary information. Computers Geosciences, 32:1378-1388. Minasny, B. . B. McBratney, .B.. 2010. Conditioned Latin Hypercube Sampling Calibrating Soil Sensor Data Soil Properties. : Proximal Soil Sensing, Progress Soil Science, pages 111-119. Roudier, P., Beaudette, D.E. Hewitt, .E. 2012. conditioned Latin hypercube sampling algorithm incorporating operational constraints. : Digital Soil Assessments Beyond. Proceedings 5th Global Workshop Digital Soil Mapping, Sydney, Australia.","code":""},{"path":[]},{"path":"/reference/sample_clhs.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Conditioned Latin Hypercube Sampling — sample_clhs","text":"Tristan R.H. Goodbody","code":""},{"path":"/reference/sample_clhs.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Conditioned Latin Hypercube Sampling — sample_clhs","text":"","code":"#--- Load raster and existing plots---# r <- system.file(\"extdata\", \"wall_metrics.tif\", package = \"sgsR\") mr <- terra::rast(r)  e <- system.file(\"extdata\", \"existing.shp\", package = \"sgsR\") e <- sf::st_read(e) #> Reading layer `existing' from data source  #>   `C:\\Users\\tgood.stu\\Documents\\R\\win-library\\4.1\\sgsR\\extdata\\existing.shp'  #>   using driver `ESRI Shapefile' #> Simple feature collection with 100 features and 1 field #> Geometry type: POINT #> Dimension:     XY #> Bounding box:  xmin: 431110 ymin: 5337750 xmax: 438550 ymax: 5343230 #> CRS:           unknown  a <- system.file(\"extdata\", \"roads.shp\", package = \"sgsR\") ac <- sf::st_read(a) #> Reading layer `roads' from data source  #>   `C:\\Users\\tgood.stu\\Documents\\R\\win-library\\4.1\\sgsR\\extdata\\roads.shp'  #>   using driver `ESRI Shapefile' #> Simple feature collection with 167 features and 2 fields #> Geometry type: MULTILINESTRING #> Dimension:     XY #> Bounding box:  xmin: 431100 ymin: 5337700 xmax: 438560 ymax: 5343240 #> Projected CRS: UTM_Zone_17_Northern_Hemisphere  sample_clhs(   mraster = mr,   nSamp = 200,   plot = TRUE,   iter = 100 )  #> Simple feature collection with 200 features and 8 fields #> Geometry type: POINT #> Dimension:     XY #> Bounding box:  xmin: 431130 ymin: 5337710 xmax: 438530 ymax: 5343190 #> CRS:           +proj=utm +zone=17 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs #> First 10 features: #>       zmean pzabove2  zsd     zq20  zq50  zq70  zq90 type #> 40767  4.27     80.4 1.35 3.130000  4.27  4.95  6.66  new #> 83398  5.12     36.8 2.40 2.750000  4.84  6.37  9.30  new #> 36775 11.59     93.5 4.52 7.570000 11.23 13.82 20.10  new #> 33671  4.83     42.1 1.65 3.330000  4.93  5.80  7.40  new #> 90931 12.54     84.2 5.32 8.179999 12.03 15.05 22.20  new #> 46436  7.23     89.3 2.53 5.180000  7.28  8.65 11.10  new #> 71859 10.07     88.0 3.69 7.050000 10.44 11.99 15.50  new #> 59088  2.78     20.5 1.19 1.780000  2.51  3.11  5.10  new #> 1850   8.57     87.9 4.12 4.770000  8.27 10.50 16.40  new #> 64460  4.71     41.6 3.11 1.950000  3.76  5.74 10.90  new #>                     geometry #> 40767 POINT (431230 5340850) #> 83398 POINT (435030 5338130) #> 36775 POINT (438530 5341110) #> 33671 POINT (438090 5341290) #> 90931 POINT (433150 5337710) #> 46436 POINT (437990 5340530) #> 71859 POINT (433950 5338910) #> 59088 POINT (435950 5339770) #> 1850  POINT (438130 5343130) #> 64460 POINT (437390 5339450)  sample_clhs(   mraster = mr,   nSamp = 400,   existing = e,   iter = 250,   details = TRUE ) #> $clhs #>   [1] 75933 89032 86157  9782 33701 51520 70990 26425  7076 76754 68968 #>  [12] 14282  6921 51788 46543 58721 55477  3950 70672 81264 10821 74677 #>  [23] 91191 37693 38338 12617 62091  7137 66078 75350 36242 31496 58114 #>  [34] 77629  2993 16670   986 39590 23001 51177 65078 37241 80112 87882 #>  [45] 90048 48187 36693 58738 52045 22476 73643 89384 63290 47723 54878 #>  [56] 60030 61244 68542 40979 23123 23085 82394 33860 68317 35849 87849 #>  [67] 63296  5251 55044 85155 21481  9202 12921 89254 27289 43635 35263 #>  [78] 30461 29896 23972 80970 37154 43236 55452 32679  1713 39748  1429 #>  [89]  8889 44958 11281  6135 21580 34507 24844 22549 50764 48231 13676 #> [100] 28223 76018  4202 45338 20424 29245 49835 51265  6288 15456 11796 #> [111] 58164 28455 75746 38018 54483 68087 18022 40791 56257 17503  2075 #> [122]  4809 78975 85863 50282 65599 33035 32294 45876 45032 73188 34015 #> [133] 80412  7262 31522 25465 28087 43990 79711 20200 51478 70609 71624 #> [144] 71163 72460 83347 29625  4005 70335 13566  9918 60825 86089 53026 #> [155] 54200 41205 37861 30156 49182 84217 62526 73613 78117 16092 76967 #> [166] 66753 84277 43621 25769 76779 36334 28054 53397 20774 12712 27616 #> [177] 52442 67411 42655 65558 14155  3338 22147 59104 77973 82811 66116 #> [188] 13857 76704 85535 74287 37157 18941 19893 68938 13226 73970 19833 #> [199] 37180 38372 49591 59839 14390 48271 88026 89243 69661 13347 73512 #> [210] 60922  7913 41181 73325 20768 61258 52914 61086 90277 29402 56663 #> [221] 67567 44286  8860 69886 75616 82072 71464  6035 30851 67612 48103 #> [232] 12483 27522 15041 78835 40038 60377 14397 68129 90792  3160  5575 #> [243] 54750   868 76309 46266 89149 34185 76409 11446 20543 87584 48090 #> [254] 30546  9085 17889 49658 21041 35488 51973 21027 43701 57449 33444 #> [265] 43090  2090 70207 74011 89121 33066 72940 10913 23657 57056 88150 #> [276] 57436 28815 51342 85384  7009 36040 58493 80128 83182 30806 81146 #> [287] 77212 12147 54450 45999 40886  4467 65639 19180 45980 50857 43317 #> [298] 57238 17046 34144 24300 10400 77186 65769  3341 26464 19725 37833 #> [309] 46556 47391 71971 22633 25549 62860 66493 30662 20092 61735 16619 #> [320] 40096  9541 42192  2025 82206 34604 39576 33349 23900 57782 20886 #> [331] 82420 64802 50178 81999 16537 71974 69351 72182 58342 20685 73455 #> [342] 64149 80821  8720 18415 41091 47933 11400 21201 53926 59847 14660 #> [353] 22036 66838 69974 56208  9418 68316 80010 11979 64572 80421 64151 #> [364]  1073 47150 29064 26574 50813 51008 61075 69827  2579 81825 85032 #> [375] 61557 19650 65371 29438 57032 55838 84328 21352 90306 55671 38414 #> [386] 39862 79361 64011 50154 39374   699 60901 89408  8160 90859 89879 #> [397] 21822 22137  8902 45258 #>  #> $samples #> Simple feature collection with 400 features and 8 fields #> Geometry type: POINT #> Dimension:     XY #> Bounding box:  xmin: 431110 ymin: 5337710 xmax: 438550 ymax: 5343210 #> CRS:           +proj=utm +zone=17 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs #> First 10 features: #>       zmean pzabove2  zsd  zq20  zq50  zq70  zq90 type #> 75833  4.50     15.6 2.59  1.86  4.09  5.83  9.27  new #> 88932  7.91     90.8 3.64  4.54  7.64  9.80 14.10  new #> 86057  5.19     97.2 1.33  4.22  5.10  5.73  7.48  new #> 9682  15.21     97.8 2.30 13.59 15.22 16.28 18.60  new #> 33601 12.50     80.4 6.18  7.20 12.22 14.63 23.40  new #> 51420 16.08     92.8 6.01  8.78 18.70 20.09 22.20  new #> 70890  6.75     58.4 3.29  3.25  7.04  8.96 11.80  new #> 26325  6.09     78.0 3.80  2.45  5.22  7.93 13.20  new #> 6976   5.92     67.5 2.67  3.55  5.75  7.07 10.80  new #> 76654 16.71     90.1 5.72 12.43 19.05 20.22 21.90  new #>                     geometry #> 75833 POINT (435390 5338590) #> 88932 POINT (436250 5337830) #> 86057 POINT (436590 5337990) #> 9682  POINT (437330 5342670) #> 33601 POINT (436630 5341290) #> 51420 POINT (435790 5340230) #> 70890 POINT (433970 5338990) #> 26325 POINT (436730 5341710) #> 6976  POINT (432750 5342810) #> 76654 POINT (434190 5338530) #>   sample_clhs(   mraster = mr,   nSamp = 200,   iter = 200,   existing = e,   access = ac,   buff_inner = 100,   buff_outer = 300,   plot = TRUE ) #> An access layer has been provided. An internal buffer of 100 m and an external buffer of 300 m have been applied  #> Simple feature collection with 200 features and 8 fields #> Geometry type: POINT #> Dimension:     XY #> Bounding box:  xmin: 431130 ymin: 5337730 xmax: 438510 ymax: 5343150 #> CRS:           +proj=utm +zone=17 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs #> First 10 features: #>       zmean pzabove2  zsd      zq20      zq50      zq70  zq90 type #> 13986  6.36     75.4 3.07  3.440000  6.120000  7.920000 11.70  new #> 24484 17.86     90.6 5.75 14.170000 18.719999 22.150000 24.20  new #> 36699  8.27     95.1 2.89  5.950000  8.309999  9.700000 13.10  new #> 34144  4.44     74.7 2.02  2.560000  4.140000  5.370000  8.32  new #> 14069 10.46     86.7 4.25  7.270000 10.750000 12.700000 17.20  new #> 34700  6.11     81.7 2.93  3.680000  5.650000  6.890000 12.50  new #> 20590  8.02     89.8 3.52  5.140000  7.880000  9.429999 15.10  new #> 32686 13.97     98.5 5.17  8.929999 14.509999 17.389999 21.20  new #> 22635  9.25     96.6 3.37  6.590000  8.970000 10.820000 15.00  new #> 33391 16.63     93.8 5.79 14.980000 18.740000 19.900000 21.50  new #>                     geometry #> 13986 POINT (432130 5341410) #> 24484 POINT (436450 5340010) #> 36699 POINT (432070 5338070) #> 34144 POINT (437210 5338450) #> 14069 POINT (434990 5341410) #> 34700 POINT (436890 5338370) #> 20590 POINT (434870 5340530) #> 32686 POINT (435030 5338630) #> 22635 POINT (435630 5340290) #> 33391 POINT (431950 5338530)  #--- cost constrained examples ---# #--- calculate distance to access layer for each pixel in mr ---# mr.c <- calculate_distance(   raster = mr,   access = ac ) #> calculating per pixel distance to provided access layer  sample_clhs(   mraster = mr.c,   nSamp = 250,   iter = 200,   cost = \"dist2access\",   plot = TRUE )  #> Simple feature collection with 250 features and 9 fields #> Geometry type: POINT #> Dimension:     XY #> Bounding box:  xmin: 431110 ymin: 5337730 xmax: 438530 ymax: 5343230 #> CRS:           +proj=utm +zone=17 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs #> First 10 features: #>       zmean pzabove2  zsd zq20  zq50      zq70  zq90 dist2access type #> 14317  5.38     49.5 2.34 3.10  5.40  6.740000  9.22  467.547127  new #> 71499  1.65      0.4 0.30 1.39  1.56  1.770000  2.23    2.809495  new #> 15859  7.67     67.6 4.12 4.03  7.15  9.309999 15.30   61.424007  new #> 80060  9.51     81.9 5.89 2.80 11.11 14.530000 17.30  462.862135  new #> 89546  6.82     74.8 2.50 4.57  6.96  8.290000 10.70  162.668457  new #> 10712  7.38     86.1 3.28 4.12  7.53  9.480000 12.50  335.001817  new #> 79706  1.98      5.4 0.62 1.46  1.79  2.210000  2.98    5.055236  new #> 52779 13.45     61.6 6.67 4.47 16.88 18.150000 19.60   18.733164  new #> 80424 12.88     92.1 6.05 7.01 14.53 17.230000 20.70   81.895134  new #> 89830  9.33     85.7 3.57 6.45  9.55 11.170000 15.10  722.719196  new #>                     geometry #> 14317 POINT (438390 5342390) #> 71499 POINT (437850 5338950) #> 15859 POINT (433170 5342290) #> 80060 POINT (431350 5338310) #> 89546 POINT (434310 5337790) #> 10712 POINT (438150 5342610) #> 79706 POINT (438270 5338350) #> 52779 POINT (435450 5340150) #> 80424 POINT (431930 5338290) #> 89830 POINT (432650 5337770)  sample_clhs(   mraster = mr.c,   nSamp = 250,   existing = e,   iter = 200,   cost = \"dist2access\",   plot = TRUE )  #> Simple feature collection with 250 features and 9 fields #> Geometry type: POINT #> Dimension:     XY #> Bounding box:  xmin: 431150 ymin: 5337770 xmax: 438510 ymax: 5343210 #> CRS:           +proj=utm +zone=17 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs #> First 10 features: #>           zmean pzabove2  zsd  zq20      zq50  zq70  zq90 dist2access #> 85627 12.700000     90.4 6.13  5.91 13.679999 17.23 20.90   15.830653 #> 41659 12.900000     91.0 3.44 10.95 13.650000 14.82 17.00  771.538601 #> 18690 10.570000     88.1 5.07  5.26 11.210000 14.06 18.20  495.216004 #> 73237 10.480000     90.0 3.53  8.22 10.860000 12.45 15.30  132.026190 #> 565    4.530000     38.6 2.26  2.66  4.110000  5.22  8.79    6.064777 #> 53797 14.380000     92.3 4.45 10.66 15.259999 17.43 20.00   16.178613 #> 88731 13.290000     91.7 5.13  9.12 14.420000 16.87 19.60   78.705477 #> 54127  8.559999     91.6 3.36  5.67  8.599999 10.46 13.90  250.980630 #> 55258  8.050000     76.3 4.56  4.19  7.150000  9.59 17.80  753.964209 #> 74529 15.599999     93.6 3.83 13.07 16.590000 17.96 20.00  147.757456 #>       type               geometry #> 85627  new POINT (435310 5338010) #> 41659  new POINT (437110 5340810) #> 18690  new POINT (431530 5342130) #> 73237  new POINT (432470 5338790) #> 565    new POINT (436030 5343210) #> 53797  new POINT (435290 5340090) #> 88731  new POINT (431970 5337830) #> 54127  new POINT (434910 5340070) #> 55258  new POINT (437030 5340010) #> 74529  new POINT (434670 5338690)"},{"path":"/reference/sample_srs.html","id":null,"dir":"Reference","previous_headings":"","what":"Simple random sampling — sample_srs","title":"Simple random sampling — sample_srs","text":"Randomly sample within stratification raster extent.","code":""},{"path":"/reference/sample_srs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simple random sampling — sample_srs","text":"","code":"sample_srs(   raster,   nSamp,   mindist = NULL,   access = NULL,   buff_inner = NULL,   buff_outer = NULL,   plot = FALSE,   filename = NULL,   overwrite = FALSE )"},{"path":"/reference/sample_srs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Simple random sampling — sample_srs","text":"raster spatRaster. Raster used random sampling. nSamp Numeric. Number desired samples. mindist Numeric. Minimum allowable distance selected samples. Default = NULL. access sf. Road access network - must lines. buff_inner Numeric. Inner buffer boundary specifying distance access plots sampled. buff_outer Numeric. Outer buffer boundary specifying distance access plots can sampled. plot Logical. Plots output strata raster samples. filename Character. Path write output samples. overwrite Logical. Choice overwrite existing filename exists.","code":""},{"path":"/reference/sample_srs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Simple random sampling — sample_srs","text":"sf object nSamp randomly sampled points.","code":""},{"path":[]},{"path":"/reference/sample_srs.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Simple random sampling — sample_srs","text":"Tristan R.H. Goodbody & Martin Queinnec","code":""},{"path":"/reference/sample_srs.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Simple random sampling — sample_srs","text":"","code":"#--- Load raster and access files ---# r <- system.file(\"extdata\", \"kmeans.tif\", package = \"sgsR\") sr <- terra::rast(r)  a <- system.file(\"extdata\", \"roads.shp\", package = \"sgsR\") ac <- sf::st_read(a) #> Reading layer `roads' from data source  #>   `C:\\Users\\tgood.stu\\Documents\\R\\win-library\\4.1\\sgsR\\extdata\\roads.shp'  #>   using driver `ESRI Shapefile' #> Simple feature collection with 167 features and 2 fields #> Geometry type: MULTILINESTRING #> Dimension:     XY #> Bounding box:  xmin: 431100 ymin: 5337700 xmax: 438560 ymax: 5343240 #> Projected CRS: UTM_Zone_17_Northern_Hemisphere  #--- perform simple random sampling ---# sample_srs(   raster = sr,   nSamp = 200,   plot = TRUE )  #> Simple feature collection with 200 features and 0 fields #> Geometry type: POINT #> Dimension:     XY #> Bounding box:  xmin: 431130 ymin: 5337750 xmax: 438550 ymax: 5343230 #> CRS:           +proj=utm +zone=17 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs #> First 10 features: #>                  geometry #> 1  POINT (436230 5341890) #> 2  POINT (436230 5341890) #> 3  POINT (431230 5340910) #> 4  POINT (438010 5341550) #> 5  POINT (431430 5341330) #> 6  POINT (435930 5337830) #> 7  POINT (438410 5342830) #> 8  POINT (432550 5342330) #> 9  POINT (437130 5341150) #> 10 POINT (431930 5340550)  sample_srs(   raster = sr,   nSamp = 200,   access = ac,   mindist = 200,   buff_inner = 50,   buff_outer = 200 ) #> An access layer has been provided. An internal buffer of 50 m and an external buffer of 200 m have been applied #> Registered S3 method overwritten by 'spatstat.geom': #>   method     from #>   print.boxx cli  #> Simple feature collection with 200 features and 0 fields #> Geometry type: POINT #> Dimension:     XY #> Bounding box:  xmin: 431210 ymin: 5337710 xmax: 438550 ymax: 5343230 #> CRS:           +proj=utm +zone=17 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs #> First 10 features: #>                  geometry #> 1  POINT (432510 5341030) #> 2  POINT (434270 5341830) #> 3  POINT (431970 5342590) #> 4  POINT (433690 5342750) #> 5  POINT (435170 5339290) #> 6  POINT (432270 5342070) #> 7  POINT (435850 5342950) #> 8  POINT (432170 5341290) #> 9  POINT (438010 5338690) #> 10 POINT (434870 5342910)  sample_srs(   raster = sr,   nSamp = 200,   access = ac,   buff_inner = 50,   buff_outer = 200,   filename = tempfile(fileext = \".shp\") ) #> An access layer has been provided. An internal buffer of 50 m and an external buffer of 200 m have been applied #> Writing layer `file55ec56affdc' to data source  #>   `C:\\Users\\tgood.stu\\AppData\\Local\\Temp\\RtmpMPmhqB\\file55ec56affdc.shp' using driver `ESRI Shapefile' #> Writing 200 features with 0 fields and geometry type Point. #> Simple feature collection with 200 features and 0 fields #> Geometry type: POINT #> Dimension:     XY #> Bounding box:  xmin: 431170 ymin: 5337750 xmax: 438550 ymax: 5343210 #> CRS:           +proj=utm +zone=17 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs #> First 10 features: #>                  geometry #> 1  POINT (433890 5343210) #> 2  POINT (433890 5343210) #> 3  POINT (437010 5337890) #> 4  POINT (437910 5342470) #> 5  POINT (434290 5338230) #> 6  POINT (432970 5339150) #> 7  POINT (438170 5339330) #> 8  POINT (434630 5342970) #> 9  POINT (436430 5340290) #> 10 POINT (438050 5340310)"},{"path":"/reference/sample_strat.html","id":null,"dir":"Reference","previous_headings":"","what":"Stratified sampling — sample_strat","title":"Stratified sampling — sample_strat","text":"Sampling based stratified raster.","code":""},{"path":"/reference/sample_strat.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Stratified sampling — sample_strat","text":"","code":"sample_strat(   sraster,   nSamp,   allocation = \"prop\",   force = FALSE,   mraster = NULL,   mindist = NULL,   existing = NULL,   include = FALSE,   remove = FALSE,   access = NULL,   buff_inner = NULL,   buff_outer = NULL,   wrow = 3,   wcol = 3,   plot = FALSE,   details = FALSE,   filename = NULL,   overwrite = FALSE )"},{"path":"/reference/sample_strat.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Stratified sampling — sample_strat","text":"sraster spatRaster. Stratification raster used sampling. nSamp Numeric. Number desired samples. existing include force influence value. allocation Character. Allocation algorithm used. Either prop (default) proportional allocation optim optimal allocation (equal sampling cost) equal equal number samples (defined nSamp)  strata. force Logical. Default = FALSE - force nSamp exactly user defined value cases nSamp sraster strata count equally divisible. Additional samples often need allocated removed based rounding differences resulting proportional differences nSamp strata coverages sraster. instances samples either added strata lowest number samples removed strata highest number samples. effect existing provided. mraster spatRaster. ALS metric raster. Required allocation = optim. mindist Numeric. Minimum allowable distance selected samples. Default = NULL. existing sf data.frame.  Existing plot network. include Logical. TRUE include existing plots nSamp total. remove Logical. TRUE randomly remove samples represented strata meet allocated sample numbers. Used existing include TRUE. access sf. Road access network - must lines. buff_inner Numeric. Inner buffer boundary specifying distance access plots sampled. buff_outer Numeric. Outer buffer boundary specifying distance access plots can sampled. wrow Numeric. Number row focal window (default 3). wcol Numeric. Number columns focal window (default 3). plot Logical. Plots existing (circles) new (crosses) samples. details Logical. FALSE (default) output sf object stratified samples. TRUE return list $details additional sampling information $raster sf object stratified samples. filename Character. Path write output samples. overwrite Logical. Choice overwrite existing filename exists.","code":""},{"path":"/reference/sample_strat.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Stratified sampling — sample_strat","text":"sf object nSamp stratified samples.","code":""},{"path":"/reference/sample_strat.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Stratified sampling — sample_strat","text":"sampling performed 2 stages: Rule 1 - Sample within grouped stratum pixels defined within wrow, wcol parameters Rule 2 - samples exist satisfy Rule 1  individual stratum pixels sampled. rule applied allocate sample defined rule attribute output samples.","code":""},{"path":"/reference/sample_strat.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Stratified sampling — sample_strat","text":"Queinnec, M., White, J. C., & Coops, N. C. (2021). Comparing airborne spaceborne photon-counting LiDAR canopy structural estimates across different boreal forest types. Remote Sensing Environment, 262 (August 2020), 112510. https://doi.org/10.1016/j.rse.2021.112510","code":""},{"path":[]},{"path":"/reference/sample_strat.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Stratified sampling — sample_strat","text":"Tristan R.H. Goodbody & Martin Queinnec","code":""},{"path":"/reference/sample_strat.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Stratified sampling — sample_strat","text":"","code":"#--- Load raster and access files ---# r <- system.file(\"extdata\", \"kmeans.tif\", package = \"sgsR\") sr <- terra::rast(r)  a <- system.file(\"extdata\", \"roads.shp\", package = \"sgsR\") ac <- sf::st_read(a) #> Reading layer `roads' from data source  #>   `C:\\Users\\tgood.stu\\Documents\\R\\win-library\\4.1\\sgsR\\extdata\\roads.shp'  #>   using driver `ESRI Shapefile' #> Simple feature collection with 167 features and 2 fields #> Geometry type: MULTILINESTRING #> Dimension:     XY #> Bounding box:  xmin: 431100 ymin: 5337700 xmax: 438560 ymax: 5343240 #> Projected CRS: UTM_Zone_17_Northern_Hemisphere  e <- system.file(\"extdata\", \"existing.shp\", package = \"sgsR\") e <- sf::st_read(e) #> Reading layer `existing' from data source  #>   `C:\\Users\\tgood.stu\\Documents\\R\\win-library\\4.1\\sgsR\\extdata\\existing.shp'  #>   using driver `ESRI Shapefile' #> Simple feature collection with 100 features and 1 field #> Geometry type: POINT #> Dimension:     XY #> Bounding box:  xmin: 431110 ymin: 5337750 xmax: 438550 ymax: 5343230 #> CRS:           unknown  #--- perform stratified sampling random sampling ---# sample_strat(   sraster = sr,   nSamp = 200,   plot = TRUE ) #> Implementing porportional allocation of samples #> nSamp of 200 is not perfectly divisible based on strata distribution. nSamp of 205 will be returned. Use \"force = TRUE\" to brute force to 200. #> Processing strata : 1 #> Processing strata : 2 #> Processing strata : 3 #> Processing strata : 4 #> Processing strata : 5 #> Processing strata : 6 #> Processing strata : 7 #> Processing strata : 8 #> Processing strata : 9 #> Processing strata : 10  #> Simple feature collection with 205 features and 3 fields #> Geometry type: POINT #> Dimension:     XY #> Bounding box:  xmin: 431190 ymin: 5337750 xmax: 438510 ymax: 5343210 #> CRS:           +proj=utm +zone=17 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs #> First 10 features: #>    strata type  rule               geometry #> x       1  new rule1 POINT (433470 5338930) #> x1      1  new rule1 POINT (438110 5341850) #> x2      1  new rule1 POINT (431310 5342670) #> x3      1  new rule1 POINT (438490 5340850) #> x4      1  new rule1 POINT (433190 5338770) #> x5      1  new rule1 POINT (437350 5340130) #> x6      1  new rule1 POINT (432770 5338430) #> x7      1  new rule1 POINT (433450 5338950) #> x8      1  new rule1 POINT (438090 5341850) #> x9      1  new rule1 POINT (432750 5338350)  #--- perform stratified sampling random sampling ---# sample_strat(   sraster = sr,   nSamp = 200,   plot = TRUE,   force = TRUE ) #> Implementing porportional allocation of samples #> Forcing 200 total samples. #> Processing strata : 1 #> Processing strata : 2 #> Processing strata : 3 #> Processing strata : 4 #> Processing strata : 5 #> Processing strata : 6 #> Processing strata : 7 #> Processing strata : 8 #> Processing strata : 9 #> Processing strata : 10  #> Simple feature collection with 200 features and 3 fields #> Geometry type: POINT #> Dimension:     XY #> Bounding box:  xmin: 431150 ymin: 5337730 xmax: 438530 ymax: 5343070 #> CRS:           +proj=utm +zone=17 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs #> First 10 features: #>    strata type  rule               geometry #> x       1  new rule1 POINT (438490 5340850) #> x1      1  new rule1 POINT (438370 5340830) #> x2      1  new rule1 POINT (438110 5341850) #> x3      1  new rule1 POINT (431290 5342650) #> x4      1  new rule1 POINT (438390 5340830) #> x5      1  new rule1 POINT (433290 5338050) #> x6      1  new rule1 POINT (433290 5338070) #> x7      1  new rule1 POINT (433470 5338930) #> x8      1  new rule1 POINT (437090 5340190) #> x9      1  new rule1 POINT (437350 5340130)  #--- extract strata values to existing samples ---# e.sr <- extract_strata(sraster = sr, existing = e)  sample_strat(   sraster = sr,   nSamp = 200,   access = ac,   existing = e.sr,   mindist = 200,   buff_inner = 50,   buff_outer = 200 ) #> Registered S3 method overwritten by 'spatstat.geom': #>   method     from #>   print.boxx cli  #> Implementing porportional allocation of samples #> nSamp of 200 is not perfectly divisible based on strata distribution. nSamp of 205 will be returned. Use \"force = TRUE\" to brute force to 200. #> An access layer has been provided. An internal buffer of 50 m and an external buffer of 200 m have been applied #> Processing strata : 1 #> Buffered area contains 2273 available candidates. Sampling to reach 14 samples starting. #> Processing strata : 2 #> Buffered area contains 6190 available candidates. Sampling to reach 29 samples starting. #> Processing strata : 3 #> Buffered area contains 2213 available candidates. Sampling to reach 15 samples starting. #> Processing strata : 4 #> Buffered area contains 3230 available candidates. Sampling to reach 21 samples starting. #> Processing strata : 5 #> Buffered area contains 4430 available candidates. Sampling to reach 26 samples starting. #> Processing strata : 6 #> Buffered area contains 4338 available candidates. Sampling to reach 25 samples starting. #> Processing strata : 7 #> Buffered area contains 3774 available candidates. Sampling to reach 24 samples starting. #> Processing strata : 8 #> Buffered area contains 4061 available candidates. Sampling to reach 17 samples starting. #> Processing strata : 9 #> Buffered area contains 6063 available candidates. Sampling to reach 23 samples starting. #> Processing strata : 10 #> Buffered area contains 1666 available candidates. Sampling to reach 11 samples starting. #> Simple feature collection with 305 features and 3 fields #> Geometry type: POINT #> Dimension:     XY #> Bounding box:  xmin: 431110 ymin: 5337730 xmax: 438550 ymax: 5343230 #> CRS:           +proj=utm +zone=17 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs #> First 10 features: #>    strata     type     rule               geometry #> 36      1 existing existing POINT (431930 5338510) #> 41      1 existing existing POINT (433990 5341870) #> x       1      new    rule1 POINT (431290 5342670) #> x1      1      new    rule1 POINT (438110 5341850) #> x2      1      new    rule1 POINT (438490 5340850) #> x3      1      new    rule2 POINT (432930 5339730) #> x4      1      new    rule2 POINT (436770 5343030) #> x5      1      new    rule2 POINT (432150 5341770) #> x6      1      new    rule2 POINT (437410 5342870) #> x7      1      new    rule2 POINT (435230 5338890)  sample_strat(   sraster = sr,   nSamp = 200,   access = ac,   buff_inner = 50,   buff_outer = 200,   filename = tempfile(fileext = \".shp\") ) #> Implementing porportional allocation of samples #> nSamp of 200 is not perfectly divisible based on strata distribution. nSamp of 205 will be returned. Use \"force = TRUE\" to brute force to 200. #> An access layer has been provided. An internal buffer of 50 m and an external buffer of 200 m have been applied #> Processing strata : 1 #> Buffered area contains 2273 available candidates. Sampling to reach 14 samples starting. #> Processing strata : 2 #> Buffered area contains 6190 available candidates. Sampling to reach 29 samples starting. #> Processing strata : 3 #> Buffered area contains 2213 available candidates. Sampling to reach 15 samples starting. #> Processing strata : 4 #> Buffered area contains 3230 available candidates. Sampling to reach 21 samples starting. #> Processing strata : 5 #> Buffered area contains 4430 available candidates. Sampling to reach 26 samples starting. #> Processing strata : 6 #> Buffered area contains 4338 available candidates. Sampling to reach 25 samples starting. #> Processing strata : 7 #> Buffered area contains 3774 available candidates. Sampling to reach 24 samples starting. #> Processing strata : 8 #> Buffered area contains 4061 available candidates. Sampling to reach 17 samples starting. #> Processing strata : 9 #> Buffered area contains 6063 available candidates. Sampling to reach 23 samples starting. #> Processing strata : 10 #> Buffered area contains 1666 available candidates. Sampling to reach 11 samples starting. #> Writing layer `file5f00251a2541' to data source  #>   `C:\\Users\\tgood.stu\\AppData\\Local\\Temp\\Rtmp2hCvHc\\file5f00251a2541.shp' using driver `ESRI Shapefile' #> Writing 205 features with 3 fields and geometry type Point. #> Simple feature collection with 205 features and 3 fields #> Geometry type: POINT #> Dimension:     XY #> Bounding box:  xmin: 431290 ymin: 5337730 xmax: 438510 ymax: 5343210 #> CRS:           +proj=utm +zone=17 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs #> First 10 features: #>    strata type  rule               geometry #> x       1  new rule1 POINT (431290 5342670) #> x1      1  new rule1 POINT (438390 5340830) #> x2      1  new rule1 POINT (438110 5341850) #> x3      1  new rule1 POINT (438370 5340830) #> x4      1  new rule1 POINT (438490 5340850) #> x5      1  new rule1 POINT (438090 5341850) #> x6      1  new rule1 POINT (431310 5342670) #> x7      1  new rule2 POINT (433070 5342970) #> x8      1  new rule2 POINT (432870 5339430) #> x9      1  new rule2 POINT (435170 5338450)  #--- Load mraster for optimal allocation ---# mr <- system.file(\"extdata\", \"wall_metrics.tif\", package = \"sgsR\") mr <- terra::rast(mr)  sample_strat(   sraster = sr,   nSamp = 200,   allocation = \"optim\",   mraster = mr$zq90,   access = ac,   buff_inner = 50,   buff_outer = 200,   filename = tempfile(fileext = \".shp\") ) #> Implementing optimal allocation of samples based on variability of 'zq90' #> nSamp of 200 is not perfectly divisible based on strata distribution. nSamp of 206 will be returned. Use \"force = TRUE\" to brute force to 200. #> An access layer has been provided. An internal buffer of 50 m and an external buffer of 200 m have been applied #> Processing strata : 1 #> Buffered area contains 2273 available candidates. Sampling to reach 17 samples starting. #> Processing strata : 2 #> Buffered area contains 6190 available candidates. Sampling to reach 32 samples starting. #> Processing strata : 3 #> Buffered area contains 2213 available candidates. Sampling to reach 15 samples starting. #> Processing strata : 4 #> Buffered area contains 3230 available candidates. Sampling to reach 18 samples starting. #> Processing strata : 5 #> Buffered area contains 4430 available candidates. Sampling to reach 20 samples starting. #> Processing strata : 6 #> Buffered area contains 4338 available candidates. Sampling to reach 21 samples starting. #> Processing strata : 7 #> Buffered area contains 3774 available candidates. Sampling to reach 24 samples starting. #> Processing strata : 8 #> Buffered area contains 4061 available candidates. Sampling to reach 24 samples starting. #> Processing strata : 9 #> Buffered area contains 6063 available candidates. Sampling to reach 22 samples starting. #> Processing strata : 10 #> Buffered area contains 1666 available candidates. Sampling to reach 13 samples starting. #> Writing layer `file5f004202732f' to data source  #>   `C:\\Users\\tgood.stu\\AppData\\Local\\Temp\\Rtmp2hCvHc\\file5f004202732f.shp' using driver `ESRI Shapefile' #> Writing 206 features with 3 fields and geometry type Point. #> Simple feature collection with 206 features and 3 fields #> Geometry type: POINT #> Dimension:     XY #> Bounding box:  xmin: 431170 ymin: 5337710 xmax: 438530 ymax: 5343210 #> CRS:           +proj=utm +zone=17 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs #> First 10 features: #>    strata type  rule               geometry #> x       1  new rule1 POINT (438390 5340830) #> x1      1  new rule1 POINT (438490 5340850) #> x2      1  new rule1 POINT (431290 5342670) #> x3      1  new rule1 POINT (431310 5342670) #> x4      1  new rule1 POINT (438370 5340830) #> x5      1  new rule1 POINT (438090 5341850) #> x6      1  new rule1 POINT (438110 5341850) #> x7      1  new rule2 POINT (433310 5342670) #> x8      1  new rule2 POINT (434210 5339430) #> x9      1  new rule2 POINT (431990 5340610)"},{"path":"/reference/sample_systematic.html","id":null,"dir":"Reference","previous_headings":"","what":"Systematic sampling — sample_systematic","title":"Systematic sampling — sample_systematic","text":"Systematic sampling within square hexagonal tessellation.","code":""},{"path":"/reference/sample_systematic.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Systematic sampling — sample_systematic","text":"","code":"sample_systematic(   raster,   cellsize,   square = TRUE,   location = \"centers\",   access = NULL,   buff_inner = NULL,   buff_outer = NULL,   plot = FALSE,   filename = NULL,   overwrite = FALSE,   details = FALSE,   ... )"},{"path":"/reference/sample_systematic.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Systematic sampling — sample_systematic","text":"raster spatRaster. Raster used define extent fishnet grid. cellsize Numeric. Desired cellsize tessellation. square Logical. Tessellation shape. Default regular square grid, FALSE hexagons returned. location Character. Sample location within tessellation. Default (\"centers\") returns samples tessellation centers, \"corners\" - corners returned, \"random\" - samples randomly located within tessellations. access sf. Road access network - must lines. buff_inner Numeric. Inner buffer boundary specifying distance access plots sampled. buff_outer Numeric. Outer buffer boundary specifying distance access plots can sampled. plot Logical. Plots output strata raster samples. filename Character. Path write output samples. overwrite Logical. Choice overwrite existing filename exists. details Logical. FALSE (default) output sf object systematic samples. TRUE returns list sf objects tessellation tessellation grid sampling, samples systematic samples. ... Additional arguments st_make_grid.","code":""},{"path":"/reference/sample_systematic.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Systematic sampling — sample_systematic","text":"sf object sampled points tessellation.","code":""},{"path":[]},{"path":"/reference/sample_systematic.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Systematic sampling — sample_systematic","text":"Tristan R.H. Goodbody","code":""},{"path":"/reference/sample_systematic.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Systematic sampling — sample_systematic","text":"","code":"#--- Load raster and access files ---# r <- system.file(\"extdata\", \"kmeans.tif\", package = \"sgsR\") sr <- terra::rast(r)  a <- system.file(\"extdata\", \"roads.shp\", package = \"sgsR\") ac <- sf::st_read(a) #> Reading layer `roads' from data source  #>   `C:\\Users\\tgood.stu\\Documents\\R\\win-library\\4.1\\sgsR\\extdata\\roads.shp'  #>   using driver `ESRI Shapefile' #> Simple feature collection with 167 features and 2 fields #> Geometry type: MULTILINESTRING #> Dimension:     XY #> Bounding box:  xmin: 431100 ymin: 5337700 xmax: 438560 ymax: 5343240 #> Projected CRS: UTM_Zone_17_Northern_Hemisphere  e <- system.file(\"extdata\", \"existing.shp\", package = \"sgsR\") e <- sf::st_read(e) #> Reading layer `existing' from data source  #>   `C:\\Users\\tgood.stu\\Documents\\R\\win-library\\4.1\\sgsR\\extdata\\existing.shp'  #>   using driver `ESRI Shapefile' #> Simple feature collection with 100 features and 1 field #> Geometry type: POINT #> Dimension:     XY #> Bounding box:  xmin: 431110 ymin: 5337750 xmax: 438550 ymax: 5343230 #> CRS:           unknown  #--- perform grid sampling ---# sample_systematic(   raster = sr,   cellsize = 1000,   plot = TRUE )  #> Simple feature collection with 40 features and 0 fields #> Geometry type: POINT #> Dimension:     XY #> Bounding box:  xmin: 431600 ymin: 5338200 xmax: 437600 ymax: 5343200 #> CRS:           +proj=utm +zone=17 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs #> First 10 features: #>                  geometry #> 1  POINT (431600 5338200) #> 2  POINT (432600 5338200) #> 3  POINT (433600 5338200) #> 4  POINT (434600 5338200) #> 5  POINT (435600 5338200) #> 6  POINT (436600 5338200) #> 7  POINT (437600 5338200) #> 8  POINT (432600 5339200) #> 9  POINT (433600 5339200) #> 10 POINT (434600 5339200)  sample_systematic(   raster = sr,   cellsize = 1000,   square = FALSE,   location = \"corners\",   plot = TRUE )  #> Simple feature collection with 312 features and 0 fields #> Geometry type: POINT #> Dimension:     XY #> Bounding box:  xmin: 431100 ymin: 5337989 xmax: 438100 ymax: 5343185 #> CRS:           +proj=utm +zone=17 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs #> First 10 features: #>                  geometry #> 1  POINT (431100 5338855) #> 2  POINT (431100 5338277) #> 3  POINT (431100 5340587) #> 4  POINT (431100 5340009) #> 5  POINT (431100 5342319) #> 6  POINT (431100 5338277) #> 7  POINT (431600 5337989) #> 8  POINT (431100 5338855) #> 9  POINT (431100 5340009) #> 10 POINT (431600 5339721)  sample_systematic(   raster = sr,   cellsize = 1000,   access = ac,   buff_inner = 50,   buff_outer = 200 ) #> An access layer has been provided. An internal buffer of 50 m and an external buffer of 200 m have been applied #> Simple feature collection with 15 features and 0 fields #> Geometry type: POINT #> Dimension:     XY #> Bounding box:  xmin: 432600 ymin: 5338200 xmax: 437600 ymax: 5343200 #> CRS:           +proj=utm +zone=17 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs #> First 10 features: #>                  geometry #> 1  POINT (434600 5338200) #> 2  POINT (436600 5338200) #> 3  POINT (432600 5339200) #> 4  POINT (434600 5339200) #> 5  POINT (437600 5339200) #> 6  POINT (435600 5340200) #> 7  POINT (432600 5341200) #> 8  POINT (433600 5341200) #> 9  POINT (434600 5341200) #> 10 POINT (432600 5342200)  sample_systematic(   raster = sr,   cellsize = 1000,   square = FALSE,   location = \"random\" ) #> Simple feature collection with 42 features and 0 fields #> Geometry type: POINT #> Dimension:     XY #> Bounding box:  xmin: 431445.4 ymin: 5337843 xmax: 438495 ymax: 5343229 #> CRS:           +proj=utm +zone=17 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs #> First 10 features: #>                    geometry #> 1  POINT (431445.4 5339583) #> 2  POINT (431842.7 5340005) #> 3  POINT (431473.8 5342375) #> 4  POINT (431733.6 5337928) #> 5  POINT (431742.6 5341008) #> 6  POINT (431989.8 5343229) #> 7  POINT (432328.5 5338429) #> 8  POINT (432408.7 5341789) #> 9  POINT (433333.8 5338130) #> 10 POINT (432979.6 5339617)"},{"path":"/reference/sgsR-package.html","id":null,"dir":"Reference","previous_headings":"","what":"sgsR: Structurally Guided Sampling Approaches using ALS Data — sgsR-package","title":"sgsR: Structurally Guided Sampling Approaches using ALS Data — sgsR-package","text":"package provides functions enable stratification sampling structurally guided sampling using ALS data.","code":""},{"path":[]},{"path":"/reference/sgsR-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"sgsR: Structurally Guided Sampling Approaches using ALS Data — sgsR-package","text":"Maintainer: Tristan RH Goodbody goodbody.t@gmail.com (ORCID) Authors: Nicholas C Coops nicholas.coops@ubc.ca (ORCID) Martin Queinnec queinnec@mail.ubc.ca (ORCID)","code":""},{"path":"/reference/strat_breaks.html","id":null,"dir":"Reference","previous_headings":"","what":"Breaks stratification — strat_breaks","title":"Breaks stratification — strat_breaks","text":"Stratify metrics raster using user defined breaks","code":""},{"path":"/reference/strat_breaks.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Breaks stratification — strat_breaks","text":"","code":"strat_breaks(   mraster,   mraster2 = NULL,   breaks,   breaks2 = NULL,   plot = FALSE,   details = FALSE,   filename = NULL,   overwrite = FALSE,   ... )"},{"path":"/reference/strat_breaks.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Breaks stratification — strat_breaks","text":"mraster Spatraster. Primary covariate raster stratify. mraster2 Spatraster. Secondary covariate raster stratify. breaks Numeric. Vector breakpoints mraster breaks2 Numeric. Vector breakpoints mraster2 (provided) plot Logical. Plots output strata raster visualized strata boundary dividers. details Logical. FALSE (default) output  stratification raster. TRUE return list $details additional stratification information  $raster output stratification spatRaster.  @param ... Additional arguments passed kmeans function. filename Character. Path write stratified raster disc. overwrite Logical. Specify whether filename overwritten disc. ... Additional arguments writing files. See writeRaster.","code":""},{"path":"/reference/strat_breaks.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Breaks stratification — strat_breaks","text":"Returns output stratification spatRaster list details = TRUE. list returned: details list output prcomp function raster stratified spatRaster based quantiles plot ggplot histogram object showing distribution break points.","code":""},{"path":[]},{"path":"/reference/strat_breaks.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Breaks stratification — strat_breaks","text":"Tristan R.H. Goodbody","code":""},{"path":"/reference/strat_breaks.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Breaks stratification — strat_breaks","text":"","code":"#--- Load raster ---# r <- system.file(\"extdata\", \"wall_metrics.tif\", package = \"sgsR\") mr <- terra::rast(r)  #--- create vector breaks ---# br.max <- c(3, 5, 11, 18) br.sd <- c(1, 2, 5)  strat_breaks(   mraster = mr$zq90,   breaks = br.max,   plot = TRUE,   details = TRUE )   #> $details #> $details$breaks #> [1]  3  5 11 18 #>  #> $details$breaks2 #> NULL #>  #>  #> $raster #> class       : SpatRaster  #> dimensions  : 277, 373, 1  (nrow, ncol, nlyr) #> resolution  : 20, 20  (x, y) #> extent      : 431100, 438560, 5337700, 5343240  (xmin, xmax, ymin, ymax) #> coord. ref. : UTM Zone 17, Northern Hemisphere  #> source      : memory  #> name        : strata  #> min value   :      1  #> max value   :      5  #>  #> $plot #> `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.  #>   strat_breaks(   mraster = mr$zq90,   mraster2 = mr$zsd,   breaks = br.max,   breaks2 = br.sd,   plot = TRUE )   #> class       : SpatRaster  #> dimensions  : 277, 373, 1  (nrow, ncol, nlyr) #> resolution  : 20, 20  (x, y) #> extent      : 431100, 438560, 5337700, 5343240  (xmin, xmax, ymin, ymax) #> coord. ref. : UTM Zone 17, Northern Hemisphere  #> source      : memory  #> name        : strata  #> min value   :      1  #> max value   :     17"},{"path":"/reference/strat_kmeans.html","id":null,"dir":"Reference","previous_headings":"","what":"k-means stratification — strat_kmeans","title":"k-means stratification — strat_kmeans","text":"Stratify metrics raster using kmeans algorithm","code":""},{"path":"/reference/strat_kmeans.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"k-means stratification — strat_kmeans","text":"","code":"strat_kmeans(   mraster,   nStrata,   iter = 500,   algorithm = \"Lloyd\",   center = TRUE,   scale = TRUE,   plot = FALSE,   details = FALSE,   filename = NULL,   overwrite = FALSE,   ... )"},{"path":"/reference/strat_kmeans.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"k-means stratification — strat_kmeans","text":"mraster spatRaster. ALS metrics raster. nStrata Character. Number desired strata. iter Numeric. maximum number iterations allowed. algorithm Character. Lloyd (default) MacQueen algorithms. center Logical. Value indicating whether variables shifted zero centered. scale Logical. Value indicating whether variables scaled unit variance plot Logical. Plots output strata raster visualized strata boundary dividers. details Logical. FALSE (default) output  stratification raster. TRUE return list $details additional stratification information  $raster output stratification spatRaster.  @param ... Additional arguments passed kmeans function. filename Character. Path write stratified raster disc. overwrite Logical. Specify whether filename overwritten disc. ... Additional arguments writing files. See writeRaster.","code":""},{"path":"/reference/strat_kmeans.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"k-means stratification — strat_kmeans","text":"output stratification spatRaster, list details = TRUE.","code":""},{"path":[]},{"path":"/reference/strat_kmeans.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"k-means stratification — strat_kmeans","text":"Tristan R.H. Goodbody","code":""},{"path":"/reference/strat_kmeans.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"k-means stratification — strat_kmeans","text":"","code":"#--- Load raster and access files ---# r <- system.file(\"extdata\", \"wall_metrics.tif\", package = \"sgsR\") mr <- terra::rast(r)  #--- perform stratification using k-means ---# kmeans <- strat_kmeans(   mraster = mr,   nStrata = 5 ) #> K-means being performed on 7 layers with 5 centers.  kmeans <- strat_kmeans(   mraster = mr,   nStrata = 5,   iter = 1000,   algorithm = \"MacQueen\",   plot = TRUE,   details = TRUE ) #> K-means being performed on 7 layers with 5 centers.   kmeans <- strat_kmeans(   mraster = mr,   nStrata = 5,   iter = 1000,   plot = TRUE,   filename = tempfile(fileext = \".tif\"),   overwrite = TRUE ) #> K-means being performed on 7 layers with 5 centers."},{"path":"/reference/strat_map.html","id":null,"dir":"Reference","previous_headings":"","what":"Map 2 stratified rasters — strat_map","title":"Map 2 stratified rasters — strat_map","text":"Map stratified rasters combined stratification.","code":""},{"path":"/reference/strat_map.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Map 2 stratified rasters — strat_map","text":"","code":"strat_map(   sraster,   sraster2,   stack = FALSE,   filename = NULL,   overwrite = FALSE,   plot = FALSE,   details = FALSE,   ... )"},{"path":"/reference/strat_map.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Map 2 stratified rasters — strat_map","text":"sraster spatRaster. Primary stratification raster. sraster2 spatRaster. Secondary stratification raster. stack Logical. Default = FALSE. TRUE, output raster 3 layers: strata, strata2, stratamapped. filename Character. Path write stratified raster disc. overwrite Logical. Specify whether filename overwritten disc. plot Logical. Plots output strata raster visualized strata boundary dividers. details Logical. FALSE (default) output mapped stratified spatRaster object. TRUE return list $outRaster mapped stratified raster, $lookUp lookup table stratification. ... Additional arguments writing files. See writeRaster.","code":""},{"path":"/reference/strat_map.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Map 2 stratified rasters — strat_map","text":"spatRaster object.","code":""},{"path":"/reference/strat_map.html","id":"mapping","dir":"Reference","previous_headings":"","what":"Mapping","title":"Map 2 stratified rasters — strat_map","text":"mapping algorithm take stratification sraster combine overlying strata values sraster2. result stratamapped attribute values inputs combined. .e. strata = 1 strata2 = 1 stratamapped = 11. strata = 2 strata2 = 14 stratamapped = 214.","code":""},{"path":[]},{"path":"/reference/strat_map.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Map 2 stratified rasters — strat_map","text":"Tristan R.H. Goodbody","code":""},{"path":"/reference/strat_map.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Map 2 stratified rasters — strat_map","text":"","code":"#--- load input metrics raster ---# raster <- system.file(\"extdata\", \"kmeans.tif\", package = \"sgsR\") srasterkmeans <- terra::rast(raster)  #--- read polygon coverage ---# poly <- system.file(\"extdata\", \"inventory_polygons.shp\", package = \"sgsR\") fri <- sf::st_read(poly) #> Reading layer `inventory_polygons' from data source  #>   `C:\\Users\\tgood.stu\\Documents\\R\\win-library\\4.1\\sgsR\\extdata\\inventory_polygons.shp'  #>   using driver `ESRI Shapefile' #> Simple feature collection with 632 features and 3 fields #> Geometry type: MULTIPOLYGON #> Dimension:     XY #> Bounding box:  xmin: 431100 ymin: 5337700 xmax: 438560 ymax: 5343240 #> Projected CRS: UTM_Zone_17_Northern_Hemisphere  #--- stratify polygon coverage ---# #--- specify polygon attribute to stratify ---#  attribute <- \"NUTRIENTS\"  #--- specify features within attribute & how they should be grouped ---# #--- as a single vector ---#  features <- c(\"poor\", \"rich\", \"medium\")  srasterfri <- strat_poly(   poly = fri,   attribute = attribute,   features = features,   raster = srasterkmeans,   plot = TRUE )   #--- map srasters ---# strat_map(   sraster = srasterfri,   sraster2 = srasterkmeans,   plot = TRUE )  #> class       : SpatRaster  #> dimensions  : 277, 373, 1  (nrow, ncol, nlyr) #> resolution  : 20, 20  (x, y) #> extent      : 431100, 438560, 5337700, 5343240  (xmin, xmax, ymin, ymax) #> coord. ref. : UTM Zone 17, Northern Hemisphere  #> source      : memory  #> name        : strata  #> min value   :     11  #> max value   :    310   strat_map(   sraster = srasterfri,   sraster2 = srasterkmeans,   stack = TRUE,   details = TRUE,   plot = TRUE ) #> Stacking sraster, sraster2, and their combination (stratamapped).  #> $outRaster #> class       : SpatRaster  #> dimensions  : 277, 373, 3  (nrow, ncol, nlyr) #> resolution  : 20, 20  (x, y) #> extent      : 431100, 438560, 5337700, 5343240  (xmin, xmax, ymin, ymax) #> coord. ref. : UTM Zone 17, Northern Hemisphere  #> sources     : memory   #>               kmeans.tif   #>               memory   #> names       : strata, strata2, stratamapped  #> min values  :      1,       1,           11  #> max values  :      3,      10,          310  #>  #> $lookUp #>    strata strata2 stratamapped #> 1       3       2           32 #> 2       3       8           38 #> 3       3       7           37 #> 4       3       5           35 #> 5       1       4           14 #> 6       1       1           11 #> 7       1       3           13 #> 8       1       6           16 #> 9       1      10          110 #> 10      3       4           34 #> 11      3       6           36 #> 12      3       1           31 #> 13      1       7           17 #> 14      1       5           15 #> 15      1       9           19 #> 16      1       8           18 #> 17      1       2           12 #> 18      2       8           28 #> 19      2       7           27 #> 20      2      10          210 #> 21      2       4           24 #> 22      2       5           25 #> 23      2       2           22 #> 24      3       3           33 #> 25      3      10          310 #> 26      3       9           39 #> 27      2       6           26 #> 28      2       3           23 #> 29      2       1           21 #> 30      2       9           29 #>"},{"path":"/reference/strat_osb.html","id":null,"dir":"Reference","previous_headings":"","what":"Determine optimum sample boundaries — strat_osb","title":"Determine optimum sample boundaries — strat_osb","text":"Determine optimum sample boundaries algorithm univariate populations using strata.data algorithm.","code":""},{"path":"/reference/strat_osb.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Determine optimum sample boundaries — strat_osb","text":"","code":"strat_osb(   mraster,   nStrata,   nSamp,   subset = 1,   plot = FALSE,   details = FALSE,   filename = NULL,   overwrite = FALSE,   ... )"},{"path":"/reference/strat_osb.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Determine optimum sample boundaries — strat_osb","text":"mraster spatRaster. ALS metrics raster. nStrata Numeric. Number desired output strata. nSamp Numeric. Number desired samples - used within OSB algorithm help determine break points. subset Numeric. Value 0 1 (default) denoting proportion data use determine optimum sample boundaries. plot Logical. Plots output strata raster visualized strata boundary dividers. details Logical. FALSE (default) output  stratification raster. TRUE return list $details additional stratification information  $raster output stratification spatRaster.  @param ... Additional arguments passed kmeans function. filename Character. Path write stratified raster disc. overwrite Logical. Specify whether filename overwritten disc. ... Additional arguments writing files. See writeRaster.","code":""},{"path":"/reference/strat_osb.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Determine optimum sample boundaries — strat_osb","text":"Returns output stratification spatRaster list details = TRUE. list returned: details list output strata.data function OSB optimum stratum boundaries nh optimum sample sizes stratum. osb vector optimum stratum boundaries. breaks matrix associated metric strata break values. raster stratified spatRaster based OSB.","code":""},{"path":"/reference/strat_osb.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Determine optimum sample boundaries — strat_osb","text":"Khan, E. ., Khan, M. G. M., & Ahsan, M. J. (2002). Optimum Stratification: Mathematical Programming Approach. Calcutta Statistical Association Bulletin, 52(1–4), 323–334. https://doi.org/10.1177/0008068320020518 Khan, M. G. M., Nand, N., & Ahmad, N. (2008). Determining optimum strata boundary points using dynamic programming. Survey methodology, 34(2), 205-214. M.G.M. Khan, K.G. Reddy & D.K. Rao (2015) Designing stratified sampling economic business surveys, Journal Applied Statistics, 42:10, 2080-2099, DOI: 10.1080/02664763.2015.1018674","code":""},{"path":[]},{"path":"/reference/strat_osb.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Determine optimum sample boundaries — strat_osb","text":"Tristan R.H. Goodbody","code":""},{"path":[]},{"path":"/reference/strat_pcomp.html","id":null,"dir":"Reference","previous_headings":"","what":"Principal components stratification — strat_pcomp","title":"Principal components stratification — strat_pcomp","text":"Stratify metrics raster using principal components quantile breaks","code":""},{"path":"/reference/strat_pcomp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Principal components stratification — strat_pcomp","text":"","code":"strat_pcomp(   mraster,   nStrata,   nStrata2 = NULL,   center = TRUE,   scale = TRUE,   plot = FALSE,   samp = 1,   details = FALSE,   filename = NULL,   overwrite = FALSE,   ... )"},{"path":"/reference/strat_pcomp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Principal components stratification — strat_pcomp","text":"mraster Spatraster. Covariate raster stratify. nStrata Numeric. Number strata primary principal component. nStrata2 Numeric. Number strata secondary principal component. center Logical. Value indicating whether variables shifted zero centered. scale Logical. Value indicating whether variables scaled unit variance plot Logical. Plots output strata raster visualized strata boundary dividers. samp Numeric. Proportion raster cells plot 0-1. details Logical. FALSE (default) output  stratification raster. TRUE return list $details additional stratification information  $raster output stratification spatRaster.  @param ... Additional arguments passed kmeans function. filename Character. Path write stratified raster disc. overwrite Logical. Specify whether filename overwritten disc. ... Additional arguments passed prcomp.","code":""},{"path":"/reference/strat_pcomp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Principal components stratification — strat_pcomp","text":"Returns output stratification spatRaster list details = TRUE. list returned: details list output prcomp function raster stratified spatRaster based PCA plot ggplot scatter plot object strata colour coded strata boundaries delineated","code":""},{"path":[]},{"path":"/reference/strat_pcomp.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Principal components stratification — strat_pcomp","text":"Tristan R.H. Goodbody","code":""},{"path":"/reference/strat_pcomp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Principal components stratification — strat_pcomp","text":"","code":"#--- Load raster and access files ---# r <- system.file(\"extdata\", \"wall_metrics.tif\", package = \"sgsR\") mr <- terra::rast(r)  strat_pcomp(   mraster = mr,   nStrata = 5,   plot = TRUE )  #> class       : SpatRaster  #> dimensions  : 277, 373, 1  (nrow, ncol, nlyr) #> resolution  : 20, 20  (x, y) #> extent      : 431100, 438560, 5337700, 5343240  (xmin, xmax, ymin, ymax) #> coord. ref. : UTM Zone 17, Northern Hemisphere  #> source      : memory  #> name        : strata  #> min value   :      1  #> max value   :      5   strat_pcomp(   mraster = mr,   nStrata = 4,   nStrata2 = 4,   plot = TRUE,   details = TRUE )  #> $details #> Standard deviations (1, .., p=9): #> [1] 2.66328897 1.09805898 0.66339469 0.41858538 0.22109594 0.14478794 #> [7] 0.09669328 0.07739106 0.02581106 #>  #> Rotation (n x k) = (9 x 9): #>                PC1         PC2         PC3         PC4         PC5 #> zmax     0.3718561  0.05890652  0.13655303  0.18644188 -0.02967021 #> zmean    0.2892076  0.11179079 -0.94037185  0.11669464 -0.01101177 #> zsd      0.2902484 -0.57132611  0.07358411 -0.03485495 -0.12710815 #> pzabove2 0.2762415  0.57389014  0.11046261 -0.48982874 -0.53278380 #> zq20     0.3222793  0.42913513  0.17765055  0.04688184  0.69772164 #> zq50     0.3621931  0.06711670  0.16260903  0.50497308 -0.03554264 #> zq70     0.3669446 -0.07622676  0.13483825  0.33474905 -0.33679147 #> zq90     0.3576125 -0.24286784  0.04467110 -0.28486752  0.00494469 #> zq95     0.3463317 -0.27351876 -0.03548477 -0.50997312  0.31217248 #>                   PC6          PC7         PC8          PC9 #> zmax     -0.022902433  0.058181544  0.12813760 -0.885232514 #> zmean     0.061423536  0.005559276 -0.04493042  0.001085691 #> zsd       0.373461072 -0.062831197 -0.65029797 -0.015746780 #> pzabove2  0.007219003  0.005909104 -0.23569527  0.052045306 #> zq20      0.371793616 -0.128585416 -0.12943905  0.141020587 #> zq50     -0.525190662  0.398814446 -0.24627692  0.293390931 #> zq70      0.136444231 -0.587797301  0.42249155  0.270652072 #> zq90      0.287643242  0.607152727  0.49439800  0.184814994 #> zq95     -0.583751620 -0.320739852  0.05279230  0.005601089 #>  #> $raster #> class       : SpatRaster  #> dimensions  : 277, 373, 1  (nrow, ncol, nlyr) #> resolution  : 20, 20  (x, y) #> extent      : 431100, 438560, 5337700, 5343240  (xmin, xmax, ymin, ymax) #> coord. ref. : UTM Zone 17, Northern Hemisphere  #> source      : memory  #> name        : strata  #> min value   :      1  #> max value   :     16  #>  #> $plot  #>   strat_pcomp(   mraster = mr,   nStrata = 3,   nStrata2 = 3,   filename = tempfile(fileext = \".tif\") ) #> class       : SpatRaster  #> dimensions  : 277, 373, 1  (nrow, ncol, nlyr) #> resolution  : 20, 20  (x, y) #> extent      : 431100, 438560, 5337700, 5343240  (xmin, xmax, ymin, ymax) #> coord. ref. : UTM Zone 17, Northern Hemisphere  #> source      : memory  #> name        : strata  #> min value   :      1  #> max value   :      9"},{"path":"/reference/strat_poly.html","id":null,"dir":"Reference","previous_headings":"","what":"Stratify using polygons — strat_poly","title":"Stratify using polygons — strat_poly","text":"Stratify based polygon coverage attributes features.","code":""},{"path":"/reference/strat_poly.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Stratify using polygons — strat_poly","text":"","code":"strat_poly(   poly,   attribute,   features,   raster,   filename = NULL,   overwrite = FALSE,   plot = FALSE,   details = FALSE,   ... )"},{"path":"/reference/strat_poly.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Stratify using polygons — strat_poly","text":"poly sf. Input polygon coverage. e.g. - forest resources inventory coverage. attribute Character. Name attribute within poly stratified features vector/list. Vector list vectors features within attribute guide stratification. raster spatRaster. Raster template enable polygon raster conversion. filename Character. Path write stratified raster disc. overwrite Logical. Specify whether filename overwritten disc. plot Logical. Plots output spatRaster. details Logical. FALSE (default) output spatRaster object stratified polygon attributes. TRUE return list $outRaster stratified attributes, $lookUp lookup table stratification, poly defined polygon attribute corresponding features / strata ... Additional arguments writing files. See writeRaster.","code":""},{"path":"/reference/strat_poly.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Stratify using polygons — strat_poly","text":"spatRaster object.","code":""},{"path":[]},{"path":"/reference/strat_poly.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Stratify using polygons — strat_poly","text":"Tristan R.H. Goodbody","code":""},{"path":"/reference/strat_poly.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Stratify using polygons — strat_poly","text":"","code":"#--- load input metrics raster ---# raster <- system.file(\"extdata\", \"kmeans.tif\", package = \"sgsR\") sraster <- terra::rast(raster)  #--- read polygon coverage ---# poly <- system.file(\"extdata\", \"inventory_polygons.shp\", package = \"sgsR\") fri <- sf::st_read(poly) #> Reading layer `inventory_polygons' from data source  #>   `C:\\Users\\tgood.stu\\Documents\\R\\win-library\\4.1\\sgsR\\extdata\\inventory_polygons.shp'  #>   using driver `ESRI Shapefile' #> Simple feature collection with 632 features and 3 fields #> Geometry type: MULTIPOLYGON #> Dimension:     XY #> Bounding box:  xmin: 431100 ymin: 5337700 xmax: 438560 ymax: 5343240 #> Projected CRS: UTM_Zone_17_Northern_Hemisphere  #--- stratify polygon coverage ---# #--- specify polygon attribute to stratify ---#  attribute <- \"NUTRIENTS\"  #--- specify features within attribute & how they should be grouped ---# #--- as a single vector ---#  features <- c(\"poor\", \"rich\", \"medium\")  srasterpoly <- strat_poly(   poly = fri,   attribute = attribute,   features = features,   raster = sraster,   plot = TRUE )   #--- or as multiple lists ---#  g1 <- \"poor\" g2 <- c(\"rich\", \"medium\")  features <- list(g1, g2)  srasterpoly <- strat_poly(   poly = fri,   attribute = attribute,   features = features,   raster = sraster,   plot = TRUE,   details = TRUE )"},{"path":"/reference/strat_quantiles.html","id":null,"dir":"Reference","previous_headings":"","what":"Quantiles stratification — strat_quantiles","title":"Quantiles stratification — strat_quantiles","text":"Stratify metric raster using metric quantiles.","code":""},{"path":"/reference/strat_quantiles.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Quantiles stratification — strat_quantiles","text":"","code":"strat_quantiles(   mraster,   mraster2 = NULL,   nStrata,   nStrata2 = NULL,   plot = FALSE,   details = FALSE,   samp = 1,   filename = NULL,   overwrite = FALSE,   ... )"},{"path":"/reference/strat_quantiles.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Quantiles stratification — strat_quantiles","text":"mraster spatRaster. ALS metrics raster. mraster2 Spatraster. Secondary covariate raster stratify. nStrata Numeric. Number quantiles stratify primary covariate. nStrata2 Numeric. Number quantiles stratify secondary covariate. plot Logical. Plots output strata raster visualized strata boundary dividers. details Logical. FALSE (default) output  stratification raster. TRUE return list $details additional stratification information  $raster output stratification spatRaster.  @param ... Additional arguments passed kmeans function. samp Numeric. Determines proportion cells plot scatterplot (default = 1). Lower values reduce visualization time. filename Character. Path write stratified raster disc. overwrite Logical. Specify whether filename overwritten disc. ... Additional arguments writing files. See writeRaster.","code":""},{"path":"/reference/strat_quantiles.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Quantiles stratification — strat_quantiles","text":"Returns output stratification spatRaster list details = TRUE. list returned: details list output prcomp function raster stratified spatRaster based quantiles plot ggplot histogram / scatter plot object (depends whether metric2 supplied). Histogram shows distribution break points scatter plot shows colour coded strata boundaries.","code":""},{"path":[]},{"path":"/reference/strat_quantiles.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Quantiles stratification — strat_quantiles","text":"Tristan R.H. Goodbody","code":""},{"path":"/reference/strat_quantiles.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Quantiles stratification — strat_quantiles","text":"","code":"#--- Load raster and existing plots---# r <- system.file(\"extdata\", \"wall_metrics.tif\", package = \"sgsR\") mr <- terra::rast(r)  strat_quantiles(   mraster = mr$zq90,   nStrata = 4,   plot = TRUE ) #> `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.   #> class       : SpatRaster  #> dimensions  : 277, 373, 1  (nrow, ncol, nlyr) #> resolution  : 20, 20  (x, y) #> extent      : 431100, 438560, 5337700, 5343240  (xmin, xmax, ymin, ymax) #> coord. ref. : UTM Zone 17, Northern Hemisphere  #> source      : memory  #> name        : strata  #> min value   :      1  #> max value   :      4   strat_quantiles(   mraster = mr$zq90,   mraster2 = mr$zsd,   nStrata = 3,   nStrata2 = 4 ) #> class       : SpatRaster  #> dimensions  : 277, 373, 1  (nrow, ncol, nlyr) #> resolution  : 20, 20  (x, y) #> extent      : 431100, 438560, 5337700, 5343240  (xmin, xmax, ymin, ymax) #> coord. ref. : UTM Zone 17, Northern Hemisphere  #> source      : memory  #> name        : strata  #> min value   :      1  #> max value   :     12"},{"path":"/reference/tidyeval.html","id":null,"dir":"Reference","previous_headings":"","what":"Tidy eval helpers — tidyeval","title":"Tidy eval helpers — tidyeval","text":"page lists tidy eval tools reexported package rlang. learn using tidy eval scripts packages high level, see dplyr programming vignette ggplot2 packages vignette. Metaprogramming section Advanced R may also useful deeper dive. tidy eval operators {{, !!, !!! syntactic constructs specially interpreted tidy eval functions. mostly need {{, !! !!! advanced operators use simple cases. curly-curly operator {{ allows tunnel data-variables passed function arguments inside tidy eval functions. {{ designed individual arguments. pass multiple arguments contained dots, use ... normal way. enquo() enquos() delay execution one several function arguments. former returns single expression, latter returns list expressions. defused, expressions longer evaluate . must injected back evaluation context !! (single expression) !!! (list expressions). simple case, code equivalent usage {{ ... . Defusing enquo() enquos() needed complex cases, instance need inspect modify expressions way. .data pronoun object represents current slice data. variable name string, use .data pronoun subset variable [[. Another tidy eval operator :=. makes possible use glue curly-curly syntax LHS =. technical reasons, R language support complex expressions left =, use := workaround. Many tidy eval functions like dplyr::mutate() dplyr::summarise() give automatic name unnamed inputs. need create sort automatic names , use as_label(). instance, glue-tunnelling syntax can reproduced manually : Expressions defused enquo() (tunnelled {{) need simple column names, can arbitrarily complex. as_label() handles cases gracefully. code assumes simple column name, use as_name() instead. safer throws error input name expected.","code":"my_function <- function(data, var, ...) {   data %>%     group_by(...) %>%     summarise(mean = mean({{ var }})) } my_function <- function(data, var, ...) {   # Defuse   var <- enquo(var)   dots <- enquos(...)    # Inject   data %>%     group_by(!!!dots) %>%     summarise(mean = mean(!!var)) } my_var <- \"disp\" mtcars %>% summarise(mean = mean(.data[[my_var]])) my_function <- function(data, var, suffix = \"foo\") {   # Use `{{` to tunnel function arguments and the usual glue   # operator `{` to interpolate plain strings.   data %>%     summarise(\"{{ var }}_mean_{suffix}\" := mean({{ var }})) } my_function <- function(data, var, suffix = \"foo\") {   var <- enquo(var)   prefix <- as_label(var)   data %>%     summarise(\"{prefix}_mean_{suffix}\" := mean(!!var)) }"}]
